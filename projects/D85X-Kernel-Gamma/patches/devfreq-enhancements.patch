diff --git Documentation/devicetree/bindings/arm/msm/cpubw.txt Documentation/devicetree/bindings/arm/msm/cpubw.txt
deleted file mode 100644
index 1dc3835..0000000
--- Documentation/devicetree/bindings/arm/msm/cpubw.txt
+++ /dev/null
@@ -1,30 +0,0 @@
-MSM CPU bandwidth device
-
-cpubw is a device that represents the CPU subsystem master ports in a MSM SoC
-and the related info that is needed to make CPU to DDR bandwidth votes.
-
-Required properties:
-- compatible:		Must be "qcom,cpubw"
-- qcom,cpu-mem-ports:	A list of tuples where each tuple consists of a bus
-			master (CPU subsystem) port number and a bus slave
-			(memory) port number.
-- qcom,bw-tbl:		A list of meaningful instantaneous bandwidth values
-			(in MB/s) that can be requested from the CPU
-			subsystem to DDR. The list of values depend on the
-			supported DDR frequencies and the bus widths.
-
-Example:
-
-	qcom,cpubw {
-		compatible = "qcom,cpubw";
-		qcom,cpu-mem-ports = <1 512>, <2 512>;
-		qcom,bw-tbl =
-			<  572 /*  75 MHz */ >,
-			< 1144 /* 150 MHz */ >,
-			< 1525 /* 200 MHz */ >,
-			< 2342 /* 307 MHz */ >,
-			< 3509 /* 460 MHz */ >,
-			< 4684 /* 614 MHz */ >,
-			< 6103 /* 800 MHz */ >,
-			< 7102 /* 931 MHz */ >;
-	};
diff --git Documentation/devicetree/bindings/arm/msm/kraitbw-l2pm.txt Documentation/devicetree/bindings/arm/msm/kraitbw-l2pm.txt
index 17d55d4..ec812ac 100644
--- Documentation/devicetree/bindings/arm/msm/kraitbw-l2pm.txt
+++ Documentation/devicetree/bindings/arm/msm/kraitbw-l2pm.txt
@@ -9,10 +9,12 @@ Required properties:
 - interrupts:		Lists the L2 PM counter overflow IRQ.
 - qcom,bytes-per-beat:	The number of bytes transferred in one data beat from
 			the Krait CPU subsystem.
+- qcom,target-dev:	Target device for cache scaling
 
 Example:
 	qcom,kraitbw-l2pm {
 		compatible = "qcom,kraitbw-l2pm";
 		interrupts = <0 1 1>;
 		qcom,bytes-per-beat = <8>;
+		qcom,target-dev = <&cache>;
 	};
diff --git Documentation/devicetree/bindings/arm/msm/msm-cpufreq.txt Documentation/devicetree/bindings/arm/msm/msm-cpufreq.txt
index fed49c9..8bbdc80 100644
--- Documentation/devicetree/bindings/arm/msm/msm-cpufreq.txt
+++ Documentation/devicetree/bindings/arm/msm/msm-cpufreq.txt
@@ -1,36 +1,36 @@
 Qualcomm MSM CPUfreq device
 
-msm-cpufreq is a device that represents the list of useable CPU frequencies
-and the cache frequency and/or memory bandwidth required for each of them. It
-also captures the bus master/slave ports towards which the bus bandwidth
-requests need to be made to ensure the required memory bandwidth.
+msm-cpufreq is a device that represents the list of usable CPU frequencies
+and provides a device handle for the CPUfreq driver to get the CPU and cache
+clocks.
 
 Required properties:
 - compatible:		Must be "qcom,msm-cpufreq"
-- qcom,cpufreq-table:	A list of tuples where each tuple consists of a
-			usable CPU frequency (KHz), an optional cache
-			frequency (KHz) and a mandatory memory bandwidth
-			value (MBPS) listed in that order.  The cache
-			frequencies shall not be listed if the device cannot
-			run the cache asynchronous to one or more CPUs.
+- qcom,cpufreq-table:	A list of usable CPU frequencies (KHz)
+
+Optional properties:
+- clock-names:		When DT based binding of clock is available, this
+			provides a list of CPU subsystem clocks.
+			"cpuX_clk" for every CPU that's present.
+			"l2_clk" when an async cache/CCI is present.
 
 Example:
 	qcom,msm-cpufreq@0 {
 		regs = <0 4>
 		compatible = "qcom,msm-cpufreq";
 		qcom,cpufreq-table =
-			<  300000  300000  600 >,
-			<  422400  422400 1200 >,
-			<  652800  499200 1600 >,
-			<  729600  576000 2456 >,
-			<  883200  576000 2456 >,
-			<  960000  960000 3680 >,
-			< 1036800 1036800 3680 >,
-			< 1190400 1036800 3680 >,
-			< 1267200 1267200 6400 >,
-			< 1497600 1497600 6400 >,
-			< 1574400 1574400 6400 >,
-			< 1728000 1651200 6400 >,
-			< 1958400 1728000 7448 >,
-			< 2265600 1728000 7448 >;
+			<  300000 >,
+			<  422400 >,
+			<  652800 >,
+			<  729600 >,
+			<  883200 >,
+			<  960000 >,
+			< 1036800 >,
+			< 1190400 >,
+			< 1267200 >,
+			< 1497600 >,
+			< 1574400 >,
+			< 1728000 >,
+			< 1958400 >,
+			< 2265600 >;
 	};
diff --git Documentation/devicetree/bindings/devfreq/bimc-bwmon.txt Documentation/devicetree/bindings/devfreq/bimc-bwmon.txt
new file mode 100644
index 0000000..69c7891
--- /dev/null
+++ Documentation/devicetree/bindings/devfreq/bimc-bwmon.txt
@@ -0,0 +1,25 @@
+MSM BIMC bandwidth monitor device
+
+bimc-bwmon is a device that represents the MSM BIMC bandwidth monitors that
+can be used to measure the bandwidth of read/write traffic from the BIMC
+master ports. For example, the CPU subsystem sits on one BIMC master port.
+
+Required properties:
+- compatible:		Must be "qcom,bimc-bwmon"
+- reg:			Pairs of physical base addresses and region sizes of
+			memory mapped registers.
+- reg-names:		Names of the bases for the above registers. Expected
+			bases are: "base", "global_base"
+- interrupts:		Lists the threshold IRQ.
+- qcom,mport:		The hardware master port that this device can monitor
+- qcom,target-dev:	The DT device that corresponds to this master port
+
+Example:
+	qcom,cpu-bwmon {
+		compatible = "qcom,bimc-bwmon";
+		reg = <0xfc388000 0x300>, <0xfc381000 0x200>;
+		reg-names = "base", "global_base";
+		interrupts = <0 183 1>;
+		qcom,mport = <0>;
+		qcom,target-dev = <&cpubw>;
+	};
diff --git Documentation/devicetree/bindings/devfreq/devbw.txt Documentation/devicetree/bindings/devfreq/devbw.txt
new file mode 100644
index 0000000..ece0fa7
--- /dev/null
+++ Documentation/devicetree/bindings/devfreq/devbw.txt
@@ -0,0 +1,39 @@
+MSM device bandwidth device
+
+devbw is a device that represents a MSM device's BW requirements from its
+master port(s) to a different device's slave port(s) in a MSM SoC. This
+device is typically used to vote for BW requirements from a device's (Eg:
+CPU, GPU) master port(s) to the slave (Eg: DDR) port(s).
+
+Required properties:
+- compatible:		Must be "qcom,devbw"
+- qcom,src-dst-ports:	A list of tuples where each tuple consists of a bus
+			master port number and a bus slave port number.
+- qcom,bw-tbl:		A list of meaningful instantaneous bandwidth values
+			(in MB/s) that can be requested from the device
+			master port to the slave port. The list of values
+			depend on the supported bus/slave frequencies and the
+			bus width.
+
+Optional properties:
+- qcom,active-only:	Indicates that the bandwidth votes need to be
+			enforced only when the CPU subsystem is active.
+- governor:		Initial governor to use for the device.
+			Default: "performance"
+
+Example:
+
+	qcom,cpubw {
+		compatible = "qcom,devbw";
+		qcom,src-dst-ports = <1 512>, <2 512>;
+		qcom,active-only;
+		qcom,bw-tbl =
+			<  572 /*  75 MHz */ >,
+			< 1144 /* 150 MHz */ >,
+			< 1525 /* 200 MHz */ >,
+			< 2342 /* 307 MHz */ >,
+			< 3509 /* 460 MHz */ >,
+			< 4684 /* 614 MHz */ >,
+			< 6103 /* 800 MHz */ >,
+			< 7102 /* 931 MHz */ >;
+	};
diff --git Documentation/devicetree/bindings/devfreq/devfreq-cpufreq.txt Documentation/devicetree/bindings/devfreq/devfreq-cpufreq.txt
new file mode 100644
index 0000000..86959fd
--- /dev/null
+++ Documentation/devicetree/bindings/devfreq/devfreq-cpufreq.txt
@@ -0,0 +1,46 @@
+Devfreq CPUfreq governor
+
+devfreq-cpufreq is a parent device that contains one or more child devices.
+Each child device provides CPU frequency to device frequency mapping for a
+specific device. Examples of devices that could use this are: DDR, cache and
+CCI.
+
+Parent device name shall be "devfreq-cpufreq".
+
+Required child device properties:
+- cpu-to-dev-map:	A list of tuples where each tuple consists of a
+			CPU frequency (KHz) and the corresponding device
+			frequency. CPU frequencies not listed in the table
+			will use the device frequency that corresponds to the
+			next rounded up CPU frequency.
+- target-dev:		Phandle to device that this mapping applies to.
+
+Example:
+	devfreq-cpufreq {
+		cpubw-cpufreq {
+			target-dev = <&cpubw>;
+			cpu-to-dev-map =
+				<  300000  1144 >,
+				<  422400  2288 >,
+				<  652800  3051 >,
+				<  883200  5996 >,
+				< 1190400  8056 >,
+				< 1497600 10101 >,
+				< 1728000 12145 >,
+				< 2649600 16250 >;
+		};
+
+		cache-cpufreq {
+			target-dev = <&cache>;
+			cpu-to-dev-map =
+				<  300000  300000 >,
+				<  422400  422400 >,
+				<  652800  499200 >,
+				<  883200  576000 >,
+				<  960000  960000 >,
+				< 1497600 1036800 >,
+				< 1574400 1574400 >,
+				< 1728000 1651200 >,
+				< 2649600 1728000 >;
+		};
+	};
diff --git Documentation/devicetree/bindings/devfreq/devfreq-simple-dev.txt Documentation/devicetree/bindings/devfreq/devfreq-simple-dev.txt
new file mode 100644
index 0000000..4072053
--- /dev/null
+++ Documentation/devicetree/bindings/devfreq/devfreq-simple-dev.txt
@@ -0,0 +1,47 @@
+Devfreq simple device
+
+devfreq-simple-dev is a device that represents a simple device that cannot do
+any status reporting and uses a clock that can be scaled by one of more
+devfreq governors.  It provides a list of usable frequencies for the device
+and some additional optional parameters.
+
+Required properties:
+- compatible:		Must be "devfreq-simple-dev"
+- clock-names:		Must be "devfreq_clk"
+- clocks:		Must refer to the clock that's fed to the device.
+- freq-tbl-khz:		A list of usable frequencies (in KHz) for the device
+			clock.
+Optional properties:
+- polling-ms:	Polling interval for the device in milliseconds. Default: 50
+- governor:	Initial governor to user for the device. Default: "performance"
+
+Example:
+
+	qcom,cache {
+		compatible = "devfreq-simple-dev";
+		clock-names = "devfreq_clk";
+		clocks = <&clock_krait clk_l2_clk>;
+		polling-ms = 50;
+		governor = "cpufreq";
+		freq-tbl-khz =
+			<  300000 >,
+			<  345600 >,
+			<  422400 >,
+			<  499200 >,
+			<  576000 >,
+			<  652800 >,
+			<  729600 >,
+			<  806400 >,
+			<  883200 >,
+			<  960000 >,
+			< 1036800 >,
+			< 1113600 >,
+			< 1190400 >,
+			< 1267200 >,
+			< 1344000 >,
+			< 1420800 >,
+			< 1497600 >,
+			< 1574400 >,
+			< 1651200 >,
+			< 1728000 >;
+	};
diff --git arch/arm/boot/dts/fsm9900.dtsi arch/arm/boot/dts/fsm9900.dtsi
index 705a512..8a6f17a 100644
--- arch/arm/boot/dts/fsm9900.dtsi
+++ arch/arm/boot/dts/fsm9900.dtsi
@@ -99,5 +99,4 @@
 		qcom,pet-time = <10000>;
 		qcom,ipi-ping;
 	};
-
 };
diff --git arch/arm/boot/dts/msm8226.dtsi arch/arm/boot/dts/msm8226.dtsi
index 08a3776..1850a6a 100644
--- arch/arm/boot/dts/msm8226.dtsi
+++ arch/arm/boot/dts/msm8226.dtsi
@@ -1048,9 +1048,11 @@
 		cpu-vdd-supply = <&apc_vreg_corner>;
 	};
 
-	qcom,cpubw {
-		compatible = "qcom,cpubw";
-		qcom,cpu-mem-ports = <1 512>;
+	cpubw: qcom,cpubw {
+		compatible = "qcom,devbw";
+		governor = "cpufreq";
+		qcom,src-dst-ports = <1 512>;
+		qcom,active-only;
 		qcom,bw-tbl =
 			< 1525 /* 200 MHz */ >,
 			< 2441 /* 320 MHz */ >,
@@ -1058,24 +1060,33 @@
 			< 4066 /* 533 MHz */ >;
 	};
 
+	devfreq-cpufreq {
+		cpubw-cpufreq {
+			target-dev = <&cpubw>;
+			cpu-to-dev-map =
+				<  787200 1525 >,
+				< 1785600 4066 >;
+		};
+	};
+
 	qcom,msm-cpufreq@0 {
 		reg = <0 4>;
 		compatible = "qcom,msm-cpufreq";
 		qcom,cpufreq-table =
-			<  300000 1525 >,
-			<  384000 1525 >,
-			<  600000 1525 >,
-			<  787200 1525 >,
-			<  998400 4066 >,
-			< 1094400 4066 >,
-			< 1190400 4066 >,
-			< 1305600 4066 >,
-			< 1344000 4066 >,
-			< 1401600 4066 >,
-			< 1497600 4066 >,
-			< 1593600 4066 >,
-			< 1689600 4066 >,
-			< 1785600 4066 >;
+			<  300000 >,
+			<  384000 >,
+			<  600000 >,
+			<  787200 >,
+			<  998400 >,
+			< 1094400 >,
+			< 1190400 >,
+			< 1305600 >,
+			< 1344000 >,
+			< 1401600 >,
+			< 1497600 >,
+			< 1593600 >,
+			< 1689600 >,
+			< 1785600 >;
 	};
 
 	qcom,ocmem@fdd00000 {
diff --git arch/arm/boot/dts/msm8610.dtsi arch/arm/boot/dts/msm8610.dtsi
index ad029ee..6b47692 100644
--- arch/arm/boot/dts/msm8610.dtsi
+++ arch/arm/boot/dts/msm8610.dtsi
@@ -493,26 +493,37 @@
 		cpu-vdd-supply = <&apc_vreg_corner>;
 	};
 
-	qcom,cpubw {
-		compatible = "qcom,cpubw";
-		qcom,cpu-mem-ports = <1 512>;
+	cpubw: qcom,cpubw {
+		compatible = "qcom,devbw";
+		governor = "cpufreq";
+		qcom,src-dst-ports = <1 512>;
+		qcom,active-only;
 		qcom,bw-tbl =
 			<  762 /* 100 MHz */ >,
 			< 1525 /* 200 MHz */ >,
 			< 2540 /* 333 MHz */ >;
 	};
 
+	devfreq-cpufreq {
+		cpubw-cpufreq {
+			target-dev = <&cpubw>;
+			cpu-to-dev-map =
+				<  384000  762 >,
+				<  787200 1525 >,
+				< 1190400 2540 >;
+		};
+	};
+
 	qcom,msm-cpufreq@0 {
 		reg = <0 4>;
 		compatible = "qcom,msm-cpufreq";
 		qcom,cpufreq-table =
-			<  300000  762 >,
-			<  384000  762 >,
-			<  600000 1525 >,
-			<  787200 1525 >,
-			<  998400 2540 >,
-			< 1094400 2540 >,
-			< 1190400 2540 >;
+			<  300000 >,
+			<  384000 >,
+			<  600000 >,
+			<  787200 >,
+			<  998400 >,
+			< 1190400 >;
 	};
 
 	spmi_bus: qcom,spmi@fc4c0000 {
diff --git arch/arm/boot/dts/msm8974.dtsi arch/arm/boot/dts/msm8974.dtsi
index db2191e..fab3b87 100644
--- arch/arm/boot/dts/msm8974.dtsi
+++ arch/arm/boot/dts/msm8974.dtsi
@@ -1607,9 +1607,39 @@
 			< 2265600000  925000 691 >;
 	};
 
-	qcom,cpubw {
-		compatible = "qcom,cpubw";
-		qcom,cpu-mem-ports = <1 512>, <2 512>;
+	cache: qcom,cache@0 {
+		reg = <0 4>;
+		compatible = "devfreq-simple-dev";
+		clock-name = "l2_clk";
+		polling-ms = <10>;
+		governor = "cpufreq";
+		freq-tbl-khz =
+			<  300000 >,
+			<  345600 >,
+			<  422400 >,
+			<  499200 >,
+			<  576000 >,
+			<  652800 >,
+			<  729600 >,
+			<  806400 >,
+			<  883200 >,
+			<  960000 >,
+			< 1036800 >,
+			< 1113600 >,
+			< 1190400 >,
+			< 1267200 >,
+			< 1344000 >,
+			< 1420800 >,
+			< 1497600 >,
+			< 1574400 >,
+			< 1651200 >,
+			< 1728000 >;
+	};
+
+	cpubw: qcom,cpubw {
+		compatible = "qcom,devbw";
+		governor = "cpufreq";
+		qcom,src-dst-ports = <1 512>, <2 512>;
+		qcom,active-only;
 		qcom,bw-tbl =
 			<  381 /*  50 MHz */ >,
 			<  572 /*  75 MHz */ >,
@@ -1627,27 +1657,58 @@
 		compatible = "qcom,kraitbw-l2pm";
 		interrupts = <0 1 1>;
 		qcom,bytes-per-beat = <8>;
+		qcom,target-dev = <&cache>;
+	};
+
+	devfreq-cpufreq {
+		cpubw-cpufreq {
+			target-dev = <&cpubw>;
+			cpu-to-dev-map =
+				<  300000  572 >,
+				<  422400 1144 >,
+				<  652800 1525 >,
+				<  883200 2342 >,
+				< 1190400 3509 >,
+				< 1497600 4684 >,
+				< 1728000 6103 >,
+				< 2457600 7102 >;
+		};
+		cache-cpufreq {
+			target-dev = <&cache>;
+			cpu-to-dev-map =
+				<  300000  300000 >,
+				<  422400  422400 >,
+				<  652800  499200 >,
+				<  883200  576000 >,
+				<  960000  960000 >,
+				< 1190400 1036800 >,
+				< 1267200 1267200 >,
+				< 1497600 1497600 >,
+				< 1574400 1574400 >,
+				< 1728000 1651200 >,
+				< 2457600 1728000 >;
+		};
 	};
 
 	qcom,msm-cpufreq@0 {
 		reg = <0 4>;
 		compatible = "qcom,msm-cpufreq";
 		qcom,cpufreq-table =
-			<  300000  300000  572 >,
-			<  422400  422400 1144 >,
-			<  652800  499200 1525 >,
-			<  729600  576000 2342 >,
-			<  883200  576000 2342 >,
-			<  960000  960000 3509 >,
-			< 1036800 1036800 3509 >,
-			< 1190400 1036800 3509 >,
-			< 1267200 1267200 4684 >,
-			< 1497600 1497600 4684 >,
-			< 1574400 1574400 6103 >,
-			< 1728000 1651200 6103 >,
-			< 1958400 1728000 7102 >,
-			< 2265600 1728000 7102 >,
-			< 2457600 1728000 7102 >;
+			<  300000 >,
+			<  422400 >,
+			<  652800 >,
+			<  729600 >,
+			<  883200 >,
+			<  960000 >,
+			< 1036800 >,
+			< 1190400 >,
+			< 1267200 >,
+			< 1497600 >,
+			< 1574400 >,
+			< 1728000 >,
+			< 1958400 >,
+			< 2265600 >,
+			< 2457600 >;
 	};
 
 	usb3: qcom,ssusb@f9200000 {
diff --git arch/arm/boot/dts/msm9625.dtsi arch/arm/boot/dts/msm9625.dtsi
index dee1f68..5ec6a9b 100644
--- arch/arm/boot/dts/msm9625.dtsi
+++ arch/arm/boot/dts/msm9625.dtsi
@@ -463,6 +463,17 @@
 		qcom,bus-speed-mode = "SDR12", "SDR25", "SDR50", "DDR50";
 	};
 
+	cpubw: qcom,cpubw {
+		compatible = "qcom,devbw";
+		governor = "cpufreq";
+		qcom,src-dst-ports = <1 512>;
+		qcom,active-only;
+		qcom,bw-tbl =
+			< 1266 /* 166 MHz */ >,
+			< 2540 /* 333 MHz */ >,
+			< 3051 /* 400 MHz */ >;
+	};
+
 	ipa_hw: qcom,ipa@fd4c0000 {
 		compatible = "qcom,ipa";
 		reg = <0xfd4c0000 0x26000>,
@@ -501,30 +512,15 @@
 		};
 	};
 
-	qcom,acpuclk@f9010000 {
-		compatible = "qcom,acpuclk-9625";
-		reg = <0xf9010008 0x10>,
-		      <0xf9008004 0x4>;
-		reg-names = "rcg_base", "pwr_base";
-		a5_cpu-supply = <&pm8019_l10_corner_ao>;
-		a5_mem-supply = <&pm8019_l12_ao>;
-	};
-
-	gdsc_usb_hsic: qcom,gdsc@fc400404 {
-		compatible = "qcom,gdsc";
-		reg = <0xfc400404 0x4>;
-		regulator-name = "gdsc_usb_hsic";
-	};
-
-	tsens@fc4a8000 {
-		compatible = "qcom,msm-tsens";
-		reg = <0xfc4a8000 0x2000>,
-		      <0xfc4bc000 0x1000>;
-		reg-names = "tsens_physical", "tsens_eeprom_physical";
-		interrupts = <0 184 0>;
-		qcom,sensors = <5>;
-		qcom,slope = <3200 3200 3200 3200 3200>;
-		qcom,calib-mode = "fuse_map1";
+	qcom,msm-cpufreq@0 {
+		reg = <0 4>;
+		compatible = "qcom,msm-cpufreq";
+		qcom,cpufreq-table =
+			<  300000 >,
+			<  600000 >,
+			<  787200 >,
+			<  998400 >,
+			< 1152000 >;
 	};
 
 	qcom,msm-thermal {
diff --git arch/arm/configs/cyanogenmod_d850_oxavelar_defconfig arch/arm/configs/cyanogenmod_d850_oxavelar_defconfig
index 2c9ca15..b8c397f 100644
--- arch/arm/configs/cyanogenmod_d850_oxavelar_defconfig
+++ arch/arm/configs/cyanogenmod_d850_oxavelar_defconfig
@@ -2986,9 +2986,12 @@ CONFIG_DEVFREQ_GOV_SIMPLE_ONDEMAND=y
 CONFIG_DEVFREQ_GOV_PERFORMANCE=y
 CONFIG_DEVFREQ_GOV_POWERSAVE=y
 # CONFIG_DEVFREQ_GOV_USERSPACE is not set
+#CONFIG_DEVFREQ_GOV_CPUFREQ=y
 CONFIG_DEVFREQ_GOV_MSM_ADRENO_TZ=y
-CONFIG_DEVFREQ_GOV_MSM_CPUFREQ=y
-CONFIG_DEVFREQ_GOV_MSM_CPUBW_HWMON=y
+CONFIG_MSM_BIMC_BWMON=y
+CONFIG_DEVFREQ_GOV_MSM_BW_HWMON=y
+CONFIG_DEVFREQ_GOV_MSM_CACHE_HWMON=y
+
 
 #
 # DEVFREQ Drivers
diff --git arch/arm/configs/cyanogenmod_d851_oxavelar_defconfig arch/arm/configs/cyanogenmod_d851_oxavelar_defconfig
index e173e97..141a6ef 100644
--- arch/arm/configs/cyanogenmod_d851_oxavelar_defconfig
+++ arch/arm/configs/cyanogenmod_d851_oxavelar_defconfig
@@ -2985,9 +2985,12 @@ CONFIG_DEVFREQ_GOV_SIMPLE_ONDEMAND=y
 CONFIG_DEVFREQ_GOV_PERFORMANCE=y
 CONFIG_DEVFREQ_GOV_POWERSAVE=y
 # CONFIG_DEVFREQ_GOV_USERSPACE is not set
+#CONFIG_DEVFREQ_GOV_CPUFREQ=y
 CONFIG_DEVFREQ_GOV_MSM_ADRENO_TZ=y
-CONFIG_DEVFREQ_GOV_MSM_CPUFREQ=y
-CONFIG_DEVFREQ_GOV_MSM_CPUBW_HWMON=y
+CONFIG_MSM_BIMC_BWMON=y
+CONFIG_DEVFREQ_GOV_MSM_BW_HWMON=y
+CONFIG_DEVFREQ_GOV_MSM_CACHE_HWMON=y
+
 
 #
 # DEVFREQ Drivers
diff --git arch/arm/configs/cyanogenmod_d855_oxavelar_defconfig arch/arm/configs/cyanogenmod_d855_oxavelar_defconfig
index 8e39963..9f2fab5 100644
--- arch/arm/configs/cyanogenmod_d855_oxavelar_defconfig
+++ arch/arm/configs/cyanogenmod_d855_oxavelar_defconfig
@@ -2971,9 +2971,11 @@ CONFIG_DEVFREQ_GOV_SIMPLE_ONDEMAND=y
 CONFIG_DEVFREQ_GOV_PERFORMANCE=y
 CONFIG_DEVFREQ_GOV_POWERSAVE=y
 # CONFIG_DEVFREQ_GOV_USERSPACE is not set
+#CONFIG_DEVFREQ_GOV_CPUFREQ=y
 CONFIG_DEVFREQ_GOV_MSM_ADRENO_TZ=y
-CONFIG_DEVFREQ_GOV_MSM_CPUFREQ=y
-CONFIG_DEVFREQ_GOV_MSM_CPUBW_HWMON=y
+CONFIG_MSM_BIMC_BWMON=y
+CONFIG_DEVFREQ_GOV_MSM_BW_HWMON=y
+CONFIG_DEVFREQ_GOV_MSM_CACHE_HWMON=y
 
 #
 # DEVFREQ Drivers
diff --git arch/arm/mach-davinci/cpufreq.c arch/arm/mach-davinci/cpufreq.c
index 031048f..4fa03d7 100644
--- arch/arm/mach-davinci/cpufreq.c
+++ arch/arm/mach-davinci/cpufreq.c
@@ -90,7 +90,6 @@ static int davinci_target(struct cpufreq_policy *policy,
 
 	freqs.old = davinci_getspeed(0);
 	freqs.new = clk_round_rate(armclk, target_freq * 1000) / 1000;
-	freqs.cpu = 0;
 
 	if (freqs.old == freqs.new)
 		return ret;
@@ -102,7 +101,7 @@ static int davinci_target(struct cpufreq_policy *policy,
 	if (ret)
 		return -EINVAL;
 
-	cpufreq_notify_transition(&freqs, CPUFREQ_PRECHANGE);
+	cpufreq_notify_transition(policy, &freqs, CPUFREQ_PRECHANGE);
 
 	/* if moving to higher frequency, up the voltage beforehand */
 	if (pdata->set_voltage && freqs.new > freqs.old) {
@@ -126,7 +125,7 @@ static int davinci_target(struct cpufreq_policy *policy,
 		pdata->set_voltage(idx);
 
 out:
-	cpufreq_notify_transition(&freqs, CPUFREQ_POSTCHANGE);
+	cpufreq_notify_transition(policy, &freqs, CPUFREQ_POSTCHANGE);
 
 	return ret;
 }
diff --git arch/arm/mach-integrator/cpu.c arch/arm/mach-integrator/cpu.c
index fbb4577..aaad77f 100644
--- arch/arm/mach-integrator/cpu.c
+++ arch/arm/mach-integrator/cpu.c
@@ -123,14 +123,12 @@ static int integrator_set_target(struct cpufreq_policy *policy,
 	vco = icst_hz_to_vco(&cclk_params, target_freq * 1000);
 	freqs.new = icst_hz(&cclk_params, vco) / 1000;
 
-	freqs.cpu = policy->cpu;
-
 	if (freqs.old == freqs.new) {
 		set_cpus_allowed(current, cpus_allowed);
 		return 0;
 	}
 
-	cpufreq_notify_transition(&freqs, CPUFREQ_PRECHANGE);
+	cpufreq_notify_transition(policy, &freqs, CPUFREQ_PRECHANGE);
 
 	cm_osc = __raw_readl(CM_OSC);
 
@@ -151,7 +149,7 @@ static int integrator_set_target(struct cpufreq_policy *policy,
 	 */
 	set_cpus_allowed(current, cpus_allowed);
 
-	cpufreq_notify_transition(&freqs, CPUFREQ_POSTCHANGE);
+	cpufreq_notify_transition(policy, &freqs, CPUFREQ_POSTCHANGE);
 
 	return 0;
 }
diff --git arch/arm/mach-msm/Kconfig arch/arm/mach-msm/Kconfig
index fd4ab41..6a5e705 100644
--- arch/arm/mach-msm/Kconfig
+++ arch/arm/mach-msm/Kconfig
@@ -262,7 +262,8 @@ config ARCH_MSM8974
 	select MULTI_IRQ_HANDLER
 	select MSM_MULTIMEDIA_USE_ION
 	select PM_DEVFREQ
-	select MSM_DEVFREQ_CPUBW
+	select MSM_DEVFREQ_DEVBW
+	select DEVFREQ_SIMPLE_DEV
 	select MSM_PIL
 	select MSM_SPM_V2
 	select MSM_L2_SPM
@@ -312,7 +313,8 @@ config ARCH_APQ8084
 	select MSM_L2_SPM
 	select MSM_RPM_SMD
 	select PM_DEVFREQ
-	select MSM_DEVFREQ_CPUBW
+	select MSM_DEVFREQ_DEVBW
+	select DEVFREQ_SIMPLE_DEV
 	select ENABLE_VMALLOC_SAVINGS
 
 config ARCH_MPQ8092
@@ -339,6 +341,8 @@ config ARCH_FSM9900
 	select MSM_GPIOMUX
 	select MULTI_IRQ_HANDLER
 	select PM_DEVFREQ
+	select MSM_DEVFREQ_DEVBW
+	select DEVFREQ_SIMPLE_DEV
 	select MSM_PIL
 	select MSM_NATIVE_RESTART
 	select MSM_RESTART_V2
@@ -417,6 +421,8 @@ config ARCH_MSM9625
 	select CPU_FREQ_MSM
 	select MSM_MULTIMEDIA_USE_ION
 	select MSM_RPM_STATS_LOG
+	select PM_DEVFREQ
+	select MSM_DEVFREQ_DEVBW
 	select MSM_QDSP6_APRV2
 	select MSM_QDSP6V2_CODECS
 	select MSM_AUDIO_QDSP6V2 if SND_SOC
@@ -474,7 +480,7 @@ config ARCH_MSM8610
 	select CPU_FREQ_MSM
 	select CPU_FREQ
 	select PM_DEVFREQ
-	select MSM_DEVFREQ_CPUBW
+	select MSM_DEVFREQ_DEVBW
 	select MSM_PIL
 	select MSM_RUN_QUEUE_STATS
 	select ARM_HAS_SG_CHAIN
@@ -516,7 +522,7 @@ config ARCH_MSM8226
 	select CPU_FREQ_MSM
 	select CPU_FREQ
 	select PM_DEVFREQ
-	select MSM_DEVFREQ_CPUBW
+	select MSM_DEVFREQ_DEVBW
 	select MSM_PIL
 	select MSM_RUN_QUEUE_STATS
 	select ARM_HAS_SG_CHAIN
@@ -588,7 +594,8 @@ config  ARCH_MSM_SCORPION
 config  ARCH_MSM_KRAIT
 	bool
 	select ARM_L1_CACHE_SHIFT_6
-	select DEVFREQ_GOV_MSM_CPUBW_HWMON
+	select DEVFREQ_GOV_MSM_BW_HWMON
+	select DEVFREQ_GOV_MSM_CACHE_HWMON
 
 config  MSM_CORTEX_A7
 	bool
@@ -1879,20 +1886,6 @@ config CPU_VOLTAGE_TABLE
 	help
 	  Krait User Voltage Control. Sysfs can be used to override.
 
-config MSM_DEVFREQ_CPUBW
-	bool "Devfreq device for CPU<->DDR IB/AB BW voting"
-	depends on PM_DEVFREQ
-	select DEVFREQ_GOV_PERFORMANCE
-	select DEVFREQ_GOV_POWERSAVE
-	select DEVFREQ_GOV_USERSPACE
-	select DEVFREQ_GOV_MSM_CPUFREQ
-	default n
-	help
-	  Different devfreq governors use this devfreq device to make CPU to
-	  DDR IB/AB bandwidth votes. This driver provides a SoC topology
-	  agnostic interface to so that some of the devfreq governors can be
-	  shared across SoCs.
-
 config MSM_AVS_HW
 	bool "Enable Adaptive Voltage Scaling (AVS)"
 	default n
diff --git arch/arm/mach-msm/Makefile arch/arm/mach-msm/Makefile
index 6f1a360..b6ec3a0 100755
--- arch/arm/mach-msm/Makefile
+++ arch/arm/mach-msm/Makefile
@@ -417,7 +417,6 @@ obj-$(CONFIG_MSM_CPU_PWRCTL) +=  msm_cpu_pwrctl.o
 obj-$(CONFIG_ARCH_MSM8974) += msm_mpmctr.o
 obj-$(CONFIG_MSM_CPR_REGULATOR) += cpr-regulator.o
 obj-$(CONFIG_CPU_FREQ_MSM) += cpufreq.o
-obj-$(CONFIG_MSM_DEVFREQ_CPUBW) += devfreq_cpubw.o
 
 obj-$(CONFIG_WALL_CLK) += wallclk.o
 obj-$(CONFIG_WALL_CLK_SYSFS) += wallclk_sysfs.o
diff --git arch/arm/mach-msm/clock-a7.c arch/arm/mach-msm/clock-a7.c
index a610a23..89b70de 100644
--- arch/arm/mach-msm/clock-a7.c
+++ arch/arm/mach-msm/clock-a7.c
@@ -18,6 +18,7 @@
 #include <linux/io.h>
 #include <linux/err.h>
 #include <linux/clk.h>
+#include <linux/cpu.h>
 #include <linux/mutex.h>
 #include <linux/delay.h>
 #include <linux/platform_device.h>
@@ -154,6 +155,9 @@ static struct mux_div_clk a7ssmux = {
 static struct clk_lookup clock_tbl_a7[] = {
 	CLK_LOOKUP("cpu0_clk",	a7ssmux.c, "0.qcom,msm-cpufreq"),
 	CLK_LOOKUP("cpu0_clk",	a7ssmux.c, "fe805664.qcom,pm-8x60"),
+	CLK_LOOKUP("cpu1_clk",	a7ssmux.c, "0.qcom,msm-cpufreq"),
+	CLK_LOOKUP("cpu2_clk",	a7ssmux.c, "0.qcom,msm-cpufreq"),
+	CLK_LOOKUP("cpu3_clk",	a7ssmux.c, "0.qcom,msm-cpufreq"),
 };
 
 static int of_get_fmax_vdd_class(struct platform_device *pdev, struct clk *c,
@@ -292,7 +296,7 @@ static int of_get_clk_src(struct platform_device *pdev, struct clk_src *parents)
 static int clock_a7_probe(struct platform_device *pdev)
 {
 	struct resource *res;
-	int speed_bin = 0, version = 0, rc;
+	int speed_bin = 0, version = 0, rc, cpu;
 	unsigned long rate, aux_rate;
 	struct clk *aux_clk, *main_pll;
 	char prop_name[] = "qcom,speedX-bin-vX";
@@ -361,8 +365,11 @@ static int clock_a7_probe(struct platform_device *pdev)
 	 * that the clocks have already been prepared and enabled by the time
 	 * they take over.
 	 */
-	WARN(clk_prepare_enable(&a7ssmux.c),
-		"Unable to turn on CPU clock");
+	get_online_cpus();
+	for_each_online_cpu(cpu)
+		WARN(clk_prepare_enable(&a7ssmux.c),
+			"Unable to turn on CPU clock");
+	put_online_cpus();
 	return 0;
 }
 
@@ -383,4 +390,4 @@ static int __init clock_a7_init(void)
 {
 	return platform_driver_probe(&clock_a7_driver, clock_a7_probe);
 }
-device_initcall(clock_a7_init);
+arch_initcall(clock_a7_init);
diff --git arch/arm/mach-msm/clock-krait-8974.c arch/arm/mach-msm/clock-krait-8974.c
index def674b..d6c80e3 100644
--- arch/arm/mach-msm/clock-krait-8974.c
+++ arch/arm/mach-msm/clock-krait-8974.c
@@ -398,6 +398,7 @@ static struct clk_lookup kpss_clocks_8974[] = {
 	CLK_LOOKUP("",	krait2_pri_mux_clk.c,		""),
 	CLK_LOOKUP("",	krait3_pri_mux_clk.c,		""),
 	CLK_LOOKUP("",	l2_pri_mux_clk.c,		""),
+	CLK_LOOKUP("l2_clk",	l2_clk.c,	  "0.qcom,cache"),
 	CLK_LOOKUP("l2_clk",	l2_clk.c,     "0.qcom,msm-cpufreq"),
 	CLK_LOOKUP("cpu0_clk",	krait0_clk.c, "0.qcom,msm-cpufreq"),
 	CLK_LOOKUP("cpu1_clk",	krait1_clk.c, "0.qcom,msm-cpufreq"),
@@ -894,7 +895,7 @@ static int __init clock_krait_8974_init(void)
 {
 	return platform_driver_register(&clock_krait_8974_driver);
 }
-module_init(clock_krait_8974_init);
+arch_initcall(clock_krait_8974_init);
 
 static void __exit clock_krait_8974_exit(void)
 {
diff --git arch/arm/mach-msm/cpufreq.c arch/arm/mach-msm/cpufreq.c
index fca2993..2b7abf7 100644
--- arch/arm/mach-msm/cpufreq.c
+++ arch/arm/mach-msm/cpufreq.c
@@ -3,7 +3,7 @@
  * MSM architecture cpufreq driver
  *
  * Copyright (C) 2007 Google, Inc.
- * Copyright (c) 2007-2013, The Linux Foundation. All rights reserved.
+ * Copyright (c) 2007-2014, The Linux Foundation. All rights reserved.
  * Author: Mike A. Chan <mikechan@google.com>
  *
  * This software is licensed under the terms of the GNU General Public
@@ -17,58 +17,26 @@
  *
  */
 
-#include <linux/earlysuspend.h>
 #include <linux/init.h>
 #include <linux/module.h>
 #include <linux/cpufreq.h>
-#include <linux/workqueue.h>
-#include <linux/completion.h>
 #include <linux/cpu.h>
 #include <linux/cpumask.h>
 #include <linux/sched.h>
+#include <linux/slab.h>
 #include <linux/suspend.h>
 #include <linux/clk.h>
 #include <linux/err.h>
 #include <linux/platform_device.h>
+#include <linux/of.h>
 #include <trace/events/power.h>
-#include <mach/socinfo.h>
-#include <mach/cpufreq.h>
-
-#include "acpuclock.h"
-
-#ifdef CONFIG_DEBUG_FS
-#include <linux/debugfs.h>
-#include <linux/seq_file.h>
-#include <asm/div64.h>
-#endif
-#ifdef CONFIG_LGE_PM_BATTERY_ID_CHECKER
-#include <linux/power/lge_battery_id.h>
-#include <mach/msm_smsm.h>
-#endif
 
 static DEFINE_MUTEX(l2bw_lock);
 
 static struct clk *cpu_clk[NR_CPUS];
 static struct clk *l2_clk;
-static unsigned int freq_index[NR_CPUS];
-static unsigned int max_freq_index;
-static struct cpufreq_frequency_table *freq_table;
-static unsigned int *l2_khz;
-static bool is_clk;
-static bool is_sync;
-static unsigned long *mem_bw;
-
-struct cpufreq_work_struct {
-	struct work_struct work;
-	struct cpufreq_policy *policy;
-	struct completion complete;
-	int frequency;
-	unsigned int index;
-	int status;
-};
-
-static DEFINE_PER_CPU(struct cpufreq_work_struct, cpufreq_work);
-static struct workqueue_struct *msm_cpufreq_wq;
+static DEFINE_PER_CPU(struct cpufreq_frequency_table *, freq_table);
+static bool hotplug_ready;
 
 struct cpufreq_suspend_t {
 	struct mutex suspend_mutex;
@@ -77,41 +45,6 @@ struct cpufreq_suspend_t {
 
 static DEFINE_PER_CPU(struct cpufreq_suspend_t, cpufreq_suspend);
 
-unsigned long msm_cpufreq_get_bw(void)
-{
-	return mem_bw[max_freq_index];
-}
-
-static void update_l2_bw(int *also_cpu)
-{
-	int rc = 0, cpu;
-	unsigned int index = 0;
-
-	mutex_lock(&l2bw_lock);
-
-	if (also_cpu)
-		index = freq_index[*also_cpu];
-
-	for_each_online_cpu(cpu) {
-		index = max(index, freq_index[cpu]);
-	}
-
-	if (l2_clk)
-		rc = clk_set_rate(l2_clk, l2_khz[index] * 1000);
-	if (rc) {
-		pr_err("Error setting L2 clock rate!\n");
-		goto out;
-	}
-
-	max_freq_index = index;
-	rc = devfreq_msm_cpufreq_update_bw();
-	if (rc)
-		pr_err("Unable to update BW (%d)\n", rc);
-
-out:
-	mutex_unlock(&l2bw_lock);
-}
-
 static int set_cpu_freq(struct cpufreq_policy *policy, unsigned int new_freq,
 			unsigned int index)
 {
@@ -120,6 +53,7 @@ static int set_cpu_freq(struct cpufreq_policy *policy, unsigned int new_freq,
 	int saved_sched_rt_prio = -EINVAL;
 	struct cpufreq_freqs freqs;
 	struct sched_param param = { .sched_priority = MAX_RT_PRIO-1 };
+	unsigned long rate;
 
 	freqs.old = policy->cur;
 	freqs.new = new_freq;
@@ -127,7 +61,7 @@ static int set_cpu_freq(struct cpufreq_policy *policy, unsigned int new_freq,
 
 	/*
 	 * Put the caller into SCHED_FIFO priority to avoid cpu starvation
-	 * in the acpuclk_set_rate path while increasing frequencies
+	 * while increasing frequencies
 	 */
 
 	if (freqs.new > freqs.old && current->policy != SCHED_FIFO) {
@@ -136,24 +70,16 @@ static int set_cpu_freq(struct cpufreq_policy *policy, unsigned int new_freq,
 		sched_setscheduler_nocheck(current, SCHED_FIFO, &param);
 	}
 
-	cpufreq_notify_transition(&freqs, CPUFREQ_PRECHANGE);
+	cpufreq_notify_transition(policy, &freqs, CPUFREQ_PRECHANGE);
 
 	trace_cpu_frequency_switch_start(freqs.old, freqs.new, policy->cpu);
-	if (is_clk) {
-		unsigned long rate = new_freq * 1000;
-		rate = clk_round_rate(cpu_clk[policy->cpu], rate);
-		ret = clk_set_rate(cpu_clk[policy->cpu], rate);
-		if (!ret) {
-			freq_index[policy->cpu] = index;
-			update_l2_bw(NULL);
-		}
-	} else {
-		ret = acpuclk_set_rate(policy->cpu, new_freq, SETRATE_CPUFREQ);
-	}
 
+	rate = new_freq * 1000;
+	rate = clk_round_rate(cpu_clk[policy->cpu], rate);
+	ret = clk_set_rate(cpu_clk[policy->cpu], rate);
 	if (!ret) {
+		cpufreq_notify_transition(policy, &freqs, CPUFREQ_POSTCHANGE);
 		trace_cpu_frequency_switch_end(policy->cpu);
-		cpufreq_notify_transition(&freqs, CPUFREQ_POSTCHANGE);
 	}
 
 	/* Restore priority after clock ramp-up */
@@ -164,16 +90,6 @@ static int set_cpu_freq(struct cpufreq_policy *policy, unsigned int new_freq,
 	return ret;
 }
 
-static void set_cpu_work(struct work_struct *work)
-{
-	struct cpufreq_work_struct *cpu_work =
-		container_of(work, struct cpufreq_work_struct, work);
-
-	cpu_work->status = set_cpu_freq(cpu_work->policy, cpu_work->frequency,
-					cpu_work->index);
-	complete(&cpu_work->complete);
-}
-
 static int msm_cpufreq_target(struct cpufreq_policy *policy,
 				unsigned int target_freq,
 				unsigned int relation)
@@ -182,8 +98,6 @@ static int msm_cpufreq_target(struct cpufreq_policy *policy,
 	int index;
 	struct cpufreq_frequency_table *table;
 
-	struct cpufreq_work_struct *cpu_work = NULL;
-
 	mutex_lock(&per_cpu(cpufreq_suspend, policy->cpu).suspend_mutex);
 
 	if (per_cpu(cpufreq_suspend, policy->cpu).device_suspended) {
@@ -205,19 +119,8 @@ static int msm_cpufreq_target(struct cpufreq_policy *policy,
 		policy->cpu, target_freq, relation,
 		policy->min, policy->max, table[index].frequency);
 
-	cpu_work = &per_cpu(cpufreq_work, policy->cpu);
-	cpu_work->policy = policy;
-	cpu_work->frequency = table[index].frequency;
-	cpu_work->index = table[index].index;
-	cpu_work->status = -ENODEV;
-
-	cancel_work_sync(&cpu_work->work);
-	INIT_COMPLETION(cpu_work->complete);
-	queue_work_on(policy->cpu, msm_cpufreq_wq, &cpu_work->work);
-	wait_for_completion(&cpu_work->complete);
-
-	ret = cpu_work->status;
-
+	ret = set_cpu_freq(policy, table[index].frequency,
+			   table[index].index);
 done:
 	mutex_unlock(&per_cpu(cpufreq_suspend, policy->cpu).suspend_mutex);
 	return ret;
@@ -232,58 +135,32 @@ static int msm_cpufreq_verify(struct cpufreq_policy *policy)
 
 static unsigned int msm_cpufreq_get_freq(unsigned int cpu)
 {
-	if (is_clk && is_sync)
-		cpu = 0;
-
-	if (is_clk)
-		return clk_get_rate(cpu_clk[cpu]) / 1000;
-
-	return acpuclk_get_rate(cpu);
+	return clk_get_rate(cpu_clk[cpu]) / 1000;
 }
 
-static int __cpuinit msm_cpufreq_init(struct cpufreq_policy *policy)
+static int msm_cpufreq_init(struct cpufreq_policy *policy)
 {
 	int cur_freq;
 	int index;
 	int ret = 0;
-	struct cpufreq_frequency_table *table;
-	struct cpufreq_work_struct *cpu_work = NULL;
+	struct cpufreq_frequency_table *table =
+			per_cpu(freq_table, policy->cpu);
+	int cpu;
 
-	table = cpufreq_frequency_get_table(policy->cpu);
-	if (table == NULL)
-		return -ENODEV;
 	/*
-	 * In 8625, 8610, and 8226 both cpu core's frequency can not
-	 * be changed independently. Each cpu is bound to
-	 * same frequency. Hence set the cpumask to all cpu.
+	 * In some SoC, some cores are clocked by same source, and their
+	 * frequencies can not be changed independently. Find all other
+	 * CPUs that share same clock, and mark them as controlled by
+	 * same policy.
 	 */
-	if (cpu_is_msm8625() || cpu_is_msm8625q() || cpu_is_msm8226()
-		|| cpu_is_msm8610() || (is_clk && is_sync))
-		cpumask_setall(policy->cpus);
-
-	cpu_work = &per_cpu(cpufreq_work, policy->cpu);
-	INIT_WORK(&cpu_work->work, set_cpu_work);
-	init_completion(&cpu_work->complete);
+	for_each_possible_cpu(cpu)
+		if (cpu_clk[cpu] == cpu_clk[policy->cpu])
+			cpumask_set_cpu(cpu, policy->cpus);
 
-	/* synchronous cpus share the same policy */
-	if (is_clk && !cpu_clk[policy->cpu])
-		return 0;
-
-	if (cpufreq_frequency_table_cpuinfo(policy, table)) {
-#ifdef CONFIG_MSM_CPU_FREQ_SET_MIN_MAX
-		policy->cpuinfo.min_freq = CONFIG_MSM_CPU_FREQ_MIN;
-		policy->cpuinfo.max_freq = CONFIG_MSM_CPU_FREQ_MAX;
-#endif
-	}
-#ifdef CONFIG_MSM_CPU_FREQ_SET_MIN_MAX
-	policy->min = CONFIG_MSM_CPU_FREQ_MIN;
-	policy->max = CONFIG_MSM_CPU_FREQ_MAX;
-#endif
+	if (cpufreq_frequency_table_cpuinfo(policy, table))
+		pr_err("cpufreq: failed to get policy min/max\n");
 
-	if (is_clk)
-		cur_freq = clk_get_rate(cpu_clk[policy->cpu])/1000;
-	else
-		cur_freq = acpuclk_get_rate(policy->cpu);
+	cur_freq = clk_get_rate(cpu_clk[policy->cpu])/1000;
 
 	if (cpufreq_frequency_table_target(policy, table, cur_freq,
 	    CPUFREQ_RELATION_H, &index) &&
@@ -297,76 +174,68 @@ static int __cpuinit msm_cpufreq_init(struct cpufreq_policy *policy)
 	 * Call set_cpu_freq unconditionally so that when cpu is set to
 	 * online, frequency limit will always be updated.
 	 */
-	ret = set_cpu_freq(policy, table[index].frequency, table[index].index);
+	ret = set_cpu_freq(policy, table[index].frequency,
+			   table[index].index);
 	if (ret)
 		return ret;
 	pr_debug("cpufreq: cpu%d init at %d switching to %d\n",
 			policy->cpu, cur_freq, table[index].frequency);
 	policy->cur = table[index].frequency;
-
-	policy->cpuinfo.transition_latency =
-		acpuclk_get_switch_time() * NSEC_PER_USEC;
+	cpufreq_frequency_table_get_attr(table, policy->cpu);
 
 	return 0;
 }
 
-static int __cpuinit msm_cpufreq_cpu_callback(struct notifier_block *nfb,
+static int msm_cpufreq_cpu_callback(struct notifier_block *nfb,
 		unsigned long action, void *hcpu)
 {
 	unsigned int cpu = (unsigned long)hcpu;
 	int rc;
 
+	/* Fail hotplug until this driver can get CPU clocks */
+	if (!hotplug_ready)
+		return NOTIFY_BAD;
+
 	switch (action & ~CPU_TASKS_FROZEN) {
-	case CPU_ONLINE:
-		per_cpu(cpufreq_suspend, cpu).device_suspended = 0;
-		break;
-	case CPU_DOWN_PREPARE:
-		mutex_lock(&per_cpu(cpufreq_suspend, cpu).suspend_mutex);
-		per_cpu(cpufreq_suspend, cpu).device_suspended = 1;
-		mutex_unlock(&per_cpu(cpufreq_suspend, cpu).suspend_mutex);
-		break;
-	case CPU_DOWN_FAILED:
-		per_cpu(cpufreq_suspend, cpu).device_suspended = 0;
+
+	case CPU_DYING:
+		clk_disable(cpu_clk[cpu]);
+		clk_disable(l2_clk);
 		break;
 	/*
 	 * Scale down clock/power of CPU that is dead and scale it back up
 	 * before the CPU is brought up.
 	 */
 	case CPU_DEAD:
-		if (is_clk) {
-			clk_disable_unprepare(cpu_clk[cpu]);
-			clk_disable_unprepare(l2_clk);
-			update_l2_bw(NULL);
-		}
+		clk_unprepare(cpu_clk[cpu]);
+		clk_unprepare(l2_clk);
 		break;
 	case CPU_UP_CANCELED:
-		if (is_clk) {
-			clk_unprepare(cpu_clk[cpu]);
-			clk_unprepare(l2_clk);
-			update_l2_bw(NULL);
-		}
+		clk_unprepare(cpu_clk[cpu]);
+		clk_unprepare(l2_clk);
 		break;
 	case CPU_UP_PREPARE:
-		if (is_clk) {
-			rc = clk_prepare(l2_clk);
-			if (rc < 0)
-				return NOTIFY_BAD;
-			rc = clk_prepare(cpu_clk[cpu]);
-			if (rc < 0)
-				return NOTIFY_BAD;
-			update_l2_bw(&cpu);
+		rc = clk_prepare(l2_clk);
+		if (rc < 0)
+			return NOTIFY_BAD;
+		rc = clk_prepare(cpu_clk[cpu]);
+		if (rc < 0) {
+			clk_unprepare(l2_clk);
+			return NOTIFY_BAD;
 		}
 		break;
+
 	case CPU_STARTING:
-		if (is_clk) {
-			rc = clk_enable(l2_clk);
-			if (rc < 0)
-				return NOTIFY_BAD;
-			rc = clk_enable(cpu_clk[cpu]);
-			if (rc < 0)
-				return NOTIFY_BAD;
+		rc = clk_enable(l2_clk);
+		if (rc < 0)
+			return NOTIFY_BAD;
+		rc = clk_enable(cpu_clk[cpu]);
+		if (rc) {
+			clk_disable(l2_clk);
+			return NOTIFY_BAD;
 		}
 		break;
+
 	default:
 		break;
 	}
@@ -378,24 +247,20 @@ static struct notifier_block __refdata msm_cpufreq_cpu_notifier = {
 	.notifier_call = msm_cpufreq_cpu_callback,
 };
 
-/*
- * Define suspend/resume for cpufreq_driver. Kernel will call
- * these during suspend/resume with interrupts disabled. This
- * helps the suspend/resume variable get's updated before cpufreq
- * governor tries to change the frequency after coming out of suspend.
- */
-static int msm_cpufreq_suspend(struct cpufreq_policy *policy)
+static int msm_cpufreq_suspend(void)
 {
 	int cpu;
 
 	for_each_possible_cpu(cpu) {
+		mutex_lock(&per_cpu(cpufreq_suspend, cpu).suspend_mutex);
 		per_cpu(cpufreq_suspend, cpu).device_suspended = 1;
+		mutex_unlock(&per_cpu(cpufreq_suspend, cpu).suspend_mutex);
 	}
 
-	return 0;
+	return NOTIFY_DONE;
 }
 
-static int msm_cpufreq_resume(struct cpufreq_policy *policy)
+static int msm_cpufreq_resume(void)
 {
 	int cpu;
 
@@ -403,9 +268,28 @@ static int msm_cpufreq_resume(struct cpufreq_policy *policy)
 		per_cpu(cpufreq_suspend, cpu).device_suspended = 0;
 	}
 
-	return 0;
+	return NOTIFY_DONE;
 }
 
+static int msm_cpufreq_pm_event(struct notifier_block *this,
+				unsigned long event, void *ptr)
+{
+	switch (event) {
+	case PM_POST_HIBERNATION:
+	case PM_POST_SUSPEND:
+		return msm_cpufreq_resume();
+	case PM_HIBERNATION_PREPARE:
+	case PM_SUSPEND_PREPARE:
+		return msm_cpufreq_suspend();
+	default:
+		return NOTIFY_DONE;
+	}
+}
+
+static struct notifier_block msm_cpufreq_pm_notifier = {
+	.notifier_call = msm_cpufreq_pm_event,
+};
+
 static struct freq_attr *msm_freq_attr[] = {
 	&cpufreq_freq_attr_scaling_available_freqs,
 	NULL,
@@ -418,81 +302,41 @@ static struct cpufreq_driver msm_cpufreq_driver = {
 	.verify		= msm_cpufreq_verify,
 	.target		= msm_cpufreq_target,
 	.get		= msm_cpufreq_get_freq,
-	.suspend	= msm_cpufreq_suspend,
-	.resume		= msm_cpufreq_resume,
 	.name		= "msm",
 	.attr		= msm_freq_attr,
 };
 
-#define PROP_TBL "qcom,cpufreq-table"
-static int cpufreq_parse_dt(struct device *dev)
+static struct cpufreq_frequency_table *cpufreq_parse_dt(struct device *dev,
+						char *tbl_name, int cpu)
 {
-	int ret, len, nf, num_cols = 2, i, j;
+	int ret, nf, i;
 	u32 *data;
-#ifdef CONFIG_LGE_PM_BATTERY_ID_CHECKER
-	uint *smem_batt = 0;
-	int IsBattery = 0;
-#endif
-
-	if (l2_clk)
-		num_cols++;
-#ifdef CONFIG_LGE_PM_BATTERY_ID_CHECKER
-	smem_batt = (uint *)smem_alloc(SMEM_BATT_INFO, sizeof(smem_batt));
-	if (smem_batt == NULL) {
-		pr_err("%s : smem_alloc returns NULL\n",__func__);
-	}
-	else {
-		pr_err("Batt ID from SBL = %d\n", *smem_batt);
-		if (*smem_batt == BATT_ID_DS2704_L ||
-			*smem_batt == BATT_ID_DS2704_C ||
-			*smem_batt == BATT_ID_ISL6296_L ||
-			*smem_batt == BATT_ID_ISL6296_C) {
-			//To Do if Battery is present
-			IsBattery = 1;
-		}
-		else {
-			//To Do if Battery is absent
-			IsBattery = 0;
-		}
-	}
-#endif
+	struct cpufreq_frequency_table *ftbl;
 
-	/* Parse CPU freq -> L2/Mem BW map table. */
-	if (!of_find_property(dev->of_node, PROP_TBL, &len))
-		return -EINVAL;
-	len /= sizeof(*data);
+	/* Parse list of usable CPU frequencies. */
+	if (!of_find_property(dev->of_node, tbl_name, &nf))
+		return ERR_PTR(-EINVAL);
+	nf /= sizeof(*data);
 
-	if (len % num_cols || len == 0)
-		return -EINVAL;
-	nf = len / num_cols;
+	if (nf == 0)
+		return ERR_PTR(-EINVAL);
 
-	data = devm_kzalloc(dev, len * sizeof(*data), GFP_KERNEL);
+	data = devm_kzalloc(dev, nf * sizeof(*data), GFP_KERNEL);
 	if (!data)
-		return -ENOMEM;
+		return ERR_PTR(-ENOMEM);
 
-	ret = of_property_read_u32_array(dev->of_node, PROP_TBL, data, len);
+	ret = of_property_read_u32_array(dev->of_node, tbl_name, data, nf);
 	if (ret)
-		return ret;
+		return ERR_PTR(ret);
 
-	/* Allocate all data structures. */
-	freq_table = devm_kzalloc(dev, (nf + 1) * sizeof(*freq_table),
-				  GFP_KERNEL);
-	mem_bw = devm_kzalloc(dev, nf * sizeof(*mem_bw), GFP_KERNEL);
-
-	if (!freq_table || !mem_bw)
-		return -ENOMEM;
-
-	if (l2_clk) {
-		l2_khz = devm_kzalloc(dev, nf * sizeof(*l2_khz), GFP_KERNEL);
-		if (!l2_khz)
-			return -ENOMEM;
-	}
+	ftbl = devm_kzalloc(dev, (nf + 1) * sizeof(*ftbl), GFP_KERNEL);
+	if (!ftbl)
+		return ERR_PTR(-ENOMEM);
 
-	j = 0;
 	for (i = 0; i < nf; i++) {
 		unsigned long f;
 
-		f = clk_round_rate(cpu_clk[0], data[j++] * 1000);
+		f = clk_round_rate(cpu_clk[cpu], data[i] * 1000);
 		if (IS_ERR_VALUE(f))
 			break;
 		f /= 1000;
@@ -512,77 +356,29 @@ static int cpufreq_parse_dt(struct device *dev)
 		 * In this case, we can CPUfreq to use 2.2 GHz and 2.3 GHz
 		 * instead of rejecting the 2.5 GHz table entry.
 		 */
-		if (i > 0 && f <= freq_table[i-1].frequency)
+		if (i > 0 && f <= ftbl[i-1].frequency)
 			break;
 
-		freq_table[i].index = i;
-		freq_table[i].frequency = f;
-
-		if (l2_clk) {
-			f = clk_round_rate(l2_clk, data[j++] * 1000);
-			if (IS_ERR_VALUE(f)) {
-				pr_err("Error finding L2 rate for CPU %d KHz\n",
-					freq_table[i].frequency);
-				freq_table[i].frequency = CPUFREQ_ENTRY_INVALID;
-			} else {
-				f /= 1000;
-				l2_khz[i] = f;
-			}
-		}
-
-		mem_bw[i] = data[j++];
+		ftbl[i].index = i;
+		ftbl[i].frequency = f;
 	}
 
-	freq_table[i].index = i;
-	freq_table[i].frequency = CPUFREQ_TABLE_END;
+	ftbl[i].index = i;
+	ftbl[i].frequency = CPUFREQ_TABLE_END;
 
 	devm_kfree(dev, data);
 
-	return 0;
+	return ftbl;
 }
 
-#ifdef CONFIG_DEBUG_FS
-static int msm_cpufreq_show(struct seq_file *m, void *unused)
-{
-	unsigned int i, cpu_freq;
-
-	if (!freq_table)
-		return 0;
-
-	seq_printf(m, "%10s%10s", "CPU (KHz)", "L2 (KHz)");
-	seq_printf(m, "%12s\n", "Mem (MBps)");
-
-	for (i = 0; freq_table[i].frequency != CPUFREQ_TABLE_END; i++) {
-		cpu_freq = freq_table[i].frequency;
-		if (cpu_freq == CPUFREQ_ENTRY_INVALID)
-			continue;
-		seq_printf(m, "%10d", cpu_freq);
-		seq_printf(m, "%10d", l2_khz ? l2_khz[i] : cpu_freq);
-		seq_printf(m, "%12lu", mem_bw[i]);
-		seq_printf(m, "\n");
-	}
-	return 0;
-}
-
-static int msm_cpufreq_open(struct inode *inode, struct file *file)
-{
-	return single_open(file, msm_cpufreq_show, inode->i_private);
-}
-
-const struct file_operations msm_cpufreq_fops = {
-	.open		= msm_cpufreq_open,
-	.read		= seq_read,
-	.llseek		= seq_lseek,
-	.release	= seq_release,
-};
-#endif
-
 static int __init msm_cpufreq_probe(struct platform_device *pdev)
 {
 	struct device *dev = &pdev->dev;
 	char clk_name[] = "cpu??_clk";
+	char tbl_name[] = "qcom,cpufreq-table-??";
 	struct clk *c;
-	int cpu, ret;
+	int cpu;
+	struct cpufreq_frequency_table *ftbl;
 
 	l2_clk = devm_clk_get(dev, "l2_clk");
 	if (IS_ERR(l2_clk))
@@ -591,36 +387,56 @@ static int __init msm_cpufreq_probe(struct platform_device *pdev)
 	for_each_possible_cpu(cpu) {
 		snprintf(clk_name, sizeof(clk_name), "cpu%d_clk", cpu);
 		c = devm_clk_get(dev, clk_name);
-		if (!IS_ERR(c))
-			cpu_clk[cpu] = c;
-		else
-			is_sync = true;
+		if (IS_ERR(c))
+			return PTR_ERR(c);
+		cpu_clk[cpu] = c;
 	}
+	hotplug_ready = true;
 
-	if (!cpu_clk[0])
-		return -ENODEV;
-
-	ret = cpufreq_parse_dt(dev);
-	if (ret)
-		return ret;
-
-	for_each_possible_cpu(cpu) {
-		cpufreq_frequency_table_get_attr(freq_table, cpu);
+	/* Parse commong cpufreq table for all CPUs */
+	ftbl = cpufreq_parse_dt(dev, "qcom,cpufreq-table", 0);
+	if (!IS_ERR(ftbl)) {
+		for_each_possible_cpu(cpu)
+			per_cpu(freq_table, cpu) = ftbl;
+		return 0;
 	}
 
-	ret = register_devfreq_msm_cpufreq();
-	if (ret) {
-		pr_err("devfreq governor registration failed\n");
-		return ret;
-	}
+	/*
+	 * No common table. Parse individual tables for each unique
+	 * CPU clock.
+	 */
+	for_each_possible_cpu(cpu) {
+		snprintf(tbl_name, sizeof(tbl_name),
+			 "qcom,cpufreq-table-%d", cpu);
+		ftbl = cpufreq_parse_dt(dev, tbl_name, cpu);
+
+		/* CPU0 must contain freq table */
+		if (cpu == 0 && IS_ERR(ftbl)) {
+			dev_err(dev, "Failed to parse CPU0's freq table\n");
+			return PTR_ERR(ftbl);
+		}
+		if (cpu == 0) {
+			per_cpu(freq_table, cpu) = ftbl;
+			continue;
+		}
 
-	is_clk = true;
+		if (cpu_clk[cpu] != cpu_clk[cpu - 1] && IS_ERR(ftbl)) {
+			dev_err(dev, "Failed to parse CPU%d's freq table\n",
+				cpu);
+			return PTR_ERR(ftbl);
+		}
 
-#ifdef CONFIG_DEBUG_FS
-	if (!debugfs_create_file("msm_cpufreq", S_IRUGO, NULL, NULL,
-		&msm_cpufreq_fops))
-		return -ENOMEM;
-#endif
+		/* Use previous CPU's table if it shares same clock */
+		if (cpu_clk[cpu] == cpu_clk[cpu - 1]) {
+			if (!IS_ERR(ftbl)) {
+				dev_warn(dev, "Conflicting tables for CPU%d\n",
+					 cpu);
+				kfree(ftbl);
+			}
+			ftbl = per_cpu(freq_table, cpu - 1);
+		}
+		per_cpu(freq_table, cpu) = ftbl;
+	}
 
 	return 0;
 }
@@ -640,17 +456,32 @@ static struct platform_driver msm_cpufreq_plat_driver = {
 
 static int __init msm_cpufreq_register(void)
 {
-	int cpu;
+	int cpu, rc;
 
 	for_each_possible_cpu(cpu) {
 		mutex_init(&(per_cpu(cpufreq_suspend, cpu).suspend_mutex));
 		per_cpu(cpufreq_suspend, cpu).device_suspended = 0;
 	}
 
-	platform_driver_probe(&msm_cpufreq_plat_driver, msm_cpufreq_probe);
-	msm_cpufreq_wq = alloc_workqueue("msm-cpufreq", WQ_HIGHPRI, 0);
-	register_hotcpu_notifier(&msm_cpufreq_cpu_notifier);
+	rc = platform_driver_probe(&msm_cpufreq_plat_driver,
+				   msm_cpufreq_probe);
+	if (rc < 0) {
+		/* Unblock hotplug if msm-cpufreq probe fails */
+		unregister_hotcpu_notifier(&msm_cpufreq_cpu_notifier);
+		for_each_possible_cpu(cpu)
+			mutex_destroy(&(per_cpu(cpufreq_suspend, cpu).
+					suspend_mutex));
+		return rc;
+	}
+
+	register_pm_notifier(&msm_cpufreq_pm_notifier);
 	return cpufreq_register_driver(&msm_cpufreq_driver);
 }
 
-device_initcall(msm_cpufreq_register);
+subsys_initcall(msm_cpufreq_register);
+
+static int __init msm_cpufreq_early_register(void)
+{
+	return register_hotcpu_notifier(&msm_cpufreq_cpu_notifier);
+}
+core_initcall(msm_cpufreq_early_register);
diff --git arch/arm/mach-msm/devfreq_cpubw.c arch/arm/mach-msm/devfreq_cpubw.c
deleted file mode 100644
index 20cabc2..0000000
--- arch/arm/mach-msm/devfreq_cpubw.c
+++ /dev/null
@@ -1,221 +0,0 @@
-/*
- * Copyright (c) 2013, The Linux Foundation. All rights reserved.
- *
- * This program is free software; you can redistribute it and/or modify
- * it under the terms of the GNU General Public License version 2 and
- * only version 2 as published by the Free Software Foundation.
- *
- * This program is distributed in the hope that it will be useful,
- * but WITHOUT ANY WARRANTY; without even the implied warranty of
- * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
- * GNU General Public License for more details.
- */
-
-#define pr_fmt(fmt) "cpubw: " fmt
-
-#include <linux/kernel.h>
-#include <linux/module.h>
-#include <linux/init.h>
-#include <linux/io.h>
-#include <linux/delay.h>
-#include <linux/ktime.h>
-#include <linux/time.h>
-#include <linux/err.h>
-#include <linux/errno.h>
-#include <linux/mutex.h>
-#include <linux/interrupt.h>
-#include <linux/devfreq.h>
-#include <linux/of.h>
-#include <trace/events/power.h>
-#include <mach/msm_bus.h>
-#include <mach/msm_bus_board.h>
-
-/* Has to be ULL to prevent overflow where this macro is used. */
-#define MBYTE (1ULL << 20)
-#define MAX_PATHS	2
-
-static struct msm_bus_vectors vectors[MAX_PATHS * 2];
-static struct msm_bus_paths bw_levels[] = {
-	{ .vectors = &vectors[0] },
-	{ .vectors = &vectors[MAX_PATHS] },
-};
-static struct msm_bus_scale_pdata bw_data = {
-	.usecase = bw_levels,
-	.num_usecases = ARRAY_SIZE(bw_levels),
-	.name = "devfreq_cpubw",
-	.active_only = 1,
-};
-static int num_paths;
-static u32 bus_client;
-
-static int set_bw(int new_ib, int new_ab)
-{
-	static int cur_idx, cur_ab, cur_ib;
-	int i, ret;
-
-	if (cur_ib == new_ib && cur_ab == new_ab)
-		return 0;
-
-	i = (cur_idx + 1) % ARRAY_SIZE(bw_levels);
-
-	bw_levels[i].vectors[0].ib = new_ib * MBYTE;
-	bw_levels[i].vectors[0].ab = new_ab / num_paths * MBYTE;
-	bw_levels[i].vectors[1].ib = new_ib * MBYTE;
-	bw_levels[i].vectors[1].ab = new_ab / num_paths * MBYTE;
-
-	pr_debug("BW MBps: AB: %d IB: %d\n", new_ab, new_ib);
-
-	ret = msm_bus_scale_client_update_request(bus_client, i);
-	if (ret) {
-		pr_err("bandwidth request failed (%d)\n", ret);
-	} else {
-		cur_idx = i;
-		cur_ib = new_ib;
-		cur_ab = new_ab;
-	}
-
-	return ret;
-}
-
-static void find_freq(struct devfreq_dev_profile *p, unsigned long *freq,
-			u32 flags)
-{
-	int i;
-	unsigned long atmost, atleast, f;
-
-	atmost = p->freq_table[0];
-	atleast = p->freq_table[p->max_state-1];
-	for (i = 0; i < p->max_state; i++) {
-		f = p->freq_table[i];
-		if (f <= *freq)
-			atmost = max(f, atmost);
-		if (f >= *freq)
-			atleast = min(f, atleast);
-	}
-
-	if (flags & DEVFREQ_FLAG_LEAST_UPPER_BOUND)
-		*freq = atmost;
-	else
-		*freq = atleast;
-}
-
-struct devfreq_dev_profile cpubw_profile;
-static long gov_ab;
-
-int cpubw_target(struct device *dev, unsigned long *freq, u32 flags)
-{
-	find_freq(&cpubw_profile, freq, flags);
-	return set_bw(*freq, gov_ab);
-}
-
-static struct devfreq_governor_data gov_data[] = {
-	{ .name = "performance" },
-	{ .name = "powersave" },
-	{ .name = "userspace" },
-	{ .name = "msm_cpufreq" },
-	{ .name = "cpubw_hwmon", .data = &gov_ab },
-};
-
-struct devfreq_dev_profile cpubw_profile = {
-	.polling_ms = 50,
-	.target = cpubw_target,
-	.governor_data = gov_data,
-	.num_governor_data = ARRAY_SIZE(gov_data),
-};
-
-#define PROP_PORTS "qcom,cpu-mem-ports"
-#define PROP_TBL "qcom,bw-tbl"
-
-static int __init cpubw_probe(struct platform_device *pdev)
-{
-	struct device *dev = &pdev->dev;
-	struct devfreq_dev_profile *p = &cpubw_profile;
-	struct devfreq *df;
-	u32 *data, ports[MAX_PATHS * 2];
-	int ret, len, i;
-
-	if (of_find_property(dev->of_node, PROP_PORTS, &len)) {
-		len /= sizeof(ports[0]);
-		if (len % 2 || len > ARRAY_SIZE(ports)) {
-			dev_err(dev, "Unexpected number of ports\n");
-			return -EINVAL;
-		}
-
-		ret = of_property_read_u32_array(dev->of_node, PROP_PORTS,
-						 ports, len);
-		if (ret)
-			return ret;
-
-		num_paths = len / 2;
-	} else {
-		return -EINVAL;
-	}
-
-	for (i = 0; i < num_paths; i++) {
-		bw_levels[0].vectors[i].src = ports[2 * i];
-		bw_levels[0].vectors[i].dst = ports[2 * i + 1];
-		bw_levels[1].vectors[i].src = ports[2 * i];
-		bw_levels[1].vectors[i].dst = ports[2 * i + 1];
-	}
-	bw_levels[0].num_paths = num_paths;
-	bw_levels[1].num_paths = num_paths;
-
-	if (of_find_property(dev->of_node, PROP_TBL, &len)) {
-		len /= sizeof(*data);
-		data = devm_kzalloc(dev, len * sizeof(*data), GFP_KERNEL);
-		if (!data)
-			return -ENOMEM;
-
-		p->freq_table = devm_kzalloc(dev,
-					     len * sizeof(*p->freq_table),
-					     GFP_KERNEL);
-		if (!p->freq_table)
-			return -ENOMEM;
-
-		ret = of_property_read_u32_array(dev->of_node, PROP_TBL,
-						 data, len);
-		if (ret)
-			return ret;
-
-		for (i = 0; i < len; i++)
-			p->freq_table[i] = data[i];
-		p->max_state = len;
-	}
-
-	bus_client = msm_bus_scale_register_client(&bw_data);
-	if (!bus_client) {
-		dev_err(dev, "Unable to register bus client\n");
-		return -ENODEV;
-	}
-
-	df = devfreq_add_device(dev, &cpubw_profile, "msm_cpufreq", NULL);
-	if (IS_ERR(df)) {
-		msm_bus_scale_unregister_client(bus_client);
-		return PTR_ERR(df);
-	}
-
-	return 0;
-}
-
-static struct of_device_id match_table[] = {
-	{ .compatible = "qcom,cpubw" },
-	{}
-};
-
-static struct platform_driver cpubw_driver = {
-	.driver = {
-		.name = "cpubw",
-		.of_match_table = match_table,
-		.owner = THIS_MODULE,
-	},
-};
-
-static int __init cpubw_init(void)
-{
-	platform_driver_probe(&cpubw_driver, cpubw_probe);
-	return 0;
-}
-device_initcall(cpubw_init);
-
-MODULE_DESCRIPTION("CPU DDR bandwidth voting driver MSM CPUs");
-MODULE_LICENSE("GPL v2");
diff --git arch/arm/mach-msm/include/mach/cpufreq.h arch/arm/mach-msm/include/mach/cpufreq.h
deleted file mode 100644
index 46872d7..0000000
--- arch/arm/mach-msm/include/mach/cpufreq.h
+++ /dev/null
@@ -1,39 +0,0 @@
-/*
- * Copyright (c) 2013 The Linux Foundation. All rights reserved.
- *
- * This program is free software; you can redistribute it and/or modify
- * it under the terms of the GNU General Public License version 2 and
- * only version 2 as published by the Free Software Foundation.
- *
- * This program is distributed in the hope that it will be useful,
- * but WITHOUT ANY WARRANTY; without even the implied warranty of
- * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
- * GNU General Public License for more details.
- */
-#ifndef __MACH_CPUFREQ_H
-#define __MACH_CPUFREQ_H
-
-#if defined(CONFIG_DEVFREQ_GOV_MSM_CPUFREQ)
-extern int devfreq_msm_cpufreq_update_bw(void);
-extern int register_devfreq_msm_cpufreq(void);
-#else
-static int devfreq_msm_cpufreq_update_bw(void)
-{
-	return 0;
-}
-static int register_devfreq_msm_cpufreq(void)
-{
-	return 0;
-}
-#endif
-
-#if defined(CONFIG_CPU_FREQ_MSM)
-extern unsigned long msm_cpufreq_get_bw(void);
-#else
-extern unsigned long msm_cpufreq_get_bw(void)
-{
-	return ULONG_MAX;
-}
-#endif
-
-#endif
diff --git arch/arm/mach-pxa/cpufreq-pxa2xx.c arch/arm/mach-pxa/cpufreq-pxa2xx.c
index 6a7aeab..f1ca4da 100644
--- arch/arm/mach-pxa/cpufreq-pxa2xx.c
+++ arch/arm/mach-pxa/cpufreq-pxa2xx.c
@@ -311,7 +311,6 @@ static int pxa_set_target(struct cpufreq_policy *policy,
 	new_freq_mem = pxa_freq_settings[idx].membus;
 	freqs.old = policy->cur;
 	freqs.new = new_freq_cpu;
-	freqs.cpu = policy->cpu;
 
 	if (freq_debug)
 		pr_debug("Changing CPU frequency to %d Mhz, (SDRAM %d Mhz)\n",
@@ -327,7 +326,7 @@ static int pxa_set_target(struct cpufreq_policy *policy,
 	 * you should add a notify client with any platform specific
 	 * Vcc changing capability
 	 */
-	cpufreq_notify_transition(&freqs, CPUFREQ_PRECHANGE);
+	cpufreq_notify_transition(policy, &freqs, CPUFREQ_PRECHANGE);
 
 	/* Calculate the next MDREFR.  If we're slowing down the SDRAM clock
 	 * we need to preset the smaller DRI before the change.	 If we're
@@ -382,7 +381,7 @@ static int pxa_set_target(struct cpufreq_policy *policy,
 	 * you should add a notify client with any platform specific
 	 * SDRAM refresh timer adjustments
 	 */
-	cpufreq_notify_transition(&freqs, CPUFREQ_POSTCHANGE);
+	cpufreq_notify_transition(policy, &freqs, CPUFREQ_POSTCHANGE);
 
 	/*
 	 * Even if voltage setting fails, we don't report it, as the frequency
diff --git arch/arm/mach-pxa/cpufreq-pxa3xx.c arch/arm/mach-pxa/cpufreq-pxa3xx.c
index b85b4ab..8c45b2b 100644
--- arch/arm/mach-pxa/cpufreq-pxa3xx.c
+++ arch/arm/mach-pxa/cpufreq-pxa3xx.c
@@ -184,7 +184,6 @@ static int pxa3xx_cpufreq_set(struct cpufreq_policy *policy,
 
 	freqs.old = policy->cur;
 	freqs.new = next->cpufreq_mhz * 1000;
-	freqs.cpu = policy->cpu;
 
 	pr_debug("CPU frequency from %d MHz to %d MHz%s\n",
 			freqs.old / 1000, freqs.new / 1000,
@@ -193,14 +192,14 @@ static int pxa3xx_cpufreq_set(struct cpufreq_policy *policy,
 	if (freqs.old == target_freq)
 		return 0;
 
-	cpufreq_notify_transition(&freqs, CPUFREQ_PRECHANGE);
+	cpufreq_notify_transition(policy, &freqs, CPUFREQ_PRECHANGE);
 
 	local_irq_save(flags);
 	__update_core_freq(next);
 	__update_bus_freq(next);
 	local_irq_restore(flags);
 
-	cpufreq_notify_transition(&freqs, CPUFREQ_POSTCHANGE);
+	cpufreq_notify_transition(policy, &freqs, CPUFREQ_POSTCHANGE);
 
 	return 0;
 }
diff --git arch/arm/mach-sa1100/cpu-sa1100.c arch/arm/mach-sa1100/cpu-sa1100.c
index 19b2053..3003d2fe 100644
--- arch/arm/mach-sa1100/cpu-sa1100.c
+++ arch/arm/mach-sa1100/cpu-sa1100.c
@@ -200,9 +200,8 @@ static int sa1100_target(struct cpufreq_policy *policy,
 
 	freqs.old = cur;
 	freqs.new = sa11x0_ppcr_to_freq(new_ppcr);
-	freqs.cpu = 0;
 
-	cpufreq_notify_transition(&freqs, CPUFREQ_PRECHANGE);
+	cpufreq_notify_transition(policy, &freqs, CPUFREQ_PRECHANGE);
 
 	if (freqs.new > cur)
 		sa1100_update_dram_timings(cur, freqs.new);
@@ -212,7 +211,7 @@ static int sa1100_target(struct cpufreq_policy *policy,
 	if (freqs.new < cur)
 		sa1100_update_dram_timings(cur, freqs.new);
 
-	cpufreq_notify_transition(&freqs, CPUFREQ_POSTCHANGE);
+	cpufreq_notify_transition(policy, &freqs, CPUFREQ_POSTCHANGE);
 
 	return 0;
 }
diff --git arch/arm/mach-sa1100/cpu-sa1110.c arch/arm/mach-sa1100/cpu-sa1110.c
index 675bf8e..4aa751c 100644
--- arch/arm/mach-sa1100/cpu-sa1110.c
+++ arch/arm/mach-sa1100/cpu-sa1110.c
@@ -257,7 +257,6 @@ static int sa1110_target(struct cpufreq_policy *policy,
 
 	freqs.old = sa11x0_getspeed(0);
 	freqs.new = sa11x0_ppcr_to_freq(ppcr);
-	freqs.cpu = 0;
 
 	sdram_calculate_timing(&sd, freqs.new, sdram);
 
@@ -278,7 +277,7 @@ static int sa1110_target(struct cpufreq_policy *policy,
 	sd.mdcas[2] = 0xaaaaaaaa;
 #endif
 
-	cpufreq_notify_transition(&freqs, CPUFREQ_PRECHANGE);
+	cpufreq_notify_transition(policy, &freqs, CPUFREQ_PRECHANGE);
 
 	/*
 	 * The clock could be going away for some time.  Set the SDRAMs
@@ -326,7 +325,7 @@ static int sa1110_target(struct cpufreq_policy *policy,
 	 */
 	sdram_update_refresh(freqs.new, sdram);
 
-	cpufreq_notify_transition(&freqs, CPUFREQ_POSTCHANGE);
+	cpufreq_notify_transition(policy, &freqs, CPUFREQ_POSTCHANGE);
 
 	return 0;
 }
diff --git arch/arm/mach-tegra/cpu-tegra.c arch/arm/mach-tegra/cpu-tegra.c
index 7a065f0..755b38e 100644
--- arch/arm/mach-tegra/cpu-tegra.c
+++ arch/arm/mach-tegra/cpu-tegra.c
@@ -93,8 +93,7 @@ static int tegra_update_cpu_speed(unsigned long rate)
 	else
 		clk_set_rate(emc_clk, 100000000);  /* emc 50Mhz */
 
-	for_each_online_cpu(freqs.cpu)
-		cpufreq_notify_transition(&freqs, CPUFREQ_PRECHANGE);
+	cpufreq_notify_transition(policy, &freqs, CPUFREQ_PRECHANGE);
 
 #ifdef CONFIG_CPU_FREQ_DEBUG
 	printk(KERN_DEBUG "cpufreq-tegra: transition: %u --> %u\n",
@@ -108,8 +107,7 @@ static int tegra_update_cpu_speed(unsigned long rate)
 		return ret;
 	}
 
-	for_each_online_cpu(freqs.cpu)
-		cpufreq_notify_transition(&freqs, CPUFREQ_POSTCHANGE);
+	cpufreq_notify_transition(policy, &freqs, CPUFREQ_POSTCHANGE);
 
 	return 0;
 }
@@ -146,7 +144,7 @@ static int tegra_target(struct cpufreq_policy *policy,
 
 	target_cpu_speed[policy->cpu] = freq;
 
-	ret = tegra_update_cpu_speed(tegra_cpu_highest_speed());
+	ret = tegra_update_cpu_speed(policy, tegra_cpu_highest_speed());
 
 out:
 	mutex_unlock(&tegra_cpu_lock);
@@ -158,10 +156,12 @@ static int tegra_pm_notify(struct notifier_block *nb, unsigned long event,
 {
 	mutex_lock(&tegra_cpu_lock);
 	if (event == PM_SUSPEND_PREPARE) {
+		struct cpufreq_policy *policy = cpufreq_cpu_get(0);
 		is_suspended = true;
 		pr_info("Tegra cpufreq suspend: setting frequency to %d kHz\n",
 			freq_table[0].frequency);
-		tegra_update_cpu_speed(freq_table[0].frequency);
+		tegra_update_cpu_speed(policy, freq_table[0].frequency);
+		cpufreq_cpu_put(policy);
 	} else if (event == PM_POST_SUSPEND) {
 		is_suspended = false;
 	}
diff --git arch/avr32/mach-at32ap/cpufreq.c arch/avr32/mach-at32ap/cpufreq.c
index 18b7656..6544887 100644
--- arch/avr32/mach-at32ap/cpufreq.c
+++ arch/avr32/mach-at32ap/cpufreq.c
@@ -61,7 +61,6 @@ static int at32_set_target(struct cpufreq_policy *policy,
 
 	freqs.old = at32_get_speed(0);
 	freqs.new = (freq + 500) / 1000;
-	freqs.cpu = 0;
 	freqs.flags = 0;
 
 	if (!ref_freq) {
@@ -69,7 +68,7 @@ static int at32_set_target(struct cpufreq_policy *policy,
 		loops_per_jiffy_ref = boot_cpu_data.loops_per_jiffy;
 	}
 
-	cpufreq_notify_transition(&freqs, CPUFREQ_PRECHANGE);
+	cpufreq_notify_transition(policy, &freqs, CPUFREQ_PRECHANGE);
 	if (freqs.old < freqs.new)
 		boot_cpu_data.loops_per_jiffy = cpufreq_scale(
 				loops_per_jiffy_ref, ref_freq, freqs.new);
@@ -77,7 +76,7 @@ static int at32_set_target(struct cpufreq_policy *policy,
 	if (freqs.new < freqs.old)
 		boot_cpu_data.loops_per_jiffy = cpufreq_scale(
 				loops_per_jiffy_ref, ref_freq, freqs.new);
-	cpufreq_notify_transition(&freqs, CPUFREQ_POSTCHANGE);
+	cpufreq_notify_transition(policy, &freqs, CPUFREQ_POSTCHANGE);
 
 	pr_debug("cpufreq: set frequency %lu Hz\n", freq);
 
diff --git arch/blackfin/mach-common/cpufreq.c arch/blackfin/mach-common/cpufreq.c
index 2e6eefd..1c24c5e 100644
--- arch/blackfin/mach-common/cpufreq.c
+++ arch/blackfin/mach-common/cpufreq.c
@@ -112,54 +112,49 @@ static int bfin_target(struct cpufreq_policy *poli,
 	cycles_t cycles;
 #endif
 
-	for_each_online_cpu(cpu) {
-		struct cpufreq_policy *policy = cpufreq_cpu_get(cpu);
+	if (cpufreq_frequency_table_target(policy, bfin_freq_table, target_freq,
+				relation, &index))
+		return -EINVAL;
 
-		if (!policy)
-			continue;
+	cclk_hz = bfin_freq_table[index].frequency;
 
-		if (cpufreq_frequency_table_target(policy, bfin_freq_table,
-				 target_freq, relation, &index))
-			return -EINVAL;
+	freqs.old = bfin_getfreq_khz(0);
+	freqs.new = cclk_hz;
 
-		cclk_hz = bfin_freq_table[index].frequency;
+	pr_debug("cpufreq: changing cclk to %lu; target = %u, oldfreq = %u\n",
+			cclk_hz, target_freq, freqs.old);
 
-		freqs.old = bfin_getfreq_khz(0);
-		freqs.new = cclk_hz;
-		freqs.cpu = cpu;
-
-		pr_debug("cpufreq: changing cclk to %lu; target = %u, oldfreq = %u\n",
-			 cclk_hz, target_freq, freqs.old);
-
-		cpufreq_notify_transition(&freqs, CPUFREQ_PRECHANGE);
-		if (cpu == CPUFREQ_CPU) {
-			flags = hard_local_irq_save();
-			plldiv = (bfin_read_PLL_DIV() & SSEL) |
-						dpm_state_table[index].csel;
-			bfin_write_PLL_DIV(plldiv);
-			on_each_cpu(bfin_adjust_core_timer, &index, 1);
+	cpufreq_notify_transition(policy, &freqs, CPUFREQ_PRECHANGE);
+#ifndef CONFIG_BF60x
+	plldiv = (bfin_read_PLL_DIV() & SSEL) | dpm_state_table[index].csel;
+	bfin_write_PLL_DIV(plldiv);
+#else
+	ret = cpu_set_cclk(policy->cpu, freqs.new * 1000);
+	if (ret != 0) {
+		WARN_ONCE(ret, "cpufreq set freq failed %d\n", ret);
+		return ret;
+	}
+#endif
+	on_each_cpu(bfin_adjust_core_timer, &index, 1);
 #if defined(CONFIG_CYCLES_CLOCKSOURCE)
-			cycles = get_cycles();
-			SSYNC();
-			cycles += 10; /* ~10 cycles we lose after get_cycles() */
-			__bfin_cycles_off +=
-			    (cycles << __bfin_cycles_mod) - (cycles << index);
-			__bfin_cycles_mod = index;
+	cycles = get_cycles();
+	SSYNC();
+	cycles += 10; /* ~10 cycles we lose after get_cycles() */
+	__bfin_cycles_off += (cycles << __bfin_cycles_mod) - (cycles << index);
+	__bfin_cycles_mod = index;
 #endif
-			if (!lpj_ref_freq) {
-				lpj_ref = loops_per_jiffy;
-				lpj_ref_freq = freqs.old;
-			}
-			if (freqs.new != freqs.old) {
-				loops_per_jiffy = cpufreq_scale(lpj_ref,
-						lpj_ref_freq, freqs.new);
-			}
-			hard_local_irq_restore(flags);
-		}
-		/* TODO: just test case for cycles clock source, remove later */
-		cpufreq_notify_transition(&freqs, CPUFREQ_POSTCHANGE);
+	if (!lpj_ref_freq) {
+		lpj_ref = loops_per_jiffy;
+		lpj_ref_freq = freqs.old;
+	}
+	if (freqs.new != freqs.old) {
+		loops_per_jiffy = cpufreq_scale(lpj_ref,
+				lpj_ref_freq, freqs.new);
 	}
 
+	/* TODO: just test case for cycles clock source, remove later */
+	cpufreq_notify_transition(policy, &freqs, CPUFREQ_POSTCHANGE);
+
 	pr_debug("cpufreq: done\n");
 	return 0;
 }
diff --git arch/cris/arch-v32/mach-a3/cpufreq.c arch/cris/arch-v32/mach-a3/cpufreq.c
index ee391ec..ee142c4 100644
--- arch/cris/arch-v32/mach-a3/cpufreq.c
+++ arch/cris/arch-v32/mach-a3/cpufreq.c
@@ -27,23 +27,17 @@ static unsigned int cris_freq_get_cpu_frequency(unsigned int cpu)
 	return clk_ctrl.pll ? 200000 : 6000;
 }
 
-static void cris_freq_set_cpu_state(unsigned int state)
+static void cris_freq_set_cpu_state(struct cpufreq_policy *policy,
+		unsigned int state)
 {
-	int i = 0;
 	struct cpufreq_freqs freqs;
 	reg_clkgen_rw_clk_ctrl clk_ctrl;
 	clk_ctrl = REG_RD(clkgen, regi_clkgen, rw_clk_ctrl);
 
-#ifdef CONFIG_SMP
-	for_each_present_cpu(i)
-#endif
-	{
-		freqs.old = cris_freq_get_cpu_frequency(i);
-		freqs.new = cris_freq_table[state].frequency;
-		freqs.cpu = i;
-	}
+	freqs.old = cris_freq_get_cpu_frequency(policy->cpu);
+	freqs.new = cris_freq_table[state].frequency;
 
-	cpufreq_notify_transition(&freqs, CPUFREQ_PRECHANGE);
+	cpufreq_notify_transition(policy, &freqs, CPUFREQ_PRECHANGE);
 
 	local_irq_disable();
 
@@ -57,7 +51,7 @@ static void cris_freq_set_cpu_state(unsigned int state)
 
 	local_irq_enable();
 
-	cpufreq_notify_transition(&freqs, CPUFREQ_POSTCHANGE);
+	cpufreq_notify_transition(policy, &freqs, CPUFREQ_POSTCHANGE);
 };
 
 static int cris_freq_verify(struct cpufreq_policy *policy)
@@ -75,7 +69,7 @@ static int cris_freq_target(struct cpufreq_policy *policy,
 			target_freq, relation, &newstate))
 		return -EINVAL;
 
-	cris_freq_set_cpu_state(newstate);
+	cris_freq_set_cpu_state(policy, newstate);
 
 	return 0;
 }
diff --git arch/cris/arch-v32/mach-fs/cpufreq.c arch/cris/arch-v32/mach-fs/cpufreq.c
index d92cf70..1295223 100644
--- arch/cris/arch-v32/mach-fs/cpufreq.c
+++ arch/cris/arch-v32/mach-fs/cpufreq.c
@@ -27,20 +27,17 @@ static unsigned int cris_freq_get_cpu_frequency(unsigned int cpu)
 	return clk_ctrl.pll ? 200000 : 6000;
 }
 
-static void cris_freq_set_cpu_state(unsigned int state)
+static void cris_freq_set_cpu_state(struct cpufreq_policy *policy,
+		unsigned int state)
 {
-	int i;
 	struct cpufreq_freqs freqs;
 	reg_config_rw_clk_ctrl clk_ctrl;
 	clk_ctrl = REG_RD(config, regi_config, rw_clk_ctrl);
 
-	for_each_possible_cpu(i) {
-		freqs.old = cris_freq_get_cpu_frequency(i);
-		freqs.new = cris_freq_table[state].frequency;
-		freqs.cpu = i;
-	}
+	freqs.old = cris_freq_get_cpu_frequency(policy->cpu);
+	freqs.new = cris_freq_table[state].frequency;
 
-	cpufreq_notify_transition(&freqs, CPUFREQ_PRECHANGE);
+	cpufreq_notify_transition(policy, &freqs, CPUFREQ_PRECHANGE);
 
 	local_irq_disable();
 
@@ -54,7 +51,7 @@ static void cris_freq_set_cpu_state(unsigned int state)
 
 	local_irq_enable();
 
-	cpufreq_notify_transition(&freqs, CPUFREQ_POSTCHANGE);
+	cpufreq_notify_transition(policy, &freqs, CPUFREQ_POSTCHANGE);
 };
 
 static int cris_freq_verify(struct cpufreq_policy *policy)
@@ -71,7 +68,7 @@ static int cris_freq_target(struct cpufreq_policy *policy,
 	    (policy, cris_freq_table, target_freq, relation, &newstate))
 		return -EINVAL;
 
-	cris_freq_set_cpu_state(newstate);
+	cris_freq_set_cpu_state(policy, newstate);
 
 	return 0;
 }
diff --git arch/ia64/kernel/cpufreq/acpi-cpufreq.c arch/ia64/kernel/cpufreq/acpi-cpufreq.c
index f09b174..4700fef 100644
--- arch/ia64/kernel/cpufreq/acpi-cpufreq.c
+++ arch/ia64/kernel/cpufreq/acpi-cpufreq.c
@@ -137,7 +137,7 @@ migrate_end:
 static int
 processor_set_freq (
 	struct cpufreq_acpi_io	*data,
-	unsigned int		cpu,
+	struct cpufreq_policy   *policy,
 	int			state)
 {
 	int			ret = 0;
@@ -149,8 +149,8 @@ processor_set_freq (
 	pr_debug("processor_set_freq\n");
 
 	saved_mask = current->cpus_allowed;
-	set_cpus_allowed_ptr(current, cpumask_of(cpu));
-	if (smp_processor_id() != cpu) {
+	set_cpus_allowed_ptr(current, cpumask_of(policy->cpu));
+	if (smp_processor_id() != policy->cpu) {
 		retval = -EAGAIN;
 		goto migrate_end;
 	}
@@ -170,12 +170,11 @@ processor_set_freq (
 		data->acpi_data.state, state);
 
 	/* cpufreq frequency struct */
-	cpufreq_freqs.cpu = cpu;
 	cpufreq_freqs.old = data->freq_table[data->acpi_data.state].frequency;
 	cpufreq_freqs.new = data->freq_table[state].frequency;
 
 	/* notify cpufreq */
-	cpufreq_notify_transition(&cpufreq_freqs, CPUFREQ_PRECHANGE);
+	cpufreq_notify_transition(policy, &cpufreq_freqs, CPUFREQ_PRECHANGE);
 
 	/*
 	 * First we write the target state's 'control' value to the
@@ -189,17 +188,20 @@ processor_set_freq (
 	ret = processor_set_pstate(value);
 	if (ret) {
 		unsigned int tmp = cpufreq_freqs.new;
-		cpufreq_notify_transition(&cpufreq_freqs, CPUFREQ_POSTCHANGE);
+		cpufreq_notify_transition(policy, &cpufreq_freqs,
+				CPUFREQ_POSTCHANGE);
 		cpufreq_freqs.new = cpufreq_freqs.old;
 		cpufreq_freqs.old = tmp;
-		cpufreq_notify_transition(&cpufreq_freqs, CPUFREQ_PRECHANGE);
-		cpufreq_notify_transition(&cpufreq_freqs, CPUFREQ_POSTCHANGE);
+		cpufreq_notify_transition(policy, &cpufreq_freqs,
+				CPUFREQ_PRECHANGE);
+		cpufreq_notify_transition(policy, &cpufreq_freqs,
+				CPUFREQ_POSTCHANGE);
 		printk(KERN_WARNING "Transition failed with error %d\n", ret);
 		retval = -ENODEV;
 		goto migrate_end;
 	}
 
-	cpufreq_notify_transition(&cpufreq_freqs, CPUFREQ_POSTCHANGE);
+	cpufreq_notify_transition(policy, &cpufreq_freqs, CPUFREQ_POSTCHANGE);
 
 	data->acpi_data.state = state;
 
@@ -240,7 +242,7 @@ acpi_cpufreq_target (
 	if (result)
 		return (result);
 
-	result = processor_set_freq(data, policy->cpu, next_state);
+	result = processor_set_freq(data, policy, next_state);
 
 	return (result);
 }
diff --git arch/mips/kernel/cpufreq/loongson2_cpufreq.c arch/mips/kernel/cpufreq/loongson2_cpufreq.c
index ae5db20..dfa5a71 100644
--- arch/mips/kernel/cpufreq/loongson2_cpufreq.c
+++ arch/mips/kernel/cpufreq/loongson2_cpufreq.c
@@ -80,7 +80,6 @@ static int loongson2_cpufreq_target(struct cpufreq_policy *policy,
 
 	pr_debug("cpufreq: requested frequency %u Hz\n", target_freq * 1000);
 
-	freqs.cpu = cpu;
 	freqs.old = loongson2_cpufreq_get(cpu);
 	freqs.new = freq;
 	freqs.flags = 0;
@@ -89,7 +88,7 @@ static int loongson2_cpufreq_target(struct cpufreq_policy *policy,
 		return 0;
 
 	/* notifiers */
-	cpufreq_notify_transition(&freqs, CPUFREQ_PRECHANGE);
+	cpufreq_notify_transition(policy, &freqs, CPUFREQ_PRECHANGE);
 
 	set_cpus_allowed_ptr(current, &cpus_allowed);
 
@@ -97,7 +96,7 @@ static int loongson2_cpufreq_target(struct cpufreq_policy *policy,
 	clk_set_rate(cpuclk, freq);
 
 	/* notifiers */
-	cpufreq_notify_transition(&freqs, CPUFREQ_POSTCHANGE);
+	cpufreq_notify_transition(policy, &freqs, CPUFREQ_POSTCHANGE);
 
 	pr_debug("cpufreq: set frequency %u kHz\n", freq);
 
diff --git arch/powerpc/platforms/cell/cbe_cpufreq.c arch/powerpc/platforms/cell/cbe_cpufreq.c
index d4c39e3..718c6a3 100644
--- arch/powerpc/platforms/cell/cbe_cpufreq.c
+++ arch/powerpc/platforms/cell/cbe_cpufreq.c
@@ -156,10 +156,9 @@ static int cbe_cpufreq_target(struct cpufreq_policy *policy,
 
 	freqs.old = policy->cur;
 	freqs.new = cbe_freqs[cbe_pmode_new].frequency;
-	freqs.cpu = policy->cpu;
 
 	mutex_lock(&cbe_switch_mutex);
-	cpufreq_notify_transition(&freqs, CPUFREQ_PRECHANGE);
+	cpufreq_notify_transition(policy, &freqs, CPUFREQ_PRECHANGE);
 
 	pr_debug("setting frequency for cpu %d to %d kHz, " \
 		 "1/%d of max frequency\n",
@@ -169,7 +168,7 @@ static int cbe_cpufreq_target(struct cpufreq_policy *policy,
 
 	rc = set_pmode(policy->cpu, cbe_pmode_new);
 
-	cpufreq_notify_transition(&freqs, CPUFREQ_POSTCHANGE);
+	cpufreq_notify_transition(policy, &freqs, CPUFREQ_POSTCHANGE);
 	mutex_unlock(&cbe_switch_mutex);
 
 	return rc;
diff --git arch/powerpc/platforms/pasemi/cpufreq.c arch/powerpc/platforms/pasemi/cpufreq.c
index 95d0017..e34b320 100644
--- arch/powerpc/platforms/pasemi/cpufreq.c
+++ arch/powerpc/platforms/pasemi/cpufreq.c
@@ -266,10 +266,9 @@ static int pas_cpufreq_target(struct cpufreq_policy *policy,
 
 	freqs.old = policy->cur;
 	freqs.new = pas_freqs[pas_astate_new].frequency;
-	freqs.cpu = policy->cpu;
 
 	mutex_lock(&pas_switch_mutex);
-	cpufreq_notify_transition(&freqs, CPUFREQ_PRECHANGE);
+	cpufreq_notify_transition(policy, &freqs, CPUFREQ_PRECHANGE);
 
 	pr_debug("setting frequency for cpu %d to %d kHz, 1/%d of max frequency\n",
 		 policy->cpu,
@@ -281,7 +280,7 @@ static int pas_cpufreq_target(struct cpufreq_policy *policy,
 	for_each_online_cpu(i)
 		set_astate(i, pas_astate_new);
 
-	cpufreq_notify_transition(&freqs, CPUFREQ_POSTCHANGE);
+	cpufreq_notify_transition(policy, &freqs, CPUFREQ_POSTCHANGE);
 	mutex_unlock(&pas_switch_mutex);
 
 	ppc_proc_freq = freqs.new * 1000ul;
diff --git arch/powerpc/platforms/powermac/cpufreq_32.c arch/powerpc/platforms/powermac/cpufreq_32.c
index 6417119..12d9c0e 100644
--- arch/powerpc/platforms/powermac/cpufreq_32.c
+++ arch/powerpc/platforms/powermac/cpufreq_32.c
@@ -334,7 +334,8 @@ static int pmu_set_cpu_speed(int low_speed)
 	return 0;
 }
 
-static int do_set_cpu_speed(int speed_mode, int notify)
+static int do_set_cpu_speed(struct cpufreq_policy *policy, int speed_mode,
+		int notify)
 {
 	struct cpufreq_freqs freqs;
 	unsigned long l3cr;
@@ -342,13 +343,12 @@ static int do_set_cpu_speed(int speed_mode, int notify)
 
 	freqs.old = cur_freq;
 	freqs.new = (speed_mode == CPUFREQ_HIGH) ? hi_freq : low_freq;
-	freqs.cpu = smp_processor_id();
 
 	if (freqs.old == freqs.new)
 		return 0;
 
 	if (notify)
-		cpufreq_notify_transition(&freqs, CPUFREQ_PRECHANGE);
+		cpufreq_notify_transition(policy, &freqs, CPUFREQ_PRECHANGE);
 	if (speed_mode == CPUFREQ_LOW &&
 	    cpu_has_feature(CPU_FTR_L3CR)) {
 		l3cr = _get_L3CR();
@@ -365,7 +365,7 @@ static int do_set_cpu_speed(int speed_mode, int notify)
 			_set_L3CR(prev_l3cr);
 	}
 	if (notify)
-		cpufreq_notify_transition(&freqs, CPUFREQ_POSTCHANGE);
+		cpufreq_notify_transition(policy, &freqs, CPUFREQ_POSTCHANGE);
 	cur_freq = (speed_mode == CPUFREQ_HIGH) ? hi_freq : low_freq;
 
 	return 0;
@@ -392,7 +392,7 @@ static int pmac_cpufreq_target(	struct cpufreq_policy *policy,
 			target_freq, relation, &newstate))
 		return -EINVAL;
 
-	rc = do_set_cpu_speed(newstate, 1);
+	rc = do_set_cpu_speed(policy, newstate, 1);
 
 	ppc_proc_freq = cur_freq * 1000ul;
 	return rc;
@@ -441,7 +441,7 @@ static int pmac_cpufreq_suspend(struct cpufreq_policy *policy)
 	no_schedule = 1;
 	sleep_freq = cur_freq;
 	if (cur_freq == low_freq && !is_pmu_based)
-		do_set_cpu_speed(CPUFREQ_HIGH, 0);
+		do_set_cpu_speed(policy, CPUFREQ_HIGH, 0);
 	return 0;
 }
 
@@ -457,7 +457,7 @@ static int pmac_cpufreq_resume(struct cpufreq_policy *policy)
 	 * is that we force a switch to whatever it was, which is
 	 * probably high speed due to our suspend() routine
 	 */
-	do_set_cpu_speed(sleep_freq == low_freq ?
+	do_set_cpu_speed(policy, sleep_freq == low_freq ?
 			 CPUFREQ_LOW : CPUFREQ_HIGH, 0);
 
 	ppc_proc_freq = cur_freq * 1000ul;
diff --git arch/powerpc/platforms/powermac/cpufreq_64.c arch/powerpc/platforms/powermac/cpufreq_64.c
index 9650c60..7ba4234 100644
--- arch/powerpc/platforms/powermac/cpufreq_64.c
+++ arch/powerpc/platforms/powermac/cpufreq_64.c
@@ -339,11 +339,10 @@ static int g5_cpufreq_target(struct cpufreq_policy *policy,
 
 	freqs.old = g5_cpu_freqs[g5_pmode_cur].frequency;
 	freqs.new = g5_cpu_freqs[newstate].frequency;
-	freqs.cpu = 0;
 
-	cpufreq_notify_transition(&freqs, CPUFREQ_PRECHANGE);
+	cpufreq_notify_transition(policy, &freqs, CPUFREQ_PRECHANGE);
 	rc = g5_switch_freq(newstate);
-	cpufreq_notify_transition(&freqs, CPUFREQ_POSTCHANGE);
+	cpufreq_notify_transition(policy, &freqs, CPUFREQ_POSTCHANGE);
 
 	mutex_unlock(&g5_switch_mutex);
 
diff --git arch/sh/kernel/cpufreq.c arch/sh/kernel/cpufreq.c
index e68b45b..2c7bd94 100644
--- arch/sh/kernel/cpufreq.c
+++ arch/sh/kernel/cpufreq.c
@@ -69,15 +69,14 @@ static int sh_cpufreq_target(struct cpufreq_policy *policy,
 
 	dev_dbg(dev, "requested frequency %u Hz\n", target_freq * 1000);
 
-	freqs.cpu	= cpu;
 	freqs.old	= sh_cpufreq_get(cpu);
 	freqs.new	= (freq + 500) / 1000;
 	freqs.flags	= 0;
 
-	cpufreq_notify_transition(&freqs, CPUFREQ_PRECHANGE);
+	cpufreq_notify_transition(policy, &freqs, CPUFREQ_PRECHANGE);
 	set_cpus_allowed_ptr(current, &cpus_allowed);
 	clk_set_rate(cpuclk, freq);
-	cpufreq_notify_transition(&freqs, CPUFREQ_POSTCHANGE);
+	cpufreq_notify_transition(policy, &freqs, CPUFREQ_POSTCHANGE);
 
 	dev_dbg(dev, "set frequency %lu Hz\n", freq);
 
diff --git arch/sparc/kernel/us2e_cpufreq.c arch/sparc/kernel/us2e_cpufreq.c
index 489fc15..abe963d 100644
--- arch/sparc/kernel/us2e_cpufreq.c
+++ arch/sparc/kernel/us2e_cpufreq.c
@@ -248,8 +248,10 @@ static unsigned int us2e_freq_get(unsigned int cpu)
 	return clock_tick / estar_to_divisor(estar);
 }
 
-static void us2e_set_cpu_divider_index(unsigned int cpu, unsigned int index)
+static void us2e_set_cpu_divider_index(struct cpufreq_policy *policy,
+		unsigned int index)
 {
+	unsigned int cpu = policy->cpu;
 	unsigned long new_bits, new_freq;
 	unsigned long clock_tick, divisor, old_divisor, estar;
 	cpumask_t cpus_allowed;
@@ -272,14 +274,13 @@ static void us2e_set_cpu_divider_index(unsigned int cpu, unsigned int index)
 
 	freqs.old = clock_tick / old_divisor;
 	freqs.new = new_freq;
-	freqs.cpu = cpu;
-	cpufreq_notify_transition(&freqs, CPUFREQ_PRECHANGE);
+	cpufreq_notify_transition(policy, &freqs, CPUFREQ_PRECHANGE);
 
 	if (old_divisor != divisor)
 		us2e_transition(estar, new_bits, clock_tick * 1000,
 				old_divisor, divisor);
 
-	cpufreq_notify_transition(&freqs, CPUFREQ_POSTCHANGE);
+	cpufreq_notify_transition(policy, &freqs, CPUFREQ_POSTCHANGE);
 
 	set_cpus_allowed_ptr(current, &cpus_allowed);
 }
@@ -295,7 +296,7 @@ static int us2e_freq_target(struct cpufreq_policy *policy,
 					   target_freq, relation, &new_index))
 		return -EINVAL;
 
-	us2e_set_cpu_divider_index(policy->cpu, new_index);
+	us2e_set_cpu_divider_index(policy, new_index);
 
 	return 0;
 }
@@ -335,7 +336,7 @@ static int __init us2e_freq_cpu_init(struct cpufreq_policy *policy)
 static int us2e_freq_cpu_exit(struct cpufreq_policy *policy)
 {
 	if (cpufreq_us2e_driver)
-		us2e_set_cpu_divider_index(policy->cpu, 0);
+		us2e_set_cpu_divider_index(policy, 0);
 
 	return 0;
 }
diff --git arch/sparc/kernel/us3_cpufreq.c arch/sparc/kernel/us3_cpufreq.c
index eb1624b..7ceb9c8 100644
--- arch/sparc/kernel/us3_cpufreq.c
+++ arch/sparc/kernel/us3_cpufreq.c
@@ -96,8 +96,10 @@ static unsigned int us3_freq_get(unsigned int cpu)
 	return ret;
 }
 
-static void us3_set_cpu_divider_index(unsigned int cpu, unsigned int index)
+static void us3_set_cpu_divider_index(struct cpufreq_policy *policy,
+		unsigned int index)
 {
+	unsigned int cpu = policy->cpu;
 	unsigned long new_bits, new_freq, reg;
 	cpumask_t cpus_allowed;
 	struct cpufreq_freqs freqs;
@@ -131,14 +133,13 @@ static void us3_set_cpu_divider_index(unsigned int cpu, unsigned int index)
 
 	freqs.old = get_current_freq(cpu, reg);
 	freqs.new = new_freq;
-	freqs.cpu = cpu;
-	cpufreq_notify_transition(&freqs, CPUFREQ_PRECHANGE);
+	cpufreq_notify_transition(policy, &freqs, CPUFREQ_PRECHANGE);
 
 	reg &= ~SAFARI_CFG_DIV_MASK;
 	reg |= new_bits;
 	write_safari_cfg(reg);
 
-	cpufreq_notify_transition(&freqs, CPUFREQ_POSTCHANGE);
+	cpufreq_notify_transition(policy, &freqs, CPUFREQ_POSTCHANGE);
 
 	set_cpus_allowed_ptr(current, &cpus_allowed);
 }
@@ -156,7 +157,7 @@ static int us3_freq_target(struct cpufreq_policy *policy,
 					   &new_index))
 		return -EINVAL;
 
-	us3_set_cpu_divider_index(policy->cpu, new_index);
+	us3_set_cpu_divider_index(policy, new_index);
 
 	return 0;
 }
@@ -192,7 +193,7 @@ static int __init us3_freq_cpu_init(struct cpufreq_policy *policy)
 static int us3_freq_cpu_exit(struct cpufreq_policy *policy)
 {
 	if (cpufreq_us3_driver)
-		us3_set_cpu_divider_index(policy->cpu, 0);
+		us3_set_cpu_divider_index(policy, 0);
 
 	return 0;
 }
diff --git arch/unicore32/kernel/cpu-ucv2.c arch/unicore32/kernel/cpu-ucv2.c
index 4a99f62..ba5a71c 100644
--- arch/unicore32/kernel/cpu-ucv2.c
+++ arch/unicore32/kernel/cpu-ucv2.c
@@ -52,15 +52,14 @@ static int ucv2_target(struct cpufreq_policy *policy,
 	struct cpufreq_freqs freqs;
 	struct clk *mclk = clk_get(NULL, "MAIN_CLK");
 
-	cpufreq_notify_transition(&freqs, CPUFREQ_PRECHANGE);
+	cpufreq_notify_transition(policy, &freqs, CPUFREQ_PRECHANGE);
 
 	if (!clk_set_rate(mclk, target_freq * 1000)) {
 		freqs.old = cur;
 		freqs.new = target_freq;
-		freqs.cpu = 0;
 	}
 
-	cpufreq_notify_transition(&freqs, CPUFREQ_POSTCHANGE);
+	cpufreq_notify_transition(policy, &freqs, CPUFREQ_POSTCHANGE);
 
 	return 0;
 }
diff --git drivers/cpufreq/acpi-cpufreq.c drivers/cpufreq/acpi-cpufreq.c
index 56c6c6b..fbe34fd 100644
--- drivers/cpufreq/acpi-cpufreq.c
+++ drivers/cpufreq/acpi-cpufreq.c
@@ -287,7 +287,6 @@ static int acpi_cpufreq_target(struct cpufreq_policy *policy,
 	struct drv_cmd cmd;
 	unsigned int next_state = 0; /* Index into freq_table */
 	unsigned int next_perf_state = 0; /* Index into perf table */
-	unsigned int i;
 	int result = 0;
 
 	pr_debug("acpi_cpufreq_target %d (%d)\n", target_freq, policy->cpu);
@@ -345,10 +344,7 @@ static int acpi_cpufreq_target(struct cpufreq_policy *policy,
 
 	freqs.old = perf->states[perf->state].core_frequency * 1000;
 	freqs.new = data->freq_table[next_state].frequency;
-	for_each_cpu(i, policy->cpus) {
-		freqs.cpu = i;
-		cpufreq_notify_transition(&freqs, CPUFREQ_PRECHANGE);
-	}
+	cpufreq_notify_transition(policy, &freqs, CPUFREQ_PRECHANGE);
 
 	drv_write(&cmd);
 
@@ -361,10 +357,7 @@ static int acpi_cpufreq_target(struct cpufreq_policy *policy,
 		}
 	}
 
-	for_each_cpu(i, policy->cpus) {
-		freqs.cpu = i;
-		cpufreq_notify_transition(&freqs, CPUFREQ_POSTCHANGE);
-	}
+	cpufreq_notify_transition(policy, &freqs, CPUFREQ_POSTCHANGE);
 	perf->state = next_perf_state;
 
 out:
diff --git drivers/cpufreq/cpufreq-nforce2.c drivers/cpufreq/cpufreq-nforce2.c
index 13d311e..224a478 100644
--- drivers/cpufreq/cpufreq-nforce2.c
+++ drivers/cpufreq/cpufreq-nforce2.c
@@ -263,7 +263,6 @@ static int nforce2_target(struct cpufreq_policy *policy,
 
 	freqs.old = nforce2_get(policy->cpu);
 	freqs.new = target_fsb * fid * 100;
-	freqs.cpu = 0;		/* Only one CPU on nForce2 platforms */
 
 	if (freqs.old == freqs.new)
 		return 0;
@@ -271,7 +270,7 @@ static int nforce2_target(struct cpufreq_policy *policy,
 	pr_debug("Old CPU frequency %d kHz, new %d kHz\n",
 	       freqs.old, freqs.new);
 
-	cpufreq_notify_transition(&freqs, CPUFREQ_PRECHANGE);
+	cpufreq_notify_transition(policy, &freqs, CPUFREQ_PRECHANGE);
 
 	/* Disable IRQs */
 	/* local_irq_save(flags); */
@@ -286,7 +285,7 @@ static int nforce2_target(struct cpufreq_policy *policy,
 	/* Enable IRQs */
 	/* local_irq_restore(flags); */
 
-	cpufreq_notify_transition(&freqs, CPUFREQ_POSTCHANGE);
+	cpufreq_notify_transition(policy, &freqs, CPUFREQ_POSTCHANGE);
 
 	return 0;
 }
diff --git drivers/cpufreq/cpufreq.c drivers/cpufreq/cpufreq.c
index d87b240..32d8556 100644
--- drivers/cpufreq/cpufreq.c
+++ drivers/cpufreq/cpufreq.c
@@ -78,10 +78,6 @@ int lock_policy_rwsem_##mode						\
 	int policy_cpu = per_cpu(cpufreq_policy_cpu, cpu);		\
 	BUG_ON(policy_cpu == -1);					\
 	down_##mode(&per_cpu(cpu_policy_rwsem, policy_cpu));		\
-	if (unlikely(!cpu_online(cpu))) {				\
-		up_##mode(&per_cpu(cpu_policy_rwsem, policy_cpu));	\
-		return -1;						\
-	}								\
 									\
 	return 0;							\
 }
@@ -252,25 +248,15 @@ static inline void adjust_jiffies(unsigned long val, struct cpufreq_freqs *ci)
 #endif
 
 
-/**
- * cpufreq_notify_transition - call notifier chain and adjust_jiffies
- * on frequency transition.
- *
- * This function calls the transition notifiers and the "adjust_jiffies"
- * function. It is called twice on all CPU frequency changes that have
- * external effects.
- */
-void cpufreq_notify_transition(struct cpufreq_freqs *freqs, unsigned int state)
+void __cpufreq_notify_transition(struct cpufreq_policy *policy,
+		struct cpufreq_freqs *freqs, unsigned int state)
 {
-	struct cpufreq_policy *policy;
-
 	BUG_ON(irqs_disabled());
 
 	freqs->flags = cpufreq_driver->flags;
 	pr_debug("notification %u of frequency transition to %u kHz\n",
 		state, freqs->new);
 
-	policy = per_cpu(cpufreq_cpu_data, freqs->cpu);
 	switch (state) {
 
 	case CPUFREQ_PRECHANGE:
@@ -307,6 +293,20 @@ void cpufreq_notify_transition(struct cpufreq_freqs *freqs, unsigned int state)
 		break;
 	}
 }
+/**
+ * cpufreq_notify_transition - call notifier chain and adjust_jiffies
+ * on frequency transition.
+ *
+ * This function calls the transition notifiers and the "adjust_jiffies"
+ * function. It is called twice on all CPU frequency changes that have
+ * external effects.
+ */
+void cpufreq_notify_transition(struct cpufreq_policy *policy,
+		struct cpufreq_freqs *freqs, unsigned int state)
+{
+	for_each_cpu(freqs->cpu, policy->cpus)
+		__cpufreq_notify_transition(policy, freqs, state);
+}
 EXPORT_SYMBOL_GPL(cpufreq_notify_transition);
 /**
  * cpufreq_notify_utilization - notify CPU userspace about CPU utilization
@@ -569,8 +569,6 @@ static ssize_t show_cpus(const struct cpumask *mask, char *buf)
  */
 static ssize_t show_related_cpus(struct cpufreq_policy *policy, char *buf)
 {
-	if (cpumask_empty(policy->related_cpus))
-		return show_cpus(policy->cpus, buf);
 	return show_cpus(policy->related_cpus, buf);
 }
 
@@ -724,6 +722,10 @@ no_policy:
 static void cpufreq_sysfs_release(struct kobject *kobj)
 {
 	struct cpufreq_policy *policy = to_policy(kobj);
+
+	blocking_notifier_call_chain(&cpufreq_policy_notifier_list,
+			CPUFREQ_REMOVE_POLICY, policy);
+
 	pr_debug("last reference is dropped\n");
 	complete(&policy->kobj_unregister);
 }
@@ -739,99 +741,6 @@ static struct kobj_type ktype_cpufreq = {
 	.release	= cpufreq_sysfs_release,
 };
 
-/*
- * Returns:
- *   Negative: Failure
- *   0:        Success
- *   Positive: When we have a managed CPU and the sysfs got symlinked
- */
-static int cpufreq_add_dev_policy(unsigned int cpu,
-				  struct cpufreq_policy *policy,
-				  struct device *dev)
-{
-	int ret = 0;
-#ifdef CONFIG_SMP
-	unsigned long flags;
-	unsigned int j;
-#ifdef CONFIG_HOTPLUG_CPU
-	struct cpufreq_governor *gov;
-
-	gov = __find_governor(per_cpu(cpufreq_policy_save, cpu).gov);
-	if (gov) {
-		policy->governor = gov;
-		pr_debug("Restoring governor %s for cpu %d\n",
-		       policy->governor->name, cpu);
-	}
-	if (per_cpu(cpufreq_policy_save, cpu).min) {
-		policy->min = per_cpu(cpufreq_policy_save, cpu).min;
-		policy->user_policy.min = policy->min;
-	}
-	if (per_cpu(cpufreq_policy_save, cpu).max) {
-		policy->max = per_cpu(cpufreq_policy_save, cpu).max;
-		policy->user_policy.max = policy->max;
-	}
-	pr_debug("Restoring CPU%d min %d and max %d\n",
-		cpu, policy->min, policy->max);
-#endif
-
-	for_each_cpu(j, policy->cpus) {
-		struct cpufreq_policy *managed_policy;
-
-		if (cpu == j)
-			continue;
-
-		/* Check for existing affected CPUs.
-		 * They may not be aware of it due to CPU Hotplug.
-		 * cpufreq_cpu_put is called when the device is removed
-		 * in __cpufreq_remove_dev()
-		 */
-		managed_policy = cpufreq_cpu_get(j);
-		if (unlikely(managed_policy)) {
-
-			/* Set proper policy_cpu */
-			unlock_policy_rwsem_write(cpu);
-			per_cpu(cpufreq_policy_cpu, cpu) = managed_policy->cpu;
-
-			if (lock_policy_rwsem_write(cpu) < 0) {
-				/* Should not go through policy unlock path */
-				if (cpufreq_driver->exit)
-					cpufreq_driver->exit(policy);
-				cpufreq_cpu_put(managed_policy);
-				return -EBUSY;
-			}
-
-			spin_lock_irqsave(&cpufreq_driver_lock, flags);
-			cpumask_copy(managed_policy->cpus, policy->cpus);
-			cpumask_and(managed_policy->cpus,
-					managed_policy->cpus, cpu_online_mask);
-			per_cpu(cpufreq_cpu_data, cpu) = managed_policy;
-			spin_unlock_irqrestore(&cpufreq_driver_lock, flags);
-
-			pr_debug("CPU already managed, adding link\n");
-			ret = sysfs_create_link(&dev->kobj,
-						&managed_policy->kobj,
-						"cpufreq");
-			if (ret)
-				cpufreq_cpu_put(managed_policy);
-			/*
-			 * Success. We only needed to be added to the mask.
-			 * Call driver->exit() because only the cpu parent of
-			 * the kobj needed to call init().
-			 */
-			if (cpufreq_driver->exit)
-				cpufreq_driver->exit(policy);
-
-			if (!ret)
-				return 1;
-			else
-				return ret;
-		}
-	}
-#endif
-	return ret;
-}
-
-
 /* symlink affected CPUs */
 static int cpufreq_add_dev_symlink(unsigned int cpu,
 				   struct cpufreq_policy *policy)
@@ -845,8 +754,6 @@ static int cpufreq_add_dev_symlink(unsigned int cpu,
 
 		if (j == cpu)
 			continue;
-		if (!cpu_online(j))
-			continue;
 
 		pr_debug("CPU %u already managed, adding link\n", j);
 		managed_policy = cpufreq_cpu_get(cpu);
@@ -903,8 +810,6 @@ static int cpufreq_add_dev_interface(unsigned int cpu,
 
 	spin_lock_irqsave(&cpufreq_driver_lock, flags);
 	for_each_cpu(j, policy->cpus) {
-		if (!cpu_online(j))
-			continue;
 		per_cpu(cpufreq_cpu_data, j) = policy;
 		per_cpu(cpufreq_policy_cpu, j) = policy->cpu;
 	}
@@ -928,6 +833,10 @@ static int cpufreq_add_dev_interface(unsigned int cpu,
 		if (cpufreq_driver->exit)
 			cpufreq_driver->exit(policy);
 	}
+
+	blocking_notifier_call_chain(&cpufreq_policy_notifier_list,
+			CPUFREQ_CREATE_POLICY, policy);
+
 	return ret;
 
 err_out_kobj_put:
@@ -936,6 +845,42 @@ err_out_kobj_put:
 	return ret;
 }
 
+#ifdef CONFIG_HOTPLUG_CPU
+static int cpufreq_add_policy_cpu(unsigned int cpu, unsigned int sibling,
+				  struct device *dev)
+{
+	struct cpufreq_policy *policy;
+	int ret = 0;
+	unsigned long flags;
+
+	policy = cpufreq_cpu_get(sibling);
+	WARN_ON(!policy);
+
+	per_cpu(cpufreq_policy_cpu, cpu) = policy->cpu;
+
+	lock_policy_rwsem_write(cpu);
+
+	__cpufreq_governor(policy, CPUFREQ_GOV_STOP);
+
+	spin_lock_irqsave(&cpufreq_driver_lock, flags);
+	cpumask_set_cpu(cpu, policy->cpus);
+	per_cpu(cpufreq_cpu_data, cpu) = policy;
+	spin_unlock_irqrestore(&cpufreq_driver_lock, flags);
+
+	__cpufreq_governor(policy, CPUFREQ_GOV_START);
+	__cpufreq_governor(policy, CPUFREQ_GOV_LIMITS);
+
+	unlock_policy_rwsem_write(cpu);
+
+	ret = sysfs_create_link(&dev->kobj, &policy->kobj, "cpufreq");
+	if (ret) {
+		cpufreq_cpu_put(policy);
+		return ret;
+	}
+
+	return 0;
+}
+#endif
 
 /**
  * cpufreq_add_dev - add a CPU device
@@ -948,12 +893,12 @@ err_out_kobj_put:
  */
 static int cpufreq_add_dev(struct device *dev, struct subsys_interface *sif)
 {
-	unsigned int cpu = dev->id;
-	int ret = 0, found = 0;
+	unsigned int j, cpu = dev->id;
+	int ret = -ENOMEM, found = 0;
 	struct cpufreq_policy *policy;
 	unsigned long flags;
-	unsigned int j;
 #ifdef CONFIG_HOTPLUG_CPU
+	struct cpufreq_governor *gov;
 	int sibling;
 #endif
 
@@ -970,6 +915,15 @@ static int cpufreq_add_dev(struct device *dev, struct subsys_interface *sif)
 		cpufreq_cpu_put(policy);
 		return 0;
 	}
+
+#ifdef CONFIG_HOTPLUG_CPU
+	/* Check if this cpu was hot-unplugged earlier and has siblings */
+	for_each_online_cpu(sibling) {
+		struct cpufreq_policy *cp = per_cpu(cpufreq_cpu_data, sibling);
+		if (cp && cpumask_test_cpu(cpu, cp->related_cpus))
+			return cpufreq_add_policy_cpu(cpu, sibling, dev);
+	}
+#endif
 #endif
 
 	if (!try_module_get(cpufreq_driver->owner)) {
@@ -977,7 +931,6 @@ static int cpufreq_add_dev(struct device *dev, struct subsys_interface *sif)
 		goto module_out;
 	}
 
-	ret = -ENOMEM;
 	policy = kzalloc(sizeof(struct cpufreq_policy), GFP_KERNEL);
 	if (!policy)
 		goto nomem_out;
@@ -1021,20 +974,30 @@ static int cpufreq_add_dev(struct device *dev, struct subsys_interface *sif)
 		pr_debug("initialization failed\n");
 		goto err_unlock_policy;
 	}
+
+	/* related cpus should atleast have policy->cpus */
+	cpumask_or(policy->related_cpus, policy->related_cpus, policy->cpus);
+
+	/*
+	 * affected cpus must always be the one, which are online. We aren't
+	 * managing offline cpus here.
+	 */
+	cpumask_and(policy->cpus, policy->cpus, cpu_online_mask);
+
 	policy->user_policy.min = policy->min;
 	policy->user_policy.max = policy->max;
 
 	blocking_notifier_call_chain(&cpufreq_policy_notifier_list,
 				     CPUFREQ_START, policy);
 
-	ret = cpufreq_add_dev_policy(cpu, policy, dev);
-	if (ret) {
-		if (ret > 0)
-			/* This is a managed cpu, symlink created,
-			   exit with 0 */
-			ret = 0;
-		goto err_unlock_policy;
+#ifdef CONFIG_HOTPLUG_CPU
+	gov = __find_governor(per_cpu(cpufreq_policy_save, cpu).gov);
+	if (gov) {
+		policy->governor = gov;
+		pr_debug("Restoring governor %s for cpu %d\n",
+		       policy->governor->name, cpu);
 	}
+#endif
 
 	ret = cpufreq_add_dev_interface(cpu, policy, dev);
 	if (ret)
@@ -1048,7 +1011,6 @@ static int cpufreq_add_dev(struct device *dev, struct subsys_interface *sif)
 
 	return 0;
 
-
 err_out_unregister:
 	spin_lock_irqsave(&cpufreq_driver_lock, flags);
 	for_each_cpu(j, policy->cpus)
@@ -1110,8 +1072,13 @@ static int __cpufreq_remove_dev(struct device *dev, struct subsys_interface *sif
 	 */
 	if (unlikely(cpu != data->cpu)) {
 		pr_debug("removing link\n");
+		__cpufreq_governor(data, CPUFREQ_GOV_STOP);
 		cpumask_clear_cpu(cpu, data->cpus);
 		spin_unlock_irqrestore(&cpufreq_driver_lock, flags);
+
+		__cpufreq_governor(data, CPUFREQ_GOV_START);
+		__cpufreq_governor(data, CPUFREQ_GOV_LIMITS);
+
 		kobj = &dev->kobj;
 		cpufreq_cpu_put(data);
 		unlock_policy_rwsem_write(cpu);
@@ -1255,16 +1222,23 @@ static void handle_update(struct work_struct *work)
 static void cpufreq_out_of_sync(unsigned int cpu, unsigned int old_freq,
 				unsigned int new_freq)
 {
+	struct cpufreq_policy *policy;
 	struct cpufreq_freqs freqs;
+	unsigned long flags;
+
 
 	pr_debug("Warning: CPU frequency out of sync: cpufreq and timing "
 	       "core thinks of %u, is %u kHz.\n", old_freq, new_freq);
 
-	freqs.cpu = cpu;
 	freqs.old = old_freq;
 	freqs.new = new_freq;
-	cpufreq_notify_transition(&freqs, CPUFREQ_PRECHANGE);
-	cpufreq_notify_transition(&freqs, CPUFREQ_POSTCHANGE);
+
+	spin_lock_irqsave(&cpufreq_driver_lock, flags);
+	policy = per_cpu(cpufreq_cpu_data, cpu);
+	spin_unlock_irqrestore(&cpufreq_driver_lock, flags);
+
+	cpufreq_notify_transition(policy, &freqs, CPUFREQ_PRECHANGE);
+	cpufreq_notify_transition(policy, &freqs, CPUFREQ_POSTCHANGE);
 }
 
 
@@ -1537,7 +1511,7 @@ int __cpufreq_driver_target(struct cpufreq_policy *policy,
 
 	pr_debug("target for CPU %u: %u kHz, relation %u\n", policy->cpu,
 		target_freq, relation);
-	if (cpu_online(policy->cpu) && cpufreq_driver->target)
+	if (cpufreq_driver->target)
 		retval = cpufreq_driver->target(policy, target_freq, relation);
 
 	return retval;
@@ -1572,12 +1546,14 @@ int __cpufreq_driver_getavg(struct cpufreq_policy *policy, unsigned int cpu)
 {
 	int ret = 0;
 
+	if (!cpufreq_driver->getavg)
+		return 0;
+
 	policy = cpufreq_cpu_get(policy->cpu);
 	if (!policy)
 		return -EINVAL;
 
-	if (cpu_online(cpu) && cpufreq_driver->getavg)
-		ret = cpufreq_driver->getavg(policy, cpu);
+	ret = cpufreq_driver->getavg(policy, cpu);
 
 	cpufreq_cpu_put(policy);
 	return ret;
@@ -1866,7 +1842,7 @@ no_policy:
 }
 EXPORT_SYMBOL(cpufreq_update_policy);
 
-static int __cpuinit cpufreq_cpu_callback(struct notifier_block *nfb,
+static int cpufreq_cpu_callback(struct notifier_block *nfb,
 					unsigned long action, void *hcpu)
 {
 	unsigned int cpu = (unsigned long)hcpu;
diff --git drivers/cpufreq/cpufreq_stats.c drivers/cpufreq/cpufreq_stats.c
index e259992..9af61af 100644
--- drivers/cpufreq/cpufreq_stats.c
+++ drivers/cpufreq/cpufreq_stats.c
@@ -685,7 +685,7 @@ out:
 	return ret;
 }
 
-static int __cpuinit cpufreq_stat_cpu_callback(struct notifier_block *nfb,
+static int cpufreq_stat_cpu_callback(struct notifier_block *nfb,
 					       unsigned long action,
 					       void *hcpu)
 {
diff --git drivers/cpufreq/e_powersaver.c drivers/cpufreq/e_powersaver.c
index 3fffbe6..37380fb 100644
--- drivers/cpufreq/e_powersaver.c
+++ drivers/cpufreq/e_powersaver.c
@@ -104,7 +104,7 @@ static unsigned int eps_get(unsigned int cpu)
 }
 
 static int eps_set_state(struct eps_cpu_data *centaur,
-			 unsigned int cpu,
+			 struct cpufreq_policy *policy,
 			 u32 dest_state)
 {
 	struct cpufreq_freqs freqs;
@@ -112,10 +112,9 @@ static int eps_set_state(struct eps_cpu_data *centaur,
 	int err = 0;
 	int i;
 
-	freqs.old = eps_get(cpu);
+	freqs.old = eps_get(policy->cpu);
 	freqs.new = centaur->fsb * ((dest_state >> 8) & 0xff);
-	freqs.cpu = cpu;
-	cpufreq_notify_transition(&freqs, CPUFREQ_PRECHANGE);
+	cpufreq_notify_transition(policy, &freqs, CPUFREQ_PRECHANGE);
 
 	/* Wait while CPU is busy */
 	rdmsr(MSR_IA32_PERF_STATUS, lo, hi);
@@ -162,7 +161,7 @@ postchange:
 		current_multiplier);
 	}
 #endif
-	cpufreq_notify_transition(&freqs, CPUFREQ_POSTCHANGE);
+	cpufreq_notify_transition(policy, &freqs, CPUFREQ_POSTCHANGE);
 	return err;
 }
 
@@ -190,7 +189,7 @@ static int eps_target(struct cpufreq_policy *policy,
 
 	/* Make frequency transition */
 	dest_state = centaur->freq_table[newstate].index & 0xffff;
-	ret = eps_set_state(centaur, cpu, dest_state);
+	ret = eps_set_state(centaur, policy, dest_state);
 	if (ret)
 		printk(KERN_ERR "eps: Timeout!\n");
 	return ret;
diff --git drivers/cpufreq/elanfreq.c drivers/cpufreq/elanfreq.c
index 960671f..658d860 100644
--- drivers/cpufreq/elanfreq.c
+++ drivers/cpufreq/elanfreq.c
@@ -117,15 +117,15 @@ static unsigned int elanfreq_get_cpu_frequency(unsigned int cpu)
  *	There is no return value.
  */
 
-static void elanfreq_set_cpu_state(unsigned int state)
+static void elanfreq_set_cpu_state(struct cpufreq_policy *policy,
+		unsigned int state)
 {
 	struct cpufreq_freqs    freqs;
 
 	freqs.old = elanfreq_get_cpu_frequency(0);
 	freqs.new = elan_multiplier[state].clock;
-	freqs.cpu = 0; /* elanfreq.c is UP only driver */
 
-	cpufreq_notify_transition(&freqs, CPUFREQ_PRECHANGE);
+	cpufreq_notify_transition(policy, &freqs, CPUFREQ_PRECHANGE);
 
 	printk(KERN_INFO "elanfreq: attempting to set frequency to %i kHz\n",
 			elan_multiplier[state].clock);
@@ -161,7 +161,7 @@ static void elanfreq_set_cpu_state(unsigned int state)
 	udelay(10000);
 	local_irq_enable();
 
-	cpufreq_notify_transition(&freqs, CPUFREQ_POSTCHANGE);
+	cpufreq_notify_transition(policy, &freqs, CPUFREQ_POSTCHANGE);
 };
 
 
@@ -188,7 +188,7 @@ static int elanfreq_target(struct cpufreq_policy *policy,
 				target_freq, relation, &newstate))
 		return -EINVAL;
 
-	elanfreq_set_cpu_state(newstate);
+	elanfreq_set_cpu_state(policy, newstate);
 
 	return 0;
 }
diff --git drivers/cpufreq/exynos-cpufreq.c drivers/cpufreq/exynos-cpufreq.c
index b243a7e..93ff790 100644
--- drivers/cpufreq/exynos-cpufreq.c
+++ drivers/cpufreq/exynos-cpufreq.c
@@ -56,6 +56,7 @@ static int exynos_target(struct cpufreq_policy *policy,
 	mutex_lock(&cpufreq_lock);
 
 	freqs.old = policy->cur;
+	freqs.new = target_freq;
 
 	if (frequency_locked && target_freq != locking_frequency) {
 		ret = -EAGAIN;
@@ -90,7 +91,7 @@ static int exynos_target(struct cpufreq_policy *policy,
 	}
 	arm_volt = volt_table[index];
 
-	cpufreq_notify_transition(&freqs, CPUFREQ_PRECHANGE);
+	cpufreq_notify_transition(policy, &freqs, CPUFREQ_PRECHANGE);
 
 	/* When the new frequency is higher than current frequency */
 	if ((freqs.new > freqs.old) && !safe_arm_volt) {
@@ -105,7 +106,7 @@ static int exynos_target(struct cpufreq_policy *policy,
 	if (freqs.new != freqs.old)
 		exynos_info->set_freq(old_index, index);
 
-	cpufreq_notify_transition(&freqs, CPUFREQ_POSTCHANGE);
+	cpufreq_notify_transition(policy, &freqs, CPUFREQ_POSTCHANGE);
 
 	/* When the new frequency is lower than current frequency */
 	if ((freqs.new < freqs.old) ||
diff --git drivers/cpufreq/freq_table.c drivers/cpufreq/freq_table.c
index 90431cb..dee1426 100644
--- drivers/cpufreq/freq_table.c
+++ drivers/cpufreq/freq_table.c
@@ -61,9 +61,6 @@ int cpufreq_frequency_table_verify(struct cpufreq_policy *policy,
 	pr_debug("request for verification of policy (%u - %u kHz) for cpu %u\n",
 					policy->min, policy->max, policy->cpu);
 
-	if (!cpu_online(policy->cpu))
-		return -EINVAL;
-
 	cpufreq_verify_within_limits(policy, policy->cpuinfo.min_freq,
 				     policy->cpuinfo.max_freq);
 
@@ -119,9 +116,6 @@ int cpufreq_frequency_table_target(struct cpufreq_policy *policy,
 		break;
 	}
 
-	if (!cpu_online(policy->cpu))
-		return -EINVAL;
-
 	for (i = 0; (table[i].frequency != CPUFREQ_TABLE_END); i++) {
 		unsigned int freq = table[i].frequency;
 		if (freq == CPUFREQ_ENTRY_INVALID)
diff --git drivers/cpufreq/gx-suspmod.c drivers/cpufreq/gx-suspmod.c
index 456bee0..3dfc99b 100644
--- drivers/cpufreq/gx-suspmod.c
+++ drivers/cpufreq/gx-suspmod.c
@@ -251,14 +251,13 @@ static unsigned int gx_validate_speed(unsigned int khz, u8 *on_duration,
  * set cpu speed in khz.
  **/
 
-static void gx_set_cpuspeed(unsigned int khz)
+static void gx_set_cpuspeed(struct cpufreq_policy *policy, unsigned int khz)
 {
 	u8 suscfg, pmer1;
 	unsigned int new_khz;
 	unsigned long flags;
 	struct cpufreq_freqs freqs;
 
-	freqs.cpu = 0;
 	freqs.old = gx_get_cpuspeed(0);
 
 	new_khz = gx_validate_speed(khz, &gx_params->on_duration,
@@ -266,11 +265,9 @@ static void gx_set_cpuspeed(unsigned int khz)
 
 	freqs.new = new_khz;
 
-	cpufreq_notify_transition(&freqs, CPUFREQ_PRECHANGE);
+	cpufreq_notify_transition(policy, &freqs, CPUFREQ_PRECHANGE);
 	local_irq_save(flags);
 
-
-
 	if (new_khz != stock_freq) {
 		/* if new khz == 100% of CPU speed, it is special case */
 		switch (gx_params->cs55x0->device) {
@@ -317,7 +314,7 @@ static void gx_set_cpuspeed(unsigned int khz)
 
 	gx_params->pci_suscfg = suscfg;
 
-	cpufreq_notify_transition(&freqs, CPUFREQ_POSTCHANGE);
+	cpufreq_notify_transition(policy, &freqs, CPUFREQ_POSTCHANGE);
 
 	pr_debug("suspend modulation w/ duration of ON:%d us, OFF:%d us\n",
 		gx_params->on_duration * 32, gx_params->off_duration * 32);
@@ -397,7 +394,7 @@ static int cpufreq_gx_target(struct cpufreq_policy *policy,
 		tmp_freq = gx_validate_speed(tmp_freq, &tmp1, &tmp2);
 	}
 
-	gx_set_cpuspeed(tmp_freq);
+	gx_set_cpuspeed(policy, tmp_freq);
 
 	return 0;
 }
diff --git drivers/cpufreq/longhaul.c drivers/cpufreq/longhaul.c
index 53ddbc7..54d4dce 100644
--- drivers/cpufreq/longhaul.c
+++ drivers/cpufreq/longhaul.c
@@ -242,7 +242,8 @@ static void do_powersaver(int cx_address, unsigned int mults_index,
  * Sets a new clock ratio.
  */
 
-static void longhaul_setstate(unsigned int table_index)
+static void longhaul_setstate(struct cpufreq_policy *policy,
+		unsigned int table_index)
 {
 	unsigned int mults_index;
 	int speed, mult;
@@ -267,9 +268,8 @@ static void longhaul_setstate(unsigned int table_index)
 
 	freqs.old = calc_speed(longhaul_get_cpu_mult());
 	freqs.new = speed;
-	freqs.cpu = 0; /* longhaul.c is UP only driver */
 
-	cpufreq_notify_transition(&freqs, CPUFREQ_PRECHANGE);
+	cpufreq_notify_transition(policy, &freqs, CPUFREQ_PRECHANGE);
 
 	pr_debug("Setting to FSB:%dMHz Mult:%d.%dx (%s)\n",
 			fsb, mult/10, mult%10, print_speed(speed/1000));
@@ -386,7 +386,7 @@ retry_loop:
 		}
 	}
 	/* Report true CPU frequency */
-	cpufreq_notify_transition(&freqs, CPUFREQ_POSTCHANGE);
+	cpufreq_notify_transition(policy, &freqs, CPUFREQ_POSTCHANGE);
 
 	if (!bm_timeout)
 		printk(KERN_INFO PFX "Warning: Timeout while waiting for "
@@ -422,7 +422,7 @@ static int guess_fsb(int mult)
 }
 
 
-static int __cpuinit longhaul_get_ranges(void)
+static int longhaul_get_ranges(void)
 {
 	unsigned int i, j, k = 0;
 	unsigned int ratio;
@@ -526,7 +526,7 @@ static int __cpuinit longhaul_get_ranges(void)
 }
 
 
-static void __cpuinit longhaul_setup_voltagescaling(void)
+static void longhaul_setup_voltagescaling(void)
 {
 	union msr_longhaul longhaul;
 	struct mV_pos minvid, maxvid, vid;
@@ -648,7 +648,7 @@ static int longhaul_target(struct cpufreq_policy *policy,
 		return 0;
 
 	if (!can_scale_voltage)
-		longhaul_setstate(table_index);
+		longhaul_setstate(policy, table_index);
 	else {
 		/* On test system voltage transitions exceeding single
 		 * step up or down were turning motherboard off. Both
@@ -663,7 +663,7 @@ static int longhaul_target(struct cpufreq_policy *policy,
 		while (i != table_index) {
 			vid = (longhaul_table[i].index >> 8) & 0x1f;
 			if (vid != current_vid) {
-				longhaul_setstate(i);
+				longhaul_setstate(policy, i);
 				current_vid = vid;
 				msleep(200);
 			}
@@ -672,7 +672,7 @@ static int longhaul_target(struct cpufreq_policy *policy,
 			else
 				i--;
 		}
-		longhaul_setstate(table_index);
+		longhaul_setstate(policy, table_index);
 	}
 	longhaul_index = table_index;
 	return 0;
@@ -780,7 +780,7 @@ static int longhaul_setup_southbridge(void)
 	return 0;
 }
 
-static int __cpuinit longhaul_cpu_init(struct cpufreq_policy *policy)
+static int longhaul_cpu_init(struct cpufreq_policy *policy)
 {
 	struct cpuinfo_x86 *c = &cpu_data(0);
 	char *cpuname = NULL;
@@ -994,15 +994,17 @@ static int __init longhaul_init(void)
 
 static void __exit longhaul_exit(void)
 {
+	struct cpufreq_policy *policy = cpufreq_cpu_get(0);
 	int i;
 
 	for (i = 0; i < numscales; i++) {
 		if (mults[i] == maxmult) {
-			longhaul_setstate(i);
+			longhaul_setstate(policy, i);
 			break;
 		}
 	}
 
+	cpufreq_cpu_put(policy);
 	cpufreq_unregister_driver(&longhaul_driver);
 	kfree(longhaul_table);
 }
diff --git drivers/cpufreq/longhaul.h drivers/cpufreq/longhaul.h
index cbf48fb..1928b92 100644
--- drivers/cpufreq/longhaul.h
+++ drivers/cpufreq/longhaul.h
@@ -56,7 +56,7 @@ union msr_longhaul {
 /*
  * VIA C3 Samuel 1  & Samuel 2 (stepping 0)
  */
-static const int __cpuinitdata samuel1_mults[16] = {
+static const int samuel1_mults[16] = {
 	-1, /* 0000 -> RESERVED */
 	30, /* 0001 ->  3.0x */
 	40, /* 0010 ->  4.0x */
@@ -75,7 +75,7 @@ static const int __cpuinitdata samuel1_mults[16] = {
 	-1, /* 1111 -> RESERVED */
 };
 
-static const int __cpuinitdata samuel1_eblcr[16] = {
+static const int samuel1_eblcr[16] = {
 	50, /* 0000 -> RESERVED */
 	30, /* 0001 ->  3.0x */
 	40, /* 0010 ->  4.0x */
@@ -97,7 +97,7 @@ static const int __cpuinitdata samuel1_eblcr[16] = {
 /*
  * VIA C3 Samuel2 Stepping 1->15
  */
-static const int __cpuinitdata samuel2_eblcr[16] = {
+static const int samuel2_eblcr[16] = {
 	50,  /* 0000 ->  5.0x */
 	30,  /* 0001 ->  3.0x */
 	40,  /* 0010 ->  4.0x */
@@ -119,7 +119,7 @@ static const int __cpuinitdata samuel2_eblcr[16] = {
 /*
  * VIA C3 Ezra
  */
-static const int __cpuinitdata ezra_mults[16] = {
+static const int ezra_mults[16] = {
 	100, /* 0000 -> 10.0x */
 	30,  /* 0001 ->  3.0x */
 	40,  /* 0010 ->  4.0x */
@@ -138,7 +138,7 @@ static const int __cpuinitdata ezra_mults[16] = {
 	120, /* 1111 -> 12.0x */
 };
 
-static const int __cpuinitdata ezra_eblcr[16] = {
+static const int ezra_eblcr[16] = {
 	50,  /* 0000 ->  5.0x */
 	30,  /* 0001 ->  3.0x */
 	40,  /* 0010 ->  4.0x */
@@ -160,7 +160,7 @@ static const int __cpuinitdata ezra_eblcr[16] = {
 /*
  * VIA C3 (Ezra-T) [C5M].
  */
-static const int __cpuinitdata ezrat_mults[32] = {
+static const int ezrat_mults[32] = {
 	100, /* 0000 -> 10.0x */
 	30,  /* 0001 ->  3.0x */
 	40,  /* 0010 ->  4.0x */
@@ -196,7 +196,7 @@ static const int __cpuinitdata ezrat_mults[32] = {
 	-1,  /* 1111 -> RESERVED (12.0x) */
 };
 
-static const int __cpuinitdata ezrat_eblcr[32] = {
+static const int ezrat_eblcr[32] = {
 	50,  /* 0000 ->  5.0x */
 	30,  /* 0001 ->  3.0x */
 	40,  /* 0010 ->  4.0x */
@@ -235,7 +235,7 @@ static const int __cpuinitdata ezrat_eblcr[32] = {
 /*
  * VIA C3 Nehemiah */
 
-static const int __cpuinitdata nehemiah_mults[32] = {
+static const int nehemiah_mults[32] = {
 	100, /* 0000 -> 10.0x */
 	-1, /* 0001 -> 16.0x */
 	40,  /* 0010 ->  4.0x */
@@ -270,7 +270,7 @@ static const int __cpuinitdata nehemiah_mults[32] = {
 	-1, /* 1111 -> 12.0x */
 };
 
-static const int __cpuinitdata nehemiah_eblcr[32] = {
+static const int nehemiah_eblcr[32] = {
 	50,  /* 0000 ->  5.0x */
 	160, /* 0001 -> 16.0x */
 	40,  /* 0010 ->  4.0x */
@@ -315,7 +315,7 @@ struct mV_pos {
 	unsigned short pos;
 };
 
-static const struct mV_pos __cpuinitdata vrm85_mV[32] = {
+static const struct mV_pos vrm85_mV[32] = {
 	{1250, 8},	{1200, 6},	{1150, 4},	{1100, 2},
 	{1050, 0},	{1800, 30},	{1750, 28},	{1700, 26},
 	{1650, 24},	{1600, 22},	{1550, 20},	{1500, 18},
@@ -326,14 +326,14 @@ static const struct mV_pos __cpuinitdata vrm85_mV[32] = {
 	{1475, 17},	{1425, 15},	{1375, 13},	{1325, 11}
 };
 
-static const unsigned char __cpuinitdata mV_vrm85[32] = {
+static const unsigned char mV_vrm85[32] = {
 	0x04,	0x14,	0x03,	0x13,	0x02,	0x12,	0x01,	0x11,
 	0x00,	0x10,	0x0f,	0x1f,	0x0e,	0x1e,	0x0d,	0x1d,
 	0x0c,	0x1c,	0x0b,	0x1b,	0x0a,	0x1a,	0x09,	0x19,
 	0x08,	0x18,	0x07,	0x17,	0x06,	0x16,	0x05,	0x15
 };
 
-static const struct mV_pos __cpuinitdata mobilevrm_mV[32] = {
+static const struct mV_pos mobilevrm_mV[32] = {
 	{1750, 31},	{1700, 30},	{1650, 29},	{1600, 28},
 	{1550, 27},	{1500, 26},	{1450, 25},	{1400, 24},
 	{1350, 23},	{1300, 22},	{1250, 21},	{1200, 20},
@@ -344,7 +344,7 @@ static const struct mV_pos __cpuinitdata mobilevrm_mV[32] = {
 	{675, 3},	{650, 2},	{625, 1},	{600, 0}
 };
 
-static const unsigned char __cpuinitdata mV_mobilevrm[32] = {
+static const unsigned char mV_mobilevrm[32] = {
 	0x1f,	0x1e,	0x1d,	0x1c,	0x1b,	0x1a,	0x19,	0x18,
 	0x17,	0x16,	0x15,	0x14,	0x13,	0x12,	0x11,	0x10,
 	0x0f,	0x0e,	0x0d,	0x0c,	0x0b,	0x0a,	0x09,	0x08,
diff --git drivers/cpufreq/longrun.c drivers/cpufreq/longrun.c
index 8bc9f5f..0fe041d 100644
--- drivers/cpufreq/longrun.c
+++ drivers/cpufreq/longrun.c
@@ -33,7 +33,7 @@ static unsigned int longrun_low_freq, longrun_high_freq;
  * Reads the current LongRun policy by access to MSR_TMTA_LONGRUN_FLAGS
  * and MSR_TMTA_LONGRUN_CTRL
  */
-static void __cpuinit longrun_get_policy(struct cpufreq_policy *policy)
+static void longrun_get_policy(struct cpufreq_policy *policy)
 {
 	u32 msr_lo, msr_hi;
 
@@ -163,7 +163,7 @@ static unsigned int longrun_get(unsigned int cpu)
  * TMTA rules:
  * performance_pctg = (target_freq - low_freq)/(high_freq - low_freq)
  */
-static int __cpuinit longrun_determine_freqs(unsigned int *low_freq,
+static int longrun_determine_freqs(unsigned int *low_freq,
 						      unsigned int *high_freq)
 {
 	u32 msr_lo, msr_hi;
@@ -256,7 +256,7 @@ static int __cpuinit longrun_determine_freqs(unsigned int *low_freq,
 }
 
 
-static int __cpuinit longrun_cpu_init(struct cpufreq_policy *policy)
+static int longrun_cpu_init(struct cpufreq_policy *policy)
 {
 	int result = 0;
 
diff --git drivers/cpufreq/maple-cpufreq.c drivers/cpufreq/maple-cpufreq.c
index 89b178a..41f04e2 100644
--- drivers/cpufreq/maple-cpufreq.c
+++ drivers/cpufreq/maple-cpufreq.c
@@ -158,11 +158,10 @@ static int maple_cpufreq_target(struct cpufreq_policy *policy,
 
 	freqs.old = maple_cpu_freqs[maple_pmode_cur].frequency;
 	freqs.new = maple_cpu_freqs[newstate].frequency;
-	freqs.cpu = 0;
 
-	cpufreq_notify_transition(&freqs, CPUFREQ_PRECHANGE);
+	cpufreq_notify_transition(policy, &freqs, CPUFREQ_PRECHANGE);
 	rc = maple_scom_switch_freq(newstate);
-	cpufreq_notify_transition(&freqs, CPUFREQ_POSTCHANGE);
+	cpufreq_notify_transition(policy, &freqs, CPUFREQ_POSTCHANGE);
 
 	mutex_unlock(&maple_switch_mutex);
 
diff --git drivers/cpufreq/omap-cpufreq.c drivers/cpufreq/omap-cpufreq.c
index 17fa04d..0a87f5a 100644
--- drivers/cpufreq/omap-cpufreq.c
+++ drivers/cpufreq/omap-cpufreq.c
@@ -106,16 +106,12 @@ static int omap_target(struct cpufreq_policy *policy,
 	}
 
 	freqs.old = omap_getspeed(policy->cpu);
-	freqs.cpu = policy->cpu;
 
 	if (freqs.old == freqs.new && policy->cur == freqs.new)
 		return ret;
 
 	/* notifiers */
-	for_each_cpu(i, policy->cpus) {
-		freqs.cpu = i;
-		cpufreq_notify_transition(&freqs, CPUFREQ_PRECHANGE);
-	}
+	cpufreq_notify_transition(policy, &freqs, CPUFREQ_PRECHANGE);
 
 	freq = freqs.new * 1000;
 
@@ -189,10 +185,7 @@ static int omap_target(struct cpufreq_policy *policy,
 
 done:
 	/* notifiers */
-	for_each_cpu(i, policy->cpus) {
-		freqs.cpu = i;
-		cpufreq_notify_transition(&freqs, CPUFREQ_POSTCHANGE);
-	}
+	cpufreq_notify_transition(policy, &freqs, CPUFREQ_POSTCHANGE);
 
 	return ret;
 }
@@ -203,7 +196,7 @@ static inline void freq_table_free(void)
 		opp_free_cpufreq_table(mpu_dev, &freq_table);
 }
 
-static int __cpuinit omap_cpu_init(struct cpufreq_policy *policy)
+static int omap_cpu_init(struct cpufreq_policy *policy)
 {
 	int result = 0;
 
diff --git drivers/cpufreq/p4-clockmod.c drivers/cpufreq/p4-clockmod.c
index 827629c9..4b2e773 100644
--- drivers/cpufreq/p4-clockmod.c
+++ drivers/cpufreq/p4-clockmod.c
@@ -125,10 +125,7 @@ static int cpufreq_p4_target(struct cpufreq_policy *policy,
 		return 0;
 
 	/* notifiers */
-	for_each_cpu(i, policy->cpus) {
-		freqs.cpu = i;
-		cpufreq_notify_transition(&freqs, CPUFREQ_PRECHANGE);
-	}
+	cpufreq_notify_transition(policy, &freqs, CPUFREQ_PRECHANGE);
 
 	/* run on each logical CPU,
 	 * see section 13.15.3 of IA32 Intel Architecture Software
@@ -138,10 +135,7 @@ static int cpufreq_p4_target(struct cpufreq_policy *policy,
 		cpufreq_p4_setdc(i, p4clockmod_table[newstate].index);
 
 	/* notifiers */
-	for_each_cpu(i, policy->cpus) {
-		freqs.cpu = i;
-		cpufreq_notify_transition(&freqs, CPUFREQ_POSTCHANGE);
-	}
+	cpufreq_notify_transition(policy, &freqs, CPUFREQ_POSTCHANGE);
 
 	return 0;
 }
diff --git drivers/cpufreq/pcc-cpufreq.c drivers/cpufreq/pcc-cpufreq.c
index cdc02ac..27492f9 100644
--- drivers/cpufreq/pcc-cpufreq.c
+++ drivers/cpufreq/pcc-cpufreq.c
@@ -215,8 +215,7 @@ static int pcc_cpufreq_target(struct cpufreq_policy *policy,
 		(pcch_virt_addr + pcc_cpu_data->input_offset));
 
 	freqs.new = target_freq;
-	freqs.cpu = cpu;
-	cpufreq_notify_transition(&freqs, CPUFREQ_PRECHANGE);
+	cpufreq_notify_transition(policy, &freqs, CPUFREQ_PRECHANGE);
 
 	input_buffer = 0x1 | (((target_freq * 100)
 			       / (ioread32(&pcch_hdr->nominal) * 1000)) << 8);
@@ -237,7 +236,7 @@ static int pcc_cpufreq_target(struct cpufreq_policy *policy,
 	}
 	iowrite16(0, &pcch_hdr->status);
 
-	cpufreq_notify_transition(&freqs, CPUFREQ_POSTCHANGE);
+	cpufreq_notify_transition(policy, &freqs, CPUFREQ_POSTCHANGE);
 	pr_debug("target: was SUCCESSFUL for cpu %d\n", cpu);
 	spin_unlock(&pcc_lock);
 
diff --git drivers/cpufreq/powernow-k6.c drivers/cpufreq/powernow-k6.c
index af23e0b..ea0222a 100644
--- drivers/cpufreq/powernow-k6.c
+++ drivers/cpufreq/powernow-k6.c
@@ -68,7 +68,8 @@ static int powernow_k6_get_cpu_multiplier(void)
  *
  *   Tries to change the PowerNow! multiplier
  */
-static void powernow_k6_set_state(unsigned int best_i)
+static void powernow_k6_set_state(struct cpufreq_policy *policy,
+		unsigned int best_i)
 {
 	unsigned long outvalue = 0, invalue = 0;
 	unsigned long msrval;
@@ -81,9 +82,8 @@ static void powernow_k6_set_state(unsigned int best_i)
 
 	freqs.old = busfreq * powernow_k6_get_cpu_multiplier();
 	freqs.new = busfreq * clock_ratio[best_i].index;
-	freqs.cpu = 0; /* powernow-k6.c is UP only driver */
 
-	cpufreq_notify_transition(&freqs, CPUFREQ_PRECHANGE);
+	cpufreq_notify_transition(policy, &freqs, CPUFREQ_PRECHANGE);
 
 	/* we now need to transform best_i to the BVC format, see AMD#23446 */
 
@@ -98,7 +98,7 @@ static void powernow_k6_set_state(unsigned int best_i)
 	msrval = POWERNOW_IOPORT + 0x0;
 	wrmsr(MSR_K6_EPMR, msrval, 0); /* disable it again */
 
-	cpufreq_notify_transition(&freqs, CPUFREQ_POSTCHANGE);
+	cpufreq_notify_transition(policy, &freqs, CPUFREQ_POSTCHANGE);
 
 	return;
 }
@@ -136,7 +136,7 @@ static int powernow_k6_target(struct cpufreq_policy *policy,
 				target_freq, relation, &newstate))
 		return -EINVAL;
 
-	powernow_k6_set_state(newstate);
+	powernow_k6_set_state(policy, newstate);
 
 	return 0;
 }
@@ -182,7 +182,7 @@ static int powernow_k6_cpu_exit(struct cpufreq_policy *policy)
 	unsigned int i;
 	for (i = 0; i < 8; i++) {
 		if (i == max_multiplier)
-			powernow_k6_set_state(i);
+			powernow_k6_set_state(policy, i);
 	}
 	cpufreq_frequency_table_put_attr(policy->cpu);
 	return 0;
diff --git drivers/cpufreq/powernow-k7.c drivers/cpufreq/powernow-k7.c
index 334cc2f..f5120d6 100644
--- drivers/cpufreq/powernow-k7.c
+++ drivers/cpufreq/powernow-k7.c
@@ -248,7 +248,7 @@ static void change_VID(int vid)
 }
 
 
-static void change_speed(unsigned int index)
+static void change_speed(struct cpufreq_policy *policy, unsigned int index)
 {
 	u8 fid, vid;
 	struct cpufreq_freqs freqs;
@@ -263,15 +263,13 @@ static void change_speed(unsigned int index)
 	fid = powernow_table[index].index & 0xFF;
 	vid = (powernow_table[index].index & 0xFF00) >> 8;
 
-	freqs.cpu = 0;
-
 	rdmsrl(MSR_K7_FID_VID_STATUS, fidvidstatus.val);
 	cfid = fidvidstatus.bits.CFID;
 	freqs.old = fsb * fid_codes[cfid] / 10;
 
 	freqs.new = powernow_table[index].frequency;
 
-	cpufreq_notify_transition(&freqs, CPUFREQ_PRECHANGE);
+	cpufreq_notify_transition(policy, &freqs, CPUFREQ_PRECHANGE);
 
 	/* Now do the magic poking into the MSRs.  */
 
@@ -292,7 +290,7 @@ static void change_speed(unsigned int index)
 	if (have_a0 == 1)
 		local_irq_enable();
 
-	cpufreq_notify_transition(&freqs, CPUFREQ_POSTCHANGE);
+	cpufreq_notify_transition(policy, &freqs, CPUFREQ_POSTCHANGE);
 }
 
 
@@ -546,7 +544,7 @@ static int powernow_target(struct cpufreq_policy *policy,
 				relation, &newstate))
 		return -EINVAL;
 
-	change_speed(newstate);
+	change_speed(policy, newstate);
 
 	return 0;
 }
@@ -565,7 +563,7 @@ static int powernow_verify(struct cpufreq_policy *policy)
  * We will then get the same kind of behaviour already tested under
  * the "well-known" other OS.
  */
-static int __cpuinit fixup_sgtc(void)
+static int fixup_sgtc(void)
 {
 	unsigned int sgtc;
 	unsigned int m;
@@ -599,7 +597,7 @@ static unsigned int powernow_get(unsigned int cpu)
 }
 
 
-static int __cpuinit acer_cpufreq_pst(const struct dmi_system_id *d)
+static int acer_cpufreq_pst(const struct dmi_system_id *d)
 {
 	printk(KERN_WARNING PFX
 		"%s laptop with broken PST tables in BIOS detected.\n",
@@ -617,7 +615,7 @@ static int __cpuinit acer_cpufreq_pst(const struct dmi_system_id *d)
  * A BIOS update is all that can save them.
  * Mention this, and disable cpufreq.
  */
-static struct dmi_system_id __cpuinitdata powernow_dmi_table[] = {
+static struct dmi_system_id powernow_dmi_table[] = {
 	{
 		.callback = acer_cpufreq_pst,
 		.ident = "Acer Aspire",
@@ -629,7 +627,7 @@ static struct dmi_system_id __cpuinitdata powernow_dmi_table[] = {
 	{ }
 };
 
-static int __cpuinit powernow_cpu_init(struct cpufreq_policy *policy)
+static int powernow_cpu_init(struct cpufreq_policy *policy)
 {
 	union msr_fidvidstatus fidvidstatus;
 	int result;
diff --git drivers/cpufreq/powernow-k8.c drivers/cpufreq/powernow-k8.c
index c0e8164..f419ff7 100644
--- drivers/cpufreq/powernow-k8.c
+++ drivers/cpufreq/powernow-k8.c
@@ -1056,9 +1056,10 @@ static int get_transition_latency(struct powernow_k8_data *data)
 static int transition_frequency_fidvid(struct powernow_k8_data *data,
 		unsigned int index)
 {
+	struct cpufreq_policy *policy;
 	u32 fid = 0;
 	u32 vid = 0;
-	int res, i;
+	int res;
 	struct cpufreq_freqs freqs;
 
 	pr_debug("cpu %d transition to index %u\n", smp_processor_id(), index);
@@ -1087,10 +1088,10 @@ static int transition_frequency_fidvid(struct powernow_k8_data *data,
 	freqs.old = find_khz_freq_from_fid(data->currfid);
 	freqs.new = find_khz_freq_from_fid(fid);
 
-	for_each_cpu(i, data->available_cores) {
-		freqs.cpu = i;
-		cpufreq_notify_transition(&freqs, CPUFREQ_PRECHANGE);
-	}
+	policy = cpufreq_cpu_get(smp_processor_id());
+	cpufreq_cpu_put(policy);
+
+	cpufreq_notify_transition(policy, &freqs, CPUFREQ_PRECHANGE);
 
 	res = transition_fid_vid(data, fid, vid);
 	if (res)
@@ -1098,10 +1099,7 @@ static int transition_frequency_fidvid(struct powernow_k8_data *data,
 
 	freqs.new = find_khz_freq_from_fid(data->currfid);
 
-	for_each_cpu(i, data->available_cores) {
-		freqs.cpu = i;
-		cpufreq_notify_transition(&freqs, CPUFREQ_POSTCHANGE);
-	}
+	cpufreq_notify_transition(policy, &freqs, CPUFREQ_POSTCHANGE);
 	return res;
 }
 
@@ -1244,7 +1242,7 @@ struct init_on_cpu {
 	int rc;
 };
 
-static void __cpuinit powernowk8_cpu_init_on_cpu(void *_init_on_cpu)
+static void powernowk8_cpu_init_on_cpu(void *_init_on_cpu)
 {
 	struct init_on_cpu *init_on_cpu = _init_on_cpu;
 
@@ -1266,7 +1264,7 @@ static void __cpuinit powernowk8_cpu_init_on_cpu(void *_init_on_cpu)
 }
 
 /* per CPU init entry point to the driver */
-static int __cpuinit powernowk8_cpu_init(struct cpufreq_policy *pol)
+static int powernowk8_cpu_init(struct cpufreq_policy *pol)
 {
 	static const char ACPI_PSS_BIOS_BUG_MSG[] =
 		KERN_ERR FW_BUG PFX "No compatible ACPI _PSS objects found.\n"
@@ -1552,7 +1550,7 @@ static struct notifier_block cpb_nb = {
 };
 
 /* driver entry point for init */
-static int __cpuinit powernowk8_init(void)
+static int powernowk8_init(void)
 {
 	unsigned int i, supported_cpus = 0, cpu;
 	int rv;
diff --git drivers/cpufreq/s3c2416-cpufreq.c drivers/cpufreq/s3c2416-cpufreq.c
index 50d2f15..b8ad022 100644
--- drivers/cpufreq/s3c2416-cpufreq.c
+++ drivers/cpufreq/s3c2416-cpufreq.c
@@ -256,7 +256,6 @@ static int s3c2416_cpufreq_set_target(struct cpufreq_policy *policy,
 		goto out;
 	}
 
-	freqs.cpu = 0;
 	freqs.flags = 0;
 	freqs.old = s3c_freq->is_dvs ? FREQ_DVS
 				     : clk_get_rate(s3c_freq->armclk) / 1000;
@@ -274,7 +273,7 @@ static int s3c2416_cpufreq_set_target(struct cpufreq_policy *policy,
 	if (!to_dvs && freqs.old == freqs.new)
 		goto out;
 
-	cpufreq_notify_transition(&freqs, CPUFREQ_PRECHANGE);
+	cpufreq_notify_transition(policy, &freqs, CPUFREQ_PRECHANGE);
 
 	if (to_dvs) {
 		pr_debug("cpufreq: enter dvs\n");
@@ -287,7 +286,7 @@ static int s3c2416_cpufreq_set_target(struct cpufreq_policy *policy,
 		ret = s3c2416_cpufreq_set_armdiv(s3c_freq, freqs.new);
 	}
 
-	cpufreq_notify_transition(&freqs, CPUFREQ_POSTCHANGE);
+	cpufreq_notify_transition(policy, &freqs, CPUFREQ_POSTCHANGE);
 
 out:
 	mutex_unlock(&cpufreq_lock);
diff --git drivers/cpufreq/s3c64xx-cpufreq.c drivers/cpufreq/s3c64xx-cpufreq.c
index 6f9490b..27cacb5 100644
--- drivers/cpufreq/s3c64xx-cpufreq.c
+++ drivers/cpufreq/s3c64xx-cpufreq.c
@@ -84,7 +84,6 @@ static int s3c64xx_cpufreq_set_target(struct cpufreq_policy *policy,
 	if (ret != 0)
 		return ret;
 
-	freqs.cpu = 0;
 	freqs.old = clk_get_rate(armclk) / 1000;
 	freqs.new = s3c64xx_freq_table[i].frequency;
 	freqs.flags = 0;
@@ -95,7 +94,7 @@ static int s3c64xx_cpufreq_set_target(struct cpufreq_policy *policy,
 
 	pr_debug("Transition %d-%dkHz\n", freqs.old, freqs.new);
 
-	cpufreq_notify_transition(&freqs, CPUFREQ_PRECHANGE);
+	cpufreq_notify_transition(policy, &freqs, CPUFREQ_PRECHANGE);
 
 #ifdef CONFIG_REGULATOR
 	if (vddarm && freqs.new > freqs.old) {
@@ -117,7 +116,7 @@ static int s3c64xx_cpufreq_set_target(struct cpufreq_policy *policy,
 		goto err;
 	}
 
-	cpufreq_notify_transition(&freqs, CPUFREQ_POSTCHANGE);
+	cpufreq_notify_transition(policy, &freqs, CPUFREQ_POSTCHANGE);
 
 #ifdef CONFIG_REGULATOR
 	if (vddarm && freqs.new < freqs.old) {
@@ -141,7 +140,7 @@ err_clk:
 	if (clk_set_rate(armclk, freqs.old * 1000) < 0)
 		pr_err("Failed to restore original clock rate\n");
 err:
-	cpufreq_notify_transition(&freqs, CPUFREQ_POSTCHANGE);
+	cpufreq_notify_transition(policy, &freqs, CPUFREQ_POSTCHANGE);
 
 	return ret;
 }
diff --git drivers/cpufreq/s5pv210-cpufreq.c drivers/cpufreq/s5pv210-cpufreq.c
index a484aae..5c77570 100644
--- drivers/cpufreq/s5pv210-cpufreq.c
+++ drivers/cpufreq/s5pv210-cpufreq.c
@@ -229,7 +229,6 @@ static int s5pv210_target(struct cpufreq_policy *policy,
 	}
 
 	freqs.new = s5pv210_freq_table[index].frequency;
-	freqs.cpu = 0;
 
 	if (freqs.new == freqs.old)
 		goto exit;
@@ -256,7 +255,7 @@ static int s5pv210_target(struct cpufreq_policy *policy,
 			goto exit;
 	}
 
-	cpufreq_notify_transition(&freqs, CPUFREQ_PRECHANGE);
+	cpufreq_notify_transition(policy, &freqs, CPUFREQ_PRECHANGE);
 
 	/* Check if there need to change PLL */
 	if ((index == L0) || (priv_index == L0))
@@ -468,7 +467,7 @@ static int s5pv210_target(struct cpufreq_policy *policy,
 		}
 	}
 
-	cpufreq_notify_transition(&freqs, CPUFREQ_POSTCHANGE);
+	cpufreq_notify_transition(policy, &freqs, CPUFREQ_POSTCHANGE);
 
 	if (freqs.new < freqs.old) {
 		regulator_set_voltage(int_regulator,
diff --git drivers/cpufreq/sc520_freq.c drivers/cpufreq/sc520_freq.c
index e42e073..f740b13 100644
--- drivers/cpufreq/sc520_freq.c
+++ drivers/cpufreq/sc520_freq.c
@@ -53,7 +53,8 @@ static unsigned int sc520_freq_get_cpu_frequency(unsigned int cpu)
 	}
 }
 
-static void sc520_freq_set_cpu_state(unsigned int state)
+static void sc520_freq_set_cpu_state(struct cpufreq_policy *policy,
+		unsigned int state)
 {
 
 	struct cpufreq_freqs	freqs;
@@ -61,9 +62,8 @@ static void sc520_freq_set_cpu_state(unsigned int state)
 
 	freqs.old = sc520_freq_get_cpu_frequency(0);
 	freqs.new = sc520_freq_table[state].frequency;
-	freqs.cpu = 0; /* AMD Elan is UP */
 
-	cpufreq_notify_transition(&freqs, CPUFREQ_PRECHANGE);
+	cpufreq_notify_transition(policy, &freqs, CPUFREQ_PRECHANGE);
 
 	pr_debug("attempting to set frequency to %i kHz\n",
 			sc520_freq_table[state].frequency);
@@ -75,7 +75,7 @@ static void sc520_freq_set_cpu_state(unsigned int state)
 
 	local_irq_enable();
 
-	cpufreq_notify_transition(&freqs, CPUFREQ_POSTCHANGE);
+	cpufreq_notify_transition(policy, &freqs, CPUFREQ_POSTCHANGE);
 };
 
 static int sc520_freq_verify(struct cpufreq_policy *policy)
@@ -93,7 +93,7 @@ static int sc520_freq_target(struct cpufreq_policy *policy,
 				target_freq, relation, &newstate))
 		return -EINVAL;
 
-	sc520_freq_set_cpu_state(newstate);
+	sc520_freq_set_cpu_state(policy, newstate);
 
 	return 0;
 }
diff --git drivers/cpufreq/speedstep-centrino.c drivers/cpufreq/speedstep-centrino.c
index 3a953d5..3dbbcc3 100644
--- drivers/cpufreq/speedstep-centrino.c
+++ drivers/cpufreq/speedstep-centrino.c
@@ -457,7 +457,7 @@ static int centrino_target (struct cpufreq_policy *policy,
 	unsigned int	msr, oldmsr = 0, h = 0, cpu = policy->cpu;
 	struct cpufreq_freqs	freqs;
 	int			retval = 0;
-	unsigned int		j, k, first_cpu, tmp;
+	unsigned int		j, first_cpu, tmp;
 	cpumask_var_t covered_cpus;
 
 	if (unlikely(!zalloc_cpumask_var(&covered_cpus, GFP_KERNEL)))
@@ -522,13 +522,8 @@ static int centrino_target (struct cpufreq_policy *policy,
 			pr_debug("target=%dkHz old=%d new=%d msr=%04x\n",
 				target_freq, freqs.old, freqs.new, msr);
 
-			for_each_cpu(k, policy->cpus) {
-				if (!cpu_online(k))
-					continue;
-				freqs.cpu = k;
-				cpufreq_notify_transition(&freqs,
+			cpufreq_notify_transition(policy, &freqs,
 					CPUFREQ_PRECHANGE);
-			}
 
 			first_cpu = 0;
 			/* all but 16 LSB are reserved, treat them with care */
@@ -544,12 +539,7 @@ static int centrino_target (struct cpufreq_policy *policy,
 		cpumask_set_cpu(j, covered_cpus);
 	}
 
-	for_each_cpu(k, policy->cpus) {
-		if (!cpu_online(k))
-			continue;
-		freqs.cpu = k;
-		cpufreq_notify_transition(&freqs, CPUFREQ_POSTCHANGE);
-	}
+	cpufreq_notify_transition(policy, &freqs, CPUFREQ_POSTCHANGE);
 
 	if (unlikely(retval)) {
 		/*
@@ -565,12 +555,8 @@ static int centrino_target (struct cpufreq_policy *policy,
 		tmp = freqs.new;
 		freqs.new = freqs.old;
 		freqs.old = tmp;
-		for_each_cpu(j, policy->cpus) {
-			if (!cpu_online(j))
-				continue;
-			cpufreq_notify_transition(&freqs, CPUFREQ_PRECHANGE);
-			cpufreq_notify_transition(&freqs, CPUFREQ_POSTCHANGE);
-		}
+		cpufreq_notify_transition(policy, &freqs, CPUFREQ_PRECHANGE);
+		cpufreq_notify_transition(policy, &freqs, CPUFREQ_POSTCHANGE);
 	}
 	retval = 0;
 
diff --git drivers/cpufreq/speedstep-ich.c drivers/cpufreq/speedstep-ich.c
index 7432b3a..9dec7fc 100644
--- drivers/cpufreq/speedstep-ich.c
+++ drivers/cpufreq/speedstep-ich.c
@@ -263,7 +263,6 @@ static int speedstep_target(struct cpufreq_policy *policy,
 {
 	unsigned int newstate = 0, policy_cpu;
 	struct cpufreq_freqs freqs;
-	int i;
 
 	if (cpufreq_frequency_table_target(policy, &speedstep_freqs[0],
 				target_freq, relation, &newstate))
@@ -272,7 +271,6 @@ static int speedstep_target(struct cpufreq_policy *policy,
 	policy_cpu = cpumask_any_and(policy->cpus, cpu_online_mask);
 	freqs.old = speedstep_get(policy_cpu);
 	freqs.new = speedstep_freqs[newstate].frequency;
-	freqs.cpu = policy->cpu;
 
 	pr_debug("transiting from %u to %u kHz\n", freqs.old, freqs.new);
 
@@ -280,18 +278,12 @@ static int speedstep_target(struct cpufreq_policy *policy,
 	if (freqs.old == freqs.new)
 		return 0;
 
-	for_each_cpu(i, policy->cpus) {
-		freqs.cpu = i;
-		cpufreq_notify_transition(&freqs, CPUFREQ_PRECHANGE);
-	}
+	cpufreq_notify_transition(policy, &freqs, CPUFREQ_PRECHANGE);
 
 	smp_call_function_single(policy_cpu, _speedstep_set_state, &newstate,
 				 true);
 
-	for_each_cpu(i, policy->cpus) {
-		freqs.cpu = i;
-		cpufreq_notify_transition(&freqs, CPUFREQ_POSTCHANGE);
-	}
+	cpufreq_notify_transition(policy, &freqs, CPUFREQ_POSTCHANGE);
 
 	return 0;
 }
diff --git drivers/cpufreq/speedstep-smi.c drivers/cpufreq/speedstep-smi.c
index 6a457fc..f5a6b70 100644
--- drivers/cpufreq/speedstep-smi.c
+++ drivers/cpufreq/speedstep-smi.c
@@ -252,14 +252,13 @@ static int speedstep_target(struct cpufreq_policy *policy,
 
 	freqs.old = speedstep_freqs[speedstep_get_state()].frequency;
 	freqs.new = speedstep_freqs[newstate].frequency;
-	freqs.cpu = 0; /* speedstep.c is UP only driver */
 
 	if (freqs.old == freqs.new)
 		return 0;
 
-	cpufreq_notify_transition(&freqs, CPUFREQ_PRECHANGE);
+	cpufreq_notify_transition(policy, &freqs, CPUFREQ_PRECHANGE);
 	speedstep_set_state(newstate);
-	cpufreq_notify_transition(&freqs, CPUFREQ_POSTCHANGE);
+	cpufreq_notify_transition(policy, &freqs, CPUFREQ_POSTCHANGE);
 
 	return 0;
 }
diff --git drivers/devfreq/Kconfig drivers/devfreq/Kconfig
index d5a026a..a1dac80 100644
--- drivers/devfreq/Kconfig
+++ drivers/devfreq/Kconfig
@@ -63,6 +63,14 @@ config DEVFREQ_GOV_USERSPACE
 	  Otherwise, the governor does not change the frequnecy
 	  given at the initialization.
 
+config DEVFREQ_GOV_CPUFREQ
+	tristate "CPUfreq"
+	depends on CPU_FREQ
+	help
+	  Chooses frequency based on the online CPUs' current frequency and a
+	  CPU frequency to device frequency mapping table(s). This governor
+	  can be useful for controlling devices such as DDR, cache, CCI, etc.
+
 config DEVFREQ_GOV_MSM_ADRENO_TZ
 	tristate "MSM Adreno Trustzone"
 	depends on MSM_KGSL && MSM_SCM
@@ -71,24 +79,36 @@ config DEVFREQ_GOV_MSM_ADRENO_TZ
 	  Sets the frequency using a "on-demand" algorithm.
 	  This governor is unlikely to be useful for other devices.
 
-config DEVFREQ_GOV_MSM_CPUFREQ
-	bool "MSM CPUfreq"
-	depends on CPU_FREQ_MSM
+config MSM_BIMC_BWMON
+	tristate "MSM BIMC Bandwidth monitor hardware"
+	depends on ARCH_MSM
 	help
-	  MSM CPUfreq based governor for CPU bandwidth voting.  Sets the CPU
-	  to DDR BW vote based on the current CPU frequency.  This governor
-	  is unlikely to be useful for non-MSM devices.
+	  The BIMC Bandwidth monitor hardware allows for monitoring the
+	  traffic coming from each master port connected to the BIMC. It also
+	  has the capability to raise an IRQ when the count exceeds a
+	  programmable limit.
+
+config DEVFREQ_GOV_MSM_BW_HWMON
+	tristate "HW monitor based governor for device BW"
+	depends on ARCH_MSM_KRAIT || ARCH_MSM_BIMC_BWMON
+	help
+	  HW monitor based governor for device to DDR bandwidth voting.
+
+	  When this governor is used for Krait CPUs, it sets the Krait CPU BW
+	  vote by using L2 PM counters to monitor the Krait's use of DDR.
+	  Since this uses some of the Krait PM counters it can conflict with
+	  existing profiling tools.  This governor is unlikely to be useful
+	  for non-MSM devices.
 
-config DEVFREQ_GOV_MSM_CPUBW_HWMON
-	tristate "HW monitor based governor for CPUBW"
-	depends on ARCH_MSM_KRAIT
+config DEVFREQ_GOV_MSM_CACHE_HWMON
+	tristate "HW monitor based governor for cache frequency"
 	help
-	  HW monitor based governor for CPU to DDR bandwidth voting. This
-	  goveror currently supports only Krait L2 PM counters.  Sets the CPU
-	  BW vote by using L2 PM counters to monitor the Krait's use of DDR.
-	  Since this governor uses some of the PM counters it can conflict
-	  with existing profiling tools.  This governor is unlikely to be
-	  useful for other devices.
+	  HW monitor based governor for cache frequency scaling. This
+	  governor currently supports only Krait L2 PM counters.  Sets the
+	  cache frequency by using L2 PM counters to monitor the Krait's use
+	  of the L2.  Since this governor uses some of the PM counters it can
+	  conflict with existing profiling tools.  This governor is unlikely
+	  to be useful for other devices.
 
 comment "DEVFREQ Drivers"
 
@@ -112,4 +132,28 @@ config ARM_EXYNOS4_BUS_DEVFREQ
 	  To operate with optimal voltages, ASV support is required
 	  (CONFIG_EXYNOS_ASV).
 
+config DEVFREQ_SIMPLE_DEV
+	tristate "Device driver for simple clock device with no status info"
+	select DEVFREQ_GOV_PERFORMANCE
+	select DEVFREQ_GOV_POWERSAVE
+	select DEVFREQ_GOV_USERSPACE
+	select DEVFREQ_GOV_CPUFREQ
+	help
+	  Device driver for simple devices that control their frequency using
+	  clock APIs and don't have any form of status reporting.
+
+config MSM_DEVFREQ_DEVBW
+	bool "MSM DEVFREQ device for device master <-> slave IB/AB BW voting"
+	depends on ARCH_MSM
+	select DEVFREQ_GOV_PERFORMANCE
+	select DEVFREQ_GOV_POWERSAVE
+	select DEVFREQ_GOV_USERSPACE
+	select DEVFREQ_GOV_CPUFREQ
+	default n
+	help
+	  Different devfreq governors use this devfreq device to make CPU to
+	  DDR IB/AB bandwidth votes. This driver provides a SoC topology
+	  agnostic interface to so that some of the devfreq governors can be
+	  shared across SoCs.
+
 endif # PM_DEVFREQ
diff --git drivers/devfreq/Makefile drivers/devfreq/Makefile
index 0056585..eefafdb 100644
--- drivers/devfreq/Makefile
+++ drivers/devfreq/Makefile
@@ -3,11 +3,17 @@ obj-$(CONFIG_DEVFREQ_GOV_SIMPLE_ONDEMAND)	+= governor_simpleondemand.o
 obj-$(CONFIG_DEVFREQ_GOV_PERFORMANCE)	+= governor_performance.o
 obj-$(CONFIG_DEVFREQ_GOV_POWERSAVE)	+= governor_powersave.o
 obj-$(CONFIG_DEVFREQ_GOV_USERSPACE)	+= governor_userspace.o
+obj-$(CONFIG_DEVFREQ_GOV_CPUFREQ)	+= governor_cpufreq.o
 obj-$(CONFIG_DEVFREQ_GOV_MSM_ADRENO_TZ)	+= governor_msm_adreno_tz.o
 obj-$(CONFIG_DEVFREQ_GOV_MSM_CPUFREQ)	+= governor_msm_cpufreq.o
-obj-$(CONFIG_DEVFREQ_GOV_MSM_CPUBW_HWMON)	+= governor_cpubw_hwmon.o
+obj-$(CONFIG_ARCH_MSM_KRAIT)		+= krait-l2pm.o
+obj-$(CONFIG_MSM_BIMC_BWMON)		+= bimc-bwmon.o
+obj-$(CONFIG_DEVFREQ_GOV_MSM_BW_HWMON)	+= governor_bw_hwmon.o
+obj-$(CONFIG_DEVFREQ_GOV_MSM_CACHE_HWMON)	+= governor_cache_hwmon.o
 
 # DEVFREQ Drivers
 obj-$(CONFIG_ARM_EXYNOS4_BUS_DEVFREQ)	+= exynos4_bus.o
 obj-$(CONFIG_LGE_DEVFREQ_DFPS)  += g3_display.o
 ccflags-$(CONFIG_LGE_DEVFREQ_DFPS) += -I$(srctree)/drivers/video/msm/mdss
+obj-$(CONFIG_MSM_DEVFREQ_DEVBW)		+= devfreq_devbw.o
+obj-$(CONFIG_DEVFREQ_SIMPLE_DEV)	+= devfreq_simple_dev.o
diff --git drivers/devfreq/bimc-bwmon.c drivers/devfreq/bimc-bwmon.c
new file mode 100644
index 0000000..a10b538
--- /dev/null
+++ drivers/devfreq/bimc-bwmon.c
@@ -0,0 +1,348 @@
+/*
+ * Copyright (c) 2014, The Linux Foundation. All rights reserved.
+ *
+ * This program is free software; you can redistribute it and/or modify
+ * it under the terms of the GNU General Public License version 2 and
+ * only version 2 as published by the Free Software Foundation.
+ *
+ * This program is distributed in the hope that it will be useful,
+ * but WITHOUT ANY WARRANTY; without even the implied warranty of
+ * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
+ * GNU General Public License for more details.
+ */
+
+#define pr_fmt(fmt) "bimc-bwmon: " fmt
+
+#include <linux/kernel.h>
+#include <linux/module.h>
+#include <linux/init.h>
+#include <linux/io.h>
+#include <linux/delay.h>
+#include <linux/err.h>
+#include <linux/errno.h>
+#include <linux/interrupt.h>
+#include <linux/platform_device.h>
+#include <linux/of.h>
+#include <linux/spinlock.h>
+#include "governor_bw_hwmon.h"
+
+#define GLB_INT_STATUS(m)	((m)->global_base + 0x100)
+#define GLB_INT_CLR(m)		((m)->global_base + 0x108)
+#define	GLB_INT_EN(m)		((m)->global_base + 0x10C)
+#define MON_INT_STATUS(m)	((m)->base + 0x100)
+#define MON_INT_CLR(m)		((m)->base + 0x108)
+#define	MON_INT_EN(m)		((m)->base + 0x10C)
+#define	MON_EN(m)		((m)->base + 0x280)
+#define MON_CLEAR(m)		((m)->base + 0x284)
+#define MON_CNT(m)		((m)->base + 0x288)
+#define MON_THRES(m)		((m)->base + 0x290)
+#define MON_MASK(m)		((m)->base + 0x298)
+#define MON_MATCH(m)		((m)->base + 0x29C)
+
+struct bwmon {
+	void __iomem *base;
+	void __iomem *global_base;
+	unsigned int mport;
+	unsigned int irq;
+	struct device *dev;
+	struct bw_hwmon hw;
+};
+
+#define to_bwmon(ptr)		container_of(ptr, struct bwmon, hw)
+
+static DEFINE_SPINLOCK(glb_lock);
+static void mon_enable(struct bwmon *m)
+{
+	writel_relaxed(0x1, MON_EN(m));
+}
+
+static void mon_disable(struct bwmon *m)
+{
+	writel_relaxed(0x0, MON_EN(m));
+}
+
+static void mon_clear(struct bwmon *m)
+{
+	writel_relaxed(0x1, MON_CLEAR(m));
+}
+
+static void mon_irq_enable(struct bwmon *m)
+{
+	u32 val;
+
+	spin_lock(&glb_lock);
+	val = readl_relaxed(GLB_INT_EN(m));
+	val |= 1 << m->mport;
+	writel_relaxed(val, GLB_INT_EN(m));
+	spin_unlock(&glb_lock);
+
+	val = readl_relaxed(MON_INT_EN(m));
+	val |= 0x1;
+	writel_relaxed(val, MON_INT_EN(m));
+}
+
+static void mon_irq_disable(struct bwmon *m)
+{
+	u32 val;
+
+	spin_lock(&glb_lock);
+	val = readl_relaxed(GLB_INT_EN(m));
+	val &= ~(1 << m->mport);
+	writel_relaxed(val, GLB_INT_EN(m));
+	spin_unlock(&glb_lock);
+
+	val = readl_relaxed(MON_INT_EN(m));
+	val &= ~0x1;
+	writel_relaxed(val, MON_INT_EN(m));
+}
+
+static int mon_irq_status(struct bwmon *m)
+{
+	return readl_relaxed(MON_INT_STATUS(m)) & 0x1;
+}
+
+static void mon_irq_clear(struct bwmon *m)
+{
+	writel_relaxed(1 << m->mport, GLB_INT_CLR(m));
+	writel_relaxed(0x1, MON_INT_CLR(m));
+}
+
+static void mon_set_limit(struct bwmon *m, u32 count)
+{
+	writel_relaxed(count, MON_THRES(m));
+	dev_dbg(m->dev, "Thres: %08x\n", count);
+}
+
+static u32 mon_get_limit(struct bwmon *m)
+{
+	return readl_relaxed(MON_THRES(m));
+}
+
+static long mon_get_count(struct bwmon *m)
+{
+	long count;
+
+	count = readl_relaxed(MON_CNT(m));
+	if (mon_irq_status(m))
+		count += mon_get_limit(m);
+	dev_dbg(m->dev, "Count: %ld\n", count);
+
+	return count;
+}
+
+/* ********** CPUBW specific code  ********** */
+
+/* Returns MBps of read/writes for the sampling window. */
+static unsigned int bytes_to_mbps(long long bytes, unsigned int us)
+{
+	bytes *= USEC_PER_SEC;
+	do_div(bytes, us);
+	bytes = DIV_ROUND_UP_ULL(bytes, SZ_1M);
+	return bytes;
+}
+
+static unsigned int mbps_to_bytes(unsigned long mbps, unsigned int ms,
+				  unsigned int tolerance_percent)
+{
+	mbps *= (100 + tolerance_percent) * ms;
+	mbps /= 100;
+	mbps = DIV_ROUND_UP(mbps, MSEC_PER_SEC);
+	mbps *= SZ_1M;
+	return mbps;
+}
+
+static unsigned long meas_bw_and_set_irq(struct bw_hwmon *hw,
+					 unsigned int tol, unsigned int us)
+{
+	unsigned long mbps;
+	u32 limit;
+	unsigned int sample_ms = hw->df->profile->polling_ms;
+	struct bwmon *m = to_bwmon(hw);
+
+	mon_disable(m);
+
+	mbps = mon_get_count(m);
+	mbps = bytes_to_mbps(mbps, us);
+	/* + 1024 is to workaround HW design issue. Needs further tuning. */
+	limit = mbps_to_bytes(mbps + 1024, sample_ms, tol);
+	mon_set_limit(m, limit);
+
+	mon_clear(m);
+	mon_irq_clear(m);
+	mon_enable(m);
+
+	dev_dbg(m->dev, "MBps = %lu\n", mbps);
+	return mbps;
+}
+
+static irqreturn_t bwmon_intr_handler(int irq, void *dev)
+{
+	struct bwmon *m = dev;
+	if (mon_irq_status(m)) {
+		update_bw_hwmon(&m->hw);
+		return IRQ_HANDLED;
+	}
+
+	return IRQ_NONE;
+}
+
+static int start_bw_hwmon(struct bw_hwmon *hw, unsigned long mbps)
+{
+	struct bwmon *m = to_bwmon(hw);
+	u32 limit;
+	int ret;
+
+	ret = request_threaded_irq(m->irq, NULL, bwmon_intr_handler,
+				  IRQF_ONESHOT | IRQF_SHARED,
+				  dev_name(m->dev), m);
+	if (ret) {
+		dev_err(m->dev, "Unable to register interrupt handler! (%d)\n",
+				ret);
+		return ret;
+	}
+
+	mon_disable(m);
+
+	limit = mbps_to_bytes(mbps, hw->df->profile->polling_ms, 0);
+	mon_set_limit(m, limit);
+
+	mon_clear(m);
+	mon_irq_clear(m);
+	mon_irq_enable(m);
+	mon_enable(m);
+
+	return 0;
+}
+
+static void stop_bw_hwmon(struct bw_hwmon *hw)
+{
+	struct bwmon *m = to_bwmon(hw);
+
+	disable_irq(m->irq);
+	free_irq(m->irq, m);
+	mon_disable(m);
+	mon_irq_disable(m);
+	mon_irq_clear(m);
+	mon_clear(m);
+}
+
+static int suspend_bw_hwmon(struct bw_hwmon *hw)
+{
+	struct bwmon *m = to_bwmon(hw);
+
+	disable_irq(m->irq);
+	mon_disable(m);
+	mon_irq_disable(m);
+	mon_irq_clear(m);
+
+	return 0;
+}
+
+static int resume_bw_hwmon(struct bw_hwmon *hw)
+{
+	struct bwmon *m = to_bwmon(hw);
+
+	mon_clear(m);
+	mon_irq_enable(m);
+	mon_enable(m);
+	enable_irq(m->irq);
+
+	return 0;
+}
+
+/*************************************************************************/
+
+static int bimc_bwmon_driver_probe(struct platform_device *pdev)
+{
+	struct device *dev = &pdev->dev;
+	struct resource *res;
+	struct bwmon *m;
+	int ret;
+	u32 data;
+
+	m = devm_kzalloc(dev, sizeof(*m), GFP_KERNEL);
+	if (!m)
+		return -ENOMEM;
+	m->dev = dev;
+
+	ret = of_property_read_u32(dev->of_node, "qcom,mport", &data);
+	if (ret) {
+		dev_err(dev, "mport not found!\n");
+		return ret;
+	}
+	m->mport = data;
+
+	res = platform_get_resource_byname(pdev, IORESOURCE_MEM, "base");
+	if (!res) {
+		dev_err(dev, "base not found!\n");
+		return -EINVAL;
+	}
+	m->base = devm_ioremap(dev, res->start, resource_size(res));
+	if (!m->base) {
+		dev_err(dev, "Unable map base!\n");
+		return -ENOMEM;
+	}
+
+	res = platform_get_resource_byname(pdev, IORESOURCE_MEM, "global_base");
+	if (!res) {
+		dev_err(dev, "global_base not found!\n");
+		return -EINVAL;
+	}
+	m->global_base = devm_ioremap(dev, res->start, resource_size(res));
+	if (!m->global_base) {
+		dev_err(dev, "Unable map global_base!\n");
+		return -ENOMEM;
+	}
+
+	m->irq = platform_get_irq(pdev, 0);
+	if (m->irq < 0) {
+		dev_err(dev, "Unable to get IRQ number\n");
+		return m->irq;
+	}
+
+	m->hw.of_node = of_parse_phandle(dev->of_node, "qcom,target-dev", 0);
+	if (!m->hw.of_node)
+		return -EINVAL;
+	m->hw.start_hwmon = &start_bw_hwmon,
+	m->hw.stop_hwmon = &stop_bw_hwmon,
+	m->hw.suspend_hwmon = &suspend_bw_hwmon,
+	m->hw.resume_hwmon = &resume_bw_hwmon,
+	m->hw.meas_bw_and_set_irq = &meas_bw_and_set_irq,
+
+	ret = register_bw_hwmon(dev, &m->hw);
+	if (ret) {
+		dev_err(dev, "Dev BW hwmon registration failed\n");
+		return ret;
+	}
+
+	return 0;
+}
+
+static struct of_device_id match_table[] = {
+	{ .compatible = "qcom,bimc-bwmon" },
+	{}
+};
+
+static struct platform_driver bimc_bwmon_driver = {
+	.probe = bimc_bwmon_driver_probe,
+	.driver = {
+		.name = "bimc-bwmon",
+		.of_match_table = match_table,
+		.owner = THIS_MODULE,
+	},
+};
+
+static int __init bimc_bwmon_init(void)
+{
+	return platform_driver_register(&bimc_bwmon_driver);
+}
+module_init(bimc_bwmon_init);
+
+static void __exit bimc_bwmon_exit(void)
+{
+	platform_driver_unregister(&bimc_bwmon_driver);
+}
+module_exit(bimc_bwmon_exit);
+
+MODULE_DESCRIPTION("BIMC bandwidth monitor driver");
+MODULE_LICENSE("GPL v2");
diff --git drivers/devfreq/devfreq.c drivers/devfreq/devfreq.c
index d41c214..893dd79 100644
--- drivers/devfreq/devfreq.c
+++ drivers/devfreq/devfreq.c
@@ -115,24 +115,25 @@ EXPORT_SYMBOL(devfreq_get_freq_level);
  */
 static int devfreq_update_status(struct devfreq *devfreq, unsigned long freq)
 {
-	int lev, prev_lev;
+	int lev, prev_lev, ret = 0;
 	unsigned long cur_time;
 
-	lev = devfreq_get_freq_level(devfreq, freq);
-	if (lev < 0)
-		return lev;
-
 	cur_time = jiffies;
-	devfreq->time_in_state[lev] +=
-			 cur_time - devfreq->last_stat_updated;
-	devfreq->last_stat_updated = cur_time;
-
-	if (freq == devfreq->previous_freq)
-		return 0;
 
 	prev_lev = devfreq_get_freq_level(devfreq, devfreq->previous_freq);
-	if (prev_lev < 0)
-		return 0;
+	if (prev_lev < 0) {
+		ret = prev_lev;
+		goto out;
+	}
+
+	devfreq->time_in_state[prev_lev] +=
+			 cur_time - devfreq->last_stat_updated;
+
+	lev = devfreq_get_freq_level(devfreq, freq);
+	if (lev < 0) {
+		ret = lev;
+		goto out;
+	}
 
 	if (lev != prev_lev) {
 		devfreq->trans_table[(prev_lev *
@@ -140,7 +141,9 @@ static int devfreq_update_status(struct devfreq *devfreq, unsigned long freq)
 		devfreq->total_trans++;
 	}
 
-	return 0;
+out:
+	devfreq->last_stat_updated = cur_time;
+	return ret;
 }
 
 /**
@@ -409,7 +412,7 @@ static int devfreq_notifier_call(struct notifier_block *nb, unsigned long type,
  * @devfreq:	the devfreq struct
  * @skip:	skip calling device_unregister().
  */
-static void _remove_devfreq(struct devfreq *devfreq, bool skip)
+static void _remove_devfreq(struct devfreq *devfreq)
 {
 	mutex_lock(&devfreq_list_lock);
 	if (IS_ERR(find_device_devfreq(devfreq->dev.parent))) {
@@ -427,11 +430,6 @@ static void _remove_devfreq(struct devfreq *devfreq, bool skip)
 	if (devfreq->profile->exit)
 		devfreq->profile->exit(devfreq->dev.parent);
 
-	if (!skip && get_device(&devfreq->dev)) {
-		device_unregister(&devfreq->dev);
-		put_device(&devfreq->dev);
-	}
-
 	mutex_destroy(&devfreq->lock);
 	kfree(devfreq);
 }
@@ -441,40 +439,12 @@ static void _remove_devfreq(struct devfreq *devfreq, bool skip)
  * @dev:	the devfreq device
  *
  * This calls _remove_devfreq() if _remove_devfreq() is not called.
- * Note that devfreq_dev_release() could be called by _remove_devfreq() as
- * well as by others unregistering the device.
  */
 static void devfreq_dev_release(struct device *dev)
 {
 	struct devfreq *devfreq = to_devfreq(dev);
 
-	_remove_devfreq(devfreq, true);
-}
-
-/**
- * find_governor_data - Find device specific private data for a governor.
- * @profile: The profile to search.
- * @governor_name: The governor to search for.
- *
- * Look up the device specific data for a governor.
- */
-static void *find_governor_data(struct devfreq_dev_profile *profile,
-				const char *governor_name)
-{
-	void *data = NULL;
-	int i;
-
-	if (profile->governor_data == NULL)
-		return NULL;
-
-	for (i = 0; i < profile->num_governor_data; i++) {
-		if (strncmp(governor_name, profile->governor_data[i].name,
-			     DEVFREQ_NAME_LEN) == 0) {
-			data = profile->governor_data[i].data;
-			break;
-		}
-	}
-	return data;
+	_remove_devfreq(devfreq);
 }
 
 /**
@@ -524,19 +494,17 @@ struct devfreq *devfreq_add_device(struct device *dev,
 	devfreq->profile = profile;
 	strncpy(devfreq->governor_name, governor_name, DEVFREQ_NAME_LEN);
 	devfreq->previous_freq = profile->initial_freq;
-
-	devfreq->data = data ? data : find_governor_data(devfreq->profile,
-							 governor_name);
-
+	devfreq->data = data;
 	devfreq->nb.notifier_call = devfreq_notifier_call;
 
 	devfreq->trans_table =	devm_kzalloc(dev, sizeof(unsigned int) *
 						devfreq->profile->max_state *
 						devfreq->profile->max_state,
 						GFP_KERNEL);
-	devfreq->time_in_state = devm_kzalloc(dev, sizeof(unsigned int) *
-						devfreq->profile->max_state,
-						GFP_KERNEL);
+	devfreq->time_in_state = devm_kzalloc(dev,
+					sizeof(*(devfreq->time_in_state)) *
+					devfreq->profile->max_state,
+					GFP_KERNEL);
 	devfreq->last_stat_updated = jiffies;
 	devfreq_set_freq_limits(devfreq);
 
@@ -592,7 +560,8 @@ int devfreq_remove_device(struct devfreq *devfreq)
 	if (!devfreq)
 		return -EINVAL;
 
-	_remove_devfreq(devfreq, false);
+	device_unregister(&devfreq->dev);
+	put_device(&devfreq->dev);
 
 	return 0;
 }
@@ -790,7 +759,6 @@ static ssize_t store_governor(struct device *dev, struct device_attribute *attr,
 			goto out;
 		}
 	}
-	df->data = find_governor_data(df->profile, str_governor);
 	df->governor = governor;
 	strncpy(df->governor_name, governor->name, DEVFREQ_NAME_LEN);
 	ret = df->governor->event_handler(df, DEVFREQ_GOV_START, NULL);
@@ -987,19 +955,26 @@ static ssize_t show_available_freqs(struct device *d,
 	struct devfreq *df = to_devfreq(d);
 	struct device *dev = df->dev.parent;
 	struct opp *opp;
+	unsigned int i = 0, max_state = df->profile->max_state;
+	bool use_opp;
 	ssize_t count = 0;
 	unsigned long freq = 0;
 
 	rcu_read_lock();
+	use_opp = opp_get_opp_count(dev) > 0;
 	do {
-		opp = opp_find_freq_ceil(dev, &freq);
-		if (IS_ERR(opp))
-			break;
+		if (use_opp) {
+			opp = opp_find_freq_ceil(dev, &freq);
+			if (IS_ERR(opp))
+				break;
+		} else {
+			freq = df->profile->freq_table[i++];
+		}
 
 		count += scnprintf(&buf[count], (PAGE_SIZE - count - 2),
 				   "%lu ", freq);
 		freq++;
-	} while (1);
+	} while (use_opp || (!use_opp && i < max_state));
 	rcu_read_unlock();
 
 	/* Truncate the trailing space */
diff --git drivers/devfreq/devfreq_devbw.c drivers/devfreq/devfreq_devbw.c
new file mode 100644
index 0000000..f01b690
--- /dev/null
+++ drivers/devfreq/devfreq_devbw.c
@@ -0,0 +1,270 @@
+/*
+ * Copyright (c) 2013-2014, The Linux Foundation. All rights reserved.
+ *
+ * This program is free software; you can redistribute it and/or modify
+ * it under the terms of the GNU General Public License version 2 and
+ * only version 2 as published by the Free Software Foundation.
+ *
+ * This program is distributed in the hope that it will be useful,
+ * but WITHOUT ANY WARRANTY; without even the implied warranty of
+ * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
+ * GNU General Public License for more details.
+ */
+
+#define pr_fmt(fmt) "devbw: " fmt
+
+#include <linux/kernel.h>
+#include <linux/module.h>
+#include <linux/init.h>
+#include <linux/io.h>
+#include <linux/delay.h>
+#include <linux/ktime.h>
+#include <linux/time.h>
+#include <linux/err.h>
+#include <linux/errno.h>
+#include <linux/mutex.h>
+#include <linux/interrupt.h>
+#include <linux/devfreq.h>
+#include <linux/of.h>
+#include <trace/events/power.h>
+#include <mach/msm_bus.h>
+#include <mach/msm_bus_board.h>
+
+/* Has to be ULL to prevent overflow where this macro is used. */
+#define MBYTE (1ULL << 20)
+#define MAX_PATHS	2
+#define DBL_BUF		2
+
+struct dev_data {
+	struct msm_bus_vectors vectors[MAX_PATHS * DBL_BUF];
+	struct msm_bus_paths bw_levels[DBL_BUF];
+	struct msm_bus_scale_pdata bw_data;
+	int num_paths;
+	u32 bus_client;
+	int cur_idx;
+	int cur_ab;
+	int cur_ib;
+	long gov_ab;
+	struct devfreq *df;
+	struct devfreq_dev_profile dp;
+};
+
+static int set_bw(struct device *dev, int new_ib, int new_ab)
+{
+	struct dev_data *d = dev_get_drvdata(dev);
+	int i, ret;
+
+	if (d->cur_ib == new_ib && d->cur_ab == new_ab)
+		return 0;
+
+	i = (d->cur_idx + 1) % DBL_BUF;
+
+	d->bw_levels[i].vectors[0].ib = new_ib * MBYTE;
+	d->bw_levels[i].vectors[0].ab = new_ab / d->num_paths * MBYTE;
+	d->bw_levels[i].vectors[1].ib = new_ib * MBYTE;
+	d->bw_levels[i].vectors[1].ab = new_ab / d->num_paths * MBYTE;
+
+	dev_dbg(dev, "BW MBps: AB: %d IB: %d\n", new_ab, new_ib);
+
+	ret = msm_bus_scale_client_update_request(d->bus_client, i);
+	if (ret) {
+		dev_err(dev, "bandwidth request failed (%d)\n", ret);
+	} else {
+		d->cur_idx = i;
+		d->cur_ib = new_ib;
+		d->cur_ab = new_ab;
+	}
+
+	return ret;
+}
+
+static void find_freq(struct devfreq_dev_profile *p, unsigned long *freq,
+			u32 flags)
+{
+	int i;
+	unsigned long atmost, atleast, f;
+
+	atmost = p->freq_table[0];
+	atleast = p->freq_table[p->max_state-1];
+	for (i = 0; i < p->max_state; i++) {
+		f = p->freq_table[i];
+		if (f <= *freq)
+			atmost = max(f, atmost);
+		if (f >= *freq)
+			atleast = min(f, atleast);
+	}
+
+	if (flags & DEVFREQ_FLAG_LEAST_UPPER_BOUND)
+		*freq = atmost;
+	else
+		*freq = atleast;
+}
+
+static int devbw_target(struct device *dev, unsigned long *freq, u32 flags)
+{
+	struct dev_data *d = dev_get_drvdata(dev);
+
+	find_freq(&d->dp, freq, flags);
+	return set_bw(dev, *freq, d->gov_ab);
+}
+
+static int devbw_get_dev_status(struct device *dev,
+				struct devfreq_dev_status *stat)
+{
+	struct dev_data *d = dev_get_drvdata(dev);
+
+	stat->private_data = &d->gov_ab;
+	return 0;
+}
+
+#define PROP_PORTS "qcom,src-dst-ports"
+#define PROP_TBL "qcom,bw-tbl"
+#define PROP_ACTIVE "qcom,active-only"
+
+int devfreq_add_devbw(struct device *dev)
+{
+	struct dev_data *d;
+	struct devfreq_dev_profile *p;
+	u32 *data, ports[MAX_PATHS * 2];
+	const char *gov_name;
+	int ret, len, i, num_paths;
+
+	d = devm_kzalloc(dev, sizeof(*d), GFP_KERNEL);
+	if (!d)
+		return -ENOMEM;
+	dev_set_drvdata(dev, d);
+
+	if (of_find_property(dev->of_node, PROP_PORTS, &len)) {
+		len /= sizeof(ports[0]);
+		if (len % 2 || len > ARRAY_SIZE(ports)) {
+			dev_err(dev, "Unexpected number of ports\n");
+			return -EINVAL;
+		}
+
+		ret = of_property_read_u32_array(dev->of_node, PROP_PORTS,
+						 ports, len);
+		if (ret)
+			return ret;
+
+		num_paths = len / 2;
+	} else {
+		return -EINVAL;
+	}
+
+	d->bw_levels[0].vectors = &d->vectors[0];
+	d->bw_levels[1].vectors = &d->vectors[MAX_PATHS];
+	d->bw_data.usecase = d->bw_levels;
+	d->bw_data.num_usecases = ARRAY_SIZE(d->bw_levels);
+	d->bw_data.name = dev_name(dev);
+	d->bw_data.active_only = of_property_read_bool(dev->of_node,
+							PROP_ACTIVE);
+
+	for (i = 0; i < num_paths; i++) {
+		d->bw_levels[0].vectors[i].src = ports[2 * i];
+		d->bw_levels[0].vectors[i].dst = ports[2 * i + 1];
+		d->bw_levels[1].vectors[i].src = ports[2 * i];
+		d->bw_levels[1].vectors[i].dst = ports[2 * i + 1];
+	}
+	d->bw_levels[0].num_paths = num_paths;
+	d->bw_levels[1].num_paths = num_paths;
+	d->num_paths = num_paths;
+
+	p = &d->dp;
+	p->polling_ms = 50;
+	p->target = devbw_target;
+	p->get_dev_status = devbw_get_dev_status;
+
+	if (of_find_property(dev->of_node, PROP_TBL, &len)) {
+		len /= sizeof(*data);
+		data = devm_kzalloc(dev, len * sizeof(*data), GFP_KERNEL);
+		if (!data)
+			return -ENOMEM;
+
+		p->freq_table = devm_kzalloc(dev,
+					     len * sizeof(*p->freq_table),
+					     GFP_KERNEL);
+		if (!p->freq_table)
+			return -ENOMEM;
+
+		ret = of_property_read_u32_array(dev->of_node, PROP_TBL,
+						 data, len);
+		if (ret)
+			return ret;
+
+		for (i = 0; i < len; i++)
+			p->freq_table[i] = data[i];
+		p->max_state = len;
+	}
+
+	d->bus_client = msm_bus_scale_register_client(&d->bw_data);
+	if (!d->bus_client) {
+		dev_err(dev, "Unable to register bus client\n");
+		return -ENODEV;
+	}
+
+	if (of_property_read_string(dev->of_node, "governor", &gov_name))
+		gov_name = "performance";
+
+	d->df = devfreq_add_device(dev, p, gov_name, NULL);
+	if (IS_ERR(d->df)) {
+		msm_bus_scale_unregister_client(d->bus_client);
+		return PTR_ERR(d->df);
+	}
+
+	return 0;
+}
+
+int devfreq_remove_devbw(struct device *dev)
+{
+	struct dev_data *d = dev_get_drvdata(dev);
+	msm_bus_scale_unregister_client(d->bus_client);
+	devfreq_remove_device(d->df);
+	return 0;
+}
+
+int devfreq_suspend_devbw(struct device *dev)
+{
+	struct dev_data *d = dev_get_drvdata(dev);
+	return devfreq_suspend_device(d->df);
+}
+
+int devfreq_resume_devbw(struct device *dev)
+{
+	struct dev_data *d = dev_get_drvdata(dev);
+	return devfreq_resume_device(d->df);
+}
+
+static int devfreq_devbw_probe(struct platform_device *pdev)
+{
+	return devfreq_add_devbw(&pdev->dev);
+}
+
+static int devfreq_devbw_remove(struct platform_device *pdev)
+{
+	return devfreq_remove_devbw(&pdev->dev);
+}
+
+static struct of_device_id match_table[] = {
+	{ .compatible = "qcom,devbw" },
+	{}
+};
+
+static struct platform_driver devbw_driver = {
+	.probe = devfreq_devbw_probe,
+	.remove = devfreq_devbw_remove,
+	.driver = {
+		.name = "devbw",
+		.of_match_table = match_table,
+		.owner = THIS_MODULE,
+	},
+};
+
+static int __init devbw_init(void)
+{
+	platform_driver_register(&devbw_driver);
+	return 0;
+}
+device_initcall(devbw_init);
+
+MODULE_DESCRIPTION("Device DDR bandwidth voting driver MSM SoCs");
+MODULE_LICENSE("GPL v2");
diff --git drivers/devfreq/devfreq_simple_dev.c drivers/devfreq/devfreq_simple_dev.c
new file mode 100644
index 0000000..653a43d
--- /dev/null
+++ drivers/devfreq/devfreq_simple_dev.c
@@ -0,0 +1,205 @@
+/*
+ * Copyright (c) 2014, The Linux Foundation. All rights reserved.
+ *
+ * This program is free software; you can redistribute it and/or modify
+ * it under the terms of the GNU General Public License version 2 and
+ * only version 2 as published by the Free Software Foundation.
+ *
+ * This program is distributed in the hope that it will be useful,
+ * but WITHOUT ANY WARRANTY; without even the implied warranty of
+ * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
+ * GNU General Public License for more details.
+ */
+
+#define pr_fmt(fmt) "devfreq-simple-dev: " fmt
+
+#include <linux/kernel.h>
+#include <linux/module.h>
+#include <linux/init.h>
+#include <linux/io.h>
+#include <linux/delay.h>
+#include <linux/ktime.h>
+#include <linux/time.h>
+#include <linux/err.h>
+#include <linux/errno.h>
+#include <linux/mutex.h>
+#include <linux/platform_device.h>
+#include <linux/interrupt.h>
+#include <linux/devfreq.h>
+#include <linux/of.h>
+#include <linux/clk.h>
+#include <trace/events/power.h>
+
+struct dev_data {
+	struct clk *clk;
+	struct devfreq *df;
+	struct devfreq_dev_profile profile;
+};
+
+static void find_freq(struct devfreq_dev_profile *p, unsigned long *freq,
+			u32 flags)
+{
+	int i;
+	unsigned long atmost, atleast, f;
+
+	atmost = p->freq_table[0];
+	atleast = p->freq_table[p->max_state-1];
+	for (i = 0; i < p->max_state; i++) {
+		f = p->freq_table[i];
+		if (f <= *freq)
+			atmost = max(f, atmost);
+		if (f >= *freq)
+			atleast = min(f, atleast);
+	}
+
+	if (flags & DEVFREQ_FLAG_LEAST_UPPER_BOUND)
+		*freq = atmost;
+	else
+		*freq = atleast;
+}
+
+static int dev_target(struct device *dev, unsigned long *freq, u32 flags)
+{
+	struct dev_data *d = dev_get_drvdata(dev);
+
+	find_freq(&d->profile, freq, flags);
+	return clk_set_rate(d->clk, *freq * 1000);
+}
+
+static int dev_get_cur_freq(struct device *dev, unsigned long *freq)
+{
+	struct dev_data *d = dev_get_drvdata(dev);
+	unsigned long f;
+
+	f = clk_get_rate(d->clk);
+	if (IS_ERR_VALUE(f))
+		return f;
+	*freq = f / 1000;
+	return 0;
+}
+
+#define PROP_TBL "freq-tbl-khz"
+static int devfreq_clock_probe(struct platform_device *pdev)
+{
+	struct device *dev = &pdev->dev;
+	struct dev_data *d;
+	struct devfreq_dev_profile *p;
+	u32 *data, poll;
+	const char *gov_name;
+	const char *clk_name;
+	int ret, len, i, j;
+	unsigned long f;
+
+	d = devm_kzalloc(dev, sizeof(*d), GFP_KERNEL);
+	if (!d)
+		return -ENOMEM;
+	platform_set_drvdata(pdev, d);
+
+	if (of_property_read_string(dev->of_node, "clock-name", &clk_name)) {
+		pr_err("%s can't find clock-name attribute!", __func__);
+		return -EINVAL;
+	}
+
+	d->clk = devm_clk_get(dev, clk_name);
+	if (IS_ERR(d->clk)) {
+        pr_err("%s clock lookup failed! %s", __func__, clk_name);
+		return PTR_ERR(d->clk);
+    }
+
+	if (!of_find_property(dev->of_node, PROP_TBL, &len)) {
+        pr_err("%s prop table lookup failed!", __func__);
+		return -EINVAL;
+    }
+
+	len /= sizeof(*data);
+	data = devm_kzalloc(dev, len * sizeof(*data), GFP_KERNEL);
+	if (!data)
+		return -ENOMEM;
+
+	p = &d->profile;
+	p->freq_table = devm_kzalloc(dev, len * sizeof(*p->freq_table),
+				     GFP_KERNEL);
+	if (!p->freq_table) {
+        pr_err("%s no freq table!", __func__);
+		return -ENOMEM;
+    }
+
+	ret = of_property_read_u32_array(dev->of_node, PROP_TBL, data, len);
+	if (ret)
+		return ret;
+
+	j = 0;
+	for (i = 0; i < len; i++) {
+		f = clk_round_rate(d->clk, data[i] * 1000);
+		if (IS_ERR_VALUE(f))
+			dev_warn(dev, "Unable to find dev rate for %d KHz",
+				 data[i]);
+		else
+			p->freq_table[j++] = f / 1000;
+	}
+	p->max_state = j;
+	devm_kfree(dev, data);
+
+	if (p->max_state == 0) {
+		dev_err(dev, "Error parsing property %s!\n", PROP_TBL);
+		return -EINVAL;
+	}
+
+	p->target = dev_target;
+	p->get_cur_freq = dev_get_cur_freq;
+	ret = dev_get_cur_freq(dev, &p->initial_freq);
+	if (ret)
+		return ret;
+
+	p->polling_ms = 50;
+	if (!of_property_read_u32(dev->of_node, "polling-ms", &poll))
+		p->polling_ms = poll;
+
+	if (of_property_read_string(dev->of_node, "governor", &gov_name))
+		gov_name = "performance";
+
+
+	d->df = devfreq_add_device(dev, p, gov_name, NULL);
+	if (IS_ERR(d->df))
+		return PTR_ERR(d->df);
+
+	return 0;
+}
+
+static int devfreq_clock_remove(struct platform_device *pdev)
+{
+	struct dev_data *d = platform_get_drvdata(pdev);
+	devfreq_remove_device(d->df);
+	return 0;
+}
+
+static struct of_device_id match_table[] = {
+	{ .compatible = "devfreq-simple-dev" },
+	{}
+};
+
+static struct platform_driver devfreq_clock_driver = {
+	.probe = devfreq_clock_probe,
+	.remove = devfreq_clock_remove,
+	.driver = {
+		.name = "devfreq-simple-dev",
+		.of_match_table = match_table,
+		.owner = THIS_MODULE,
+	},
+};
+
+static int __init devfreq_clock_init(void)
+{
+	platform_driver_register(&devfreq_clock_driver);
+	return 0;
+}
+device_initcall(devfreq_clock_init);
+
+static void __exit devfreq_clock_exit(void)
+{
+	platform_driver_unregister(&devfreq_clock_driver);
+}
+module_exit(devfreq_clock_exit);
+
+MODULE_DESCRIPTION("Devfreq driver for setting generic device clock frequency");
+MODULE_LICENSE("GPL v2");
diff --git drivers/devfreq/governor_bw_hwmon.c drivers/devfreq/governor_bw_hwmon.c
new file mode 100644
index 0000000..f0c14e4
--- /dev/null
+++ drivers/devfreq/governor_bw_hwmon.c
@@ -0,0 +1,551 @@
+/*
+ * Copyright (c) 2013-2014, The Linux Foundation. All rights reserved.
+ *
+ * This program is free software; you can redistribute it and/or modify
+ * it under the terms of the GNU General Public License version 2 and
+ * only version 2 as published by the Free Software Foundation.
+ *
+ * This program is distributed in the hope that it will be useful,
+ * but WITHOUT ANY WARRANTY; without even the implied warranty of
+ * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
+ * GNU General Public License for more details.
+ */
+
+#define pr_fmt(fmt) "bw-hwmon: " fmt
+
+#include <linux/kernel.h>
+#include <linux/module.h>
+#include <linux/init.h>
+#include <linux/io.h>
+#include <linux/delay.h>
+#include <linux/ktime.h>
+#include <linux/time.h>
+#include <linux/err.h>
+#include <linux/errno.h>
+#include <linux/mutex.h>
+#include <linux/interrupt.h>
+#include <linux/platform_device.h>
+#include <linux/of.h>
+#include <linux/devfreq.h>
+#include "governor.h"
+#include "governor_bw_hwmon.h"
+
+struct hwmon_node {
+	unsigned int tolerance_percent;
+	unsigned int guard_band_mbps;
+	unsigned int decay_rate;
+	unsigned int io_percent;
+	unsigned int bw_step;
+	unsigned long prev_ab;
+	unsigned long *dev_ab;
+	unsigned long resume_freq;
+	unsigned long resume_ab;
+	ktime_t prev_ts;
+	bool mon_started;
+	struct list_head list;
+	void *orig_data;
+	struct bw_hwmon *hw;
+	struct devfreq_governor *gov;
+	struct attribute_group *attr_grp;
+};
+
+static LIST_HEAD(hwmon_list);
+static DEFINE_MUTEX(list_lock);
+
+static int use_cnt;
+static DEFINE_MUTEX(state_lock);
+
+#define show_attr(name) \
+static ssize_t show_##name(struct device *dev,				\
+			struct device_attribute *attr, char *buf)	\
+{									\
+	struct devfreq *df = to_devfreq(dev);				\
+	struct hwmon_node *hw = df->data;				\
+	return snprintf(buf, PAGE_SIZE, "%u\n", hw->name);		\
+}
+
+#define store_attr(name, _min, _max) \
+static ssize_t store_##name(struct device *dev,				\
+			struct device_attribute *attr, const char *buf,	\
+			size_t count)					\
+{									\
+	struct devfreq *df = to_devfreq(dev);				\
+	struct hwmon_node *hw = df->data;				\
+	int ret;							\
+	unsigned int val;						\
+	ret = sscanf(buf, "%u", &val);					\
+	if (ret != 1)							\
+		return -EINVAL;						\
+	val = max(val, _min);						\
+	val = min(val, _max);						\
+	hw->name = val;							\
+	return count;							\
+}
+
+#define gov_attr(__attr, min, max)	\
+show_attr(__attr)			\
+store_attr(__attr, min, max)		\
+static DEVICE_ATTR(__attr, 0644, show_##__attr, store_##__attr)
+
+#define MIN_MS	10U
+#define MAX_MS	500U
+
+static unsigned long measure_bw_and_set_irq(struct hwmon_node *node)
+{
+	ktime_t ts;
+	unsigned int us;
+	unsigned long mbps;
+	struct bw_hwmon *hw = node->hw;
+
+	/*
+	 * Since we are stopping the counters, we don't want this short work
+	 * to be interrupted by other tasks and cause the measurements to be
+	 * wrong. Not blocking interrupts to avoid affecting interrupt
+	 * latency and since they should be short anyway because they run in
+	 * atomic context.
+	 */
+	preempt_disable();
+
+	ts = ktime_get();
+	us = ktime_to_us(ktime_sub(ts, node->prev_ts));
+	if (!us)
+		us = 1;
+
+	mbps = hw->meas_bw_and_set_irq(hw, node->tolerance_percent, us);
+	node->prev_ts = ts;
+
+	preempt_enable();
+
+	dev_dbg(hw->df->dev.parent, "BW MBps = %6lu, period = %u\n", mbps, us);
+
+	return mbps;
+}
+
+static void compute_bw(struct hwmon_node *node, int mbps,
+			unsigned long *freq, unsigned long *ab)
+{
+	int new_bw;
+
+	mbps += node->guard_band_mbps;
+
+	if (mbps > node->prev_ab) {
+		new_bw = mbps;
+	} else {
+		new_bw = mbps * node->decay_rate
+			+ node->prev_ab * (100 - node->decay_rate);
+		new_bw /= 100;
+	}
+
+	node->prev_ab = new_bw;
+	if (ab)
+		*ab = roundup(new_bw, node->bw_step);
+	*freq = (new_bw * 100) / node->io_percent;
+}
+
+static struct hwmon_node *find_hwmon_node(struct devfreq *df)
+{
+	struct hwmon_node *node, *found = NULL;
+
+	mutex_lock(&list_lock);
+	list_for_each_entry(node, &hwmon_list, list)
+		if (node->hw->dev == df->dev.parent ||
+		    node->hw->of_node == df->dev.parent->of_node ||
+		    (!node->hw->dev && !node->hw->of_node &&
+		     node->gov == df->governor)) {
+			found = node;
+			break;
+		}
+	mutex_unlock(&list_lock);
+
+	return found;
+}
+
+#define TOO_SOON_US	(1 * USEC_PER_MSEC)
+int update_bw_hwmon(struct bw_hwmon *hwmon)
+{
+	struct devfreq *df;
+	struct hwmon_node *node;
+	ktime_t ts;
+	unsigned int us;
+	int ret;
+
+	if (!hwmon)
+		return -EINVAL;
+	df = hwmon->df;
+	if (!df)
+		return -ENODEV;
+	node = find_hwmon_node(df);
+	if (!node)
+		return -ENODEV;
+
+	if (!node->mon_started)
+		return -EBUSY;
+
+	dev_dbg(df->dev.parent, "Got update request\n");
+	devfreq_monitor_stop(df);
+
+	/*
+	 * Don't recalc bandwidth if the interrupt comes right after a
+	 * previous bandwidth calculation.  This is done for two reasons:
+	 *
+	 * 1. Sampling the BW during a very short duration can result in a
+	 *    very inaccurate measurement due to very short bursts.
+	 * 2. This can only happen if the limit was hit very close to the end
+	 *    of the previous sample period. Which means the current BW
+	 *    estimate is not very off and doesn't need to be readjusted.
+	 */
+	ts = ktime_get();
+	us = ktime_to_us(ktime_sub(ts, node->prev_ts));
+	if (us > TOO_SOON_US) {
+		mutex_lock(&df->lock);
+		ret = update_devfreq(df);
+		if (ret)
+			dev_err(df->dev.parent,
+				"Unable to update freq on request!\n");
+		mutex_unlock(&df->lock);
+	}
+
+	devfreq_monitor_start(df);
+
+	return 0;
+}
+
+static int start_monitor(struct devfreq *df, bool init)
+{
+	struct hwmon_node *node = df->data;
+	struct bw_hwmon *hw = node->hw;
+	struct device *dev = df->dev.parent;
+	unsigned long mbps;
+	int ret;
+
+	node->prev_ts = ktime_get();
+
+	if (init) {
+		node->prev_ab = 0;
+		node->resume_freq = 0;
+		node->resume_ab = 0;
+		mbps = (df->previous_freq * node->io_percent) / 100;
+		ret = hw->start_hwmon(hw, mbps);
+	} else {
+		ret = hw->resume_hwmon(hw);
+	}
+
+	if (ret) {
+		dev_err(dev, "Unable to start HW monitor! (%d)\n", ret);
+		return ret;
+	}
+
+	if (init)
+		devfreq_monitor_start(df);
+	else
+		devfreq_monitor_resume(df);
+
+	node->mon_started = true;
+
+	return 0;
+}
+
+static void stop_monitor(struct devfreq *df, bool init)
+{
+	struct hwmon_node *node = df->data;
+	struct bw_hwmon *hw = node->hw;
+
+	node->mon_started = false;
+
+	if (init) {
+		devfreq_monitor_stop(df);
+		hw->stop_hwmon(hw);
+	} else {
+		devfreq_monitor_suspend(df);
+		hw->suspend_hwmon(hw);
+	}
+
+}
+
+static int gov_start(struct devfreq *df)
+{
+	int ret = 0;
+	struct device *dev = df->dev.parent;
+	struct hwmon_node *node;
+	struct bw_hwmon *hw;
+	struct devfreq_dev_status stat;
+
+	node = find_hwmon_node(df);
+	if (!node) {
+		dev_err(dev, "Unable to find HW monitor!\n");
+		return -ENODEV;
+	}
+	hw = node->hw;
+
+	stat.private_data = NULL;
+	if (df->profile->get_dev_status)
+		ret = df->profile->get_dev_status(df->dev.parent, &stat);
+	if (ret || !stat.private_data)
+		dev_warn(dev, "Device doesn't take AB votes!\n");
+	else
+		node->dev_ab = stat.private_data;
+
+	hw->df = df;
+	node->orig_data = df->data;
+	df->data = node;
+
+	if (start_monitor(df, true))
+		goto err_start;
+
+	ret = sysfs_create_group(&df->dev.kobj, node->attr_grp);
+	if (ret)
+		goto err_sysfs;
+
+	return 0;
+
+err_sysfs:
+	stop_monitor(df, true);
+err_start:
+	df->data = node->orig_data;
+	node->orig_data = NULL;
+	hw->df = NULL;
+	node->dev_ab = NULL;
+	return ret;
+}
+
+static void gov_stop(struct devfreq *df)
+{
+	struct hwmon_node *node = df->data;
+	struct bw_hwmon *hw = node->hw;
+
+	sysfs_remove_group(&df->dev.kobj, node->attr_grp);
+	stop_monitor(df, true);
+	df->data = node->orig_data;
+	node->orig_data = NULL;
+	hw->df = NULL;
+	/*
+	 * Not all governors know about this additional extended device
+	 * configuration. To avoid leaving the extended configuration at a
+	 * stale state, set it to 0 and let the next governor take it from
+	 * there.
+	 */
+	if (node->dev_ab)
+		*node->dev_ab = 0;
+	node->dev_ab = NULL;
+}
+
+static int gov_suspend(struct devfreq *df)
+{
+	struct hwmon_node *node = df->data;
+	unsigned long resume_freq = df->previous_freq;
+	unsigned long resume_ab = *node->dev_ab;
+
+	if (!node->hw->suspend_hwmon)
+		return -ENOSYS;
+
+	if (node->resume_freq) {
+		dev_warn(df->dev.parent, "Governor already suspended!\n");
+		return -EBUSY;
+	}
+
+	stop_monitor(df, false);
+
+	mutex_lock(&df->lock);
+	update_devfreq(df);
+	mutex_unlock(&df->lock);
+
+	node->resume_freq = resume_freq;
+	node->resume_ab = resume_ab;
+
+	return 0;
+}
+
+static int gov_resume(struct devfreq *df)
+{
+	struct hwmon_node *node = df->data;
+
+	if (!node->hw->resume_hwmon)
+		return -ENOSYS;
+
+	if (!node->resume_freq) {
+		dev_warn(df->dev.parent, "Governor already resumed!\n");
+		return -EBUSY;
+	}
+
+	mutex_lock(&df->lock);
+	update_devfreq(df);
+	mutex_unlock(&df->lock);
+
+	node->resume_freq = 0;
+	node->resume_ab = 0;
+
+	return start_monitor(df, false);
+}
+
+static int devfreq_bw_hwmon_get_freq(struct devfreq *df,
+					unsigned long *freq,
+					u32 *flag)
+{
+	unsigned long mbps;
+	struct hwmon_node *node = df->data;
+
+	/* Suspend/resume sequence */
+	if (!node->mon_started) {
+		*freq = node->resume_freq;
+		*node->dev_ab = node->resume_ab;
+		return 0;
+	}
+
+	mbps = measure_bw_and_set_irq(node);
+	compute_bw(node, mbps, freq, node->dev_ab);
+
+	return 0;
+}
+
+gov_attr(tolerance_percent, 0U, 30U);
+gov_attr(guard_band_mbps, 0U, 2000U);
+gov_attr(decay_rate, 0U, 100U);
+gov_attr(io_percent, 1U, 100U);
+gov_attr(bw_step, 50U, 1000U);
+
+static struct attribute *dev_attr[] = {
+	&dev_attr_tolerance_percent.attr,
+	&dev_attr_guard_band_mbps.attr,
+	&dev_attr_decay_rate.attr,
+	&dev_attr_io_percent.attr,
+	&dev_attr_bw_step.attr,
+	NULL,
+};
+
+static struct attribute_group dev_attr_group = {
+	.name = "bw_hwmon",
+	.attrs = dev_attr,
+};
+
+static int devfreq_bw_hwmon_ev_handler(struct devfreq *df,
+					unsigned int event, void *data)
+{
+	int ret;
+	unsigned int sample_ms;
+
+	switch (event) {
+	case DEVFREQ_GOV_START:
+		sample_ms = df->profile->polling_ms;
+		sample_ms = max(MIN_MS, sample_ms);
+		sample_ms = min(MAX_MS, sample_ms);
+		df->profile->polling_ms = sample_ms;
+
+		ret = gov_start(df);
+		if (ret)
+			return ret;
+
+		dev_dbg(df->dev.parent,
+			"Enabled dev BW HW monitor governor\n");
+		break;
+
+	case DEVFREQ_GOV_STOP:
+		gov_stop(df);
+		dev_dbg(df->dev.parent,
+			"Disabled dev BW HW monitor governor\n");
+		break;
+
+	case DEVFREQ_GOV_INTERVAL:
+		sample_ms = *(unsigned int *)data;
+		sample_ms = max(MIN_MS, sample_ms);
+		sample_ms = min(MAX_MS, sample_ms);
+		devfreq_interval_update(df, &sample_ms);
+		break;
+
+	case DEVFREQ_GOV_SUSPEND:
+		ret = gov_suspend(df);
+		if (ret) {
+			dev_err(df->dev.parent,
+				"Unable to suspend BW HW mon governor (%d)\n",
+				ret);
+			return ret;
+		}
+
+		dev_dbg(df->dev.parent, "Suspended BW HW mon governor\n");
+		break;
+
+	case DEVFREQ_GOV_RESUME:
+		ret = gov_resume(df);
+		if (ret) {
+			dev_err(df->dev.parent,
+				"Unable to resume BW HW mon governor (%d)\n",
+				ret);
+			return ret;
+		}
+
+		dev_dbg(df->dev.parent, "Resumed BW HW mon governor\n");
+		break;
+	}
+
+	return 0;
+}
+
+static struct devfreq_governor devfreq_gov_bw_hwmon = {
+	.name = "bw_hwmon",
+	.get_target_freq = devfreq_bw_hwmon_get_freq,
+	.event_handler = devfreq_bw_hwmon_ev_handler,
+};
+
+int register_bw_hwmon(struct device *dev, struct bw_hwmon *hwmon)
+{
+	int ret = 0;
+	struct hwmon_node *node;
+	struct attribute_group *attr_grp;
+
+	if (!hwmon->gov && !hwmon->dev && !hwmon->of_node)
+		return -EINVAL;
+
+	node = devm_kzalloc(dev, sizeof(*node), GFP_KERNEL);
+	if (!node) {
+		dev_err(dev, "Unable to register gov. Out of memory!\n");
+		return -ENOMEM;
+	}
+
+	if (hwmon->gov) {
+		attr_grp = devm_kzalloc(dev, sizeof(*attr_grp), GFP_KERNEL);
+		if (!attr_grp)
+			return -ENOMEM;
+
+		hwmon->gov->get_target_freq = devfreq_bw_hwmon_get_freq;
+		hwmon->gov->event_handler = devfreq_bw_hwmon_ev_handler;
+		attr_grp->name = hwmon->gov->name;
+		attr_grp->attrs = dev_attr;
+
+		node->gov = hwmon->gov;
+		node->attr_grp = attr_grp;
+	} else {
+		node->gov = &devfreq_gov_bw_hwmon;
+		node->attr_grp = &dev_attr_group;
+	}
+
+	node->tolerance_percent = 10;
+	node->guard_band_mbps = 100;
+	node->decay_rate = 90;
+	node->io_percent = 16;
+	node->bw_step = 190;
+	node->hw = hwmon;
+
+	mutex_lock(&list_lock);
+	list_add_tail(&node->list, &hwmon_list);
+	mutex_unlock(&list_lock);
+
+	if (hwmon->gov) {
+		ret = devfreq_add_governor(hwmon->gov);
+	} else {
+		mutex_lock(&state_lock);
+		if (!use_cnt)
+			ret = devfreq_add_governor(&devfreq_gov_bw_hwmon);
+		if (!ret)
+			use_cnt++;
+		mutex_unlock(&state_lock);
+	}
+
+	if (!ret)
+		dev_info(dev, "BW HWmon governor registered.\n");
+	else
+		dev_err(dev, "BW HWmon governor registration failed!\n");
+
+	return ret;
+}
+
+MODULE_DESCRIPTION("HW monitor based dev DDR bandwidth voting driver");
+MODULE_LICENSE("GPL v2");
diff --git drivers/devfreq/governor_bw_hwmon.h drivers/devfreq/governor_bw_hwmon.h
new file mode 100644
index 0000000..30de542
--- /dev/null
+++ drivers/devfreq/governor_bw_hwmon.h
@@ -0,0 +1,76 @@
+/*
+ * Copyright (c) 2014, The Linux Foundation. All rights reserved.
+ *
+ * This program is free software; you can redistribute it and/or modify
+ * it under the terms of the GNU General Public License version 2 and
+ * only version 2 as published by the Free Software Foundation.
+ *
+ * This program is distributed in the hope that it will be useful,
+ * but WITHOUT ANY WARRANTY; without even the implied warranty of
+ * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
+ * GNU General Public License for more details.
+ */
+
+#ifndef _GOVERNOR_BW_HWMON_H
+#define _GOVERNOR_BW_HWMON_H
+
+#include <linux/kernel.h>
+#include <linux/devfreq.h>
+
+/**
+ * struct bw_hwmon - dev BW HW monitor info
+ * @start_hwmon:		Start the HW monitoring of the dev BW
+ * @stop_hwmon:			Stop the HW monitoring of dev BW
+ * @is_valid_irq:		Check whether the IRQ was triggered by the
+ *				counters used to monitor dev BW.
+ * @meas_bw_and_set_irq:	Return the measured bandwidth and set up the
+ *				IRQ to fire if the usage exceeds current
+ *				measurement by @tol percent.
+ * @irq:			IRQ number that corresponds to this HW
+ *				monitor.
+ * @dev:			Pointer to device that this HW monitor can
+ *				monitor.
+ * @of_node:			OF node of device that this HW monitor can
+ *				monitor.
+ * @gov:			devfreq_governor struct that should be used
+ *				when registering this HW monitor with devfreq.
+ *				Only the name field is expected to be
+ *				initialized.
+ * @df:				Devfreq node that this HW monitor is being
+ *				used for. NULL when not actively in use and
+ *				non-NULL when in use.
+ *
+ * One of dev, of_node or governor_name needs to be specified for a
+ * successful registration.
+ *
+ */
+struct bw_hwmon {
+	int (*start_hwmon)(struct bw_hwmon *hw, unsigned long mbps);
+	void (*stop_hwmon)(struct bw_hwmon *hw);
+	int (*suspend_hwmon)(struct bw_hwmon *hw);
+	int (*resume_hwmon)(struct bw_hwmon *hw);
+	unsigned long (*meas_bw_and_set_irq)(struct bw_hwmon *hw,
+					unsigned int tol, unsigned int us);
+	struct device *dev;
+	struct device_node *of_node;
+	struct devfreq_governor *gov;
+
+	struct devfreq *df;
+};
+
+#ifdef CONFIG_DEVFREQ_GOV_MSM_BW_HWMON
+int register_bw_hwmon(struct device *dev, struct bw_hwmon *hwmon);
+int update_bw_hwmon(struct bw_hwmon *hwmon);
+#else
+static inline int register_bw_hwmon(struct device *dev,
+					struct bw_hwmon *hwmon)
+{
+	return 0;
+}
+int update_bw_hwmon(struct bw_hwmon *hwmon)
+{
+	return 0;
+}
+#endif
+
+#endif /* _GOVERNOR_BW_HWMON_H */
diff --git drivers/devfreq/governor_cache_hwmon.c drivers/devfreq/governor_cache_hwmon.c
new file mode 100644
index 0000000..5554474
--- /dev/null
+++ drivers/devfreq/governor_cache_hwmon.c
@@ -0,0 +1,416 @@
+/*
+ * Copyright (c) 2014, The Linux Foundation. All rights reserved.
+ *
+ * This program is free software; you can redistribute it and/or modify
+ * it under the terms of the GNU General Public License version 2 and
+ * only version 2 as published by the Free Software Foundation.
+ *
+ * This program is distributed in the hope that it will be useful,
+ * but WITHOUT ANY WARRANTY; without even the implied warranty of
+ * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
+ * GNU General Public License for more details.
+ */
+
+#define pr_fmt(fmt) "cache-hwmon: " fmt
+
+#include <linux/kernel.h>
+#include <linux/module.h>
+#include <linux/init.h>
+#include <linux/io.h>
+#include <linux/delay.h>
+#include <linux/ktime.h>
+#include <linux/time.h>
+#include <linux/err.h>
+#include <linux/errno.h>
+#include <linux/mutex.h>
+#include <linux/interrupt.h>
+#include <linux/platform_device.h>
+#include <linux/of.h>
+#include <linux/devfreq.h>
+#include "governor.h"
+#include "governor_cache_hwmon.h"
+
+struct cache_hwmon_node {
+	unsigned int cycles_per_low_req;
+	unsigned int cycles_per_med_req;
+	unsigned int cycles_per_high_req;
+	unsigned int min_busy;
+	unsigned int max_busy;
+	unsigned int tolerance_mrps;
+	unsigned int guard_band_mhz;
+	unsigned int decay_rate;
+	unsigned long prev_mhz;
+	ktime_t prev_ts;
+	bool mon_started;
+	struct list_head list;
+	void *orig_data;
+	struct cache_hwmon *hw;
+	struct attribute_group *attr_grp;
+};
+
+static LIST_HEAD(cache_hwmon_list);
+static DEFINE_MUTEX(list_lock);
+
+static int use_cnt;
+static DEFINE_MUTEX(state_lock);
+
+#define show_attr(name) \
+static ssize_t show_##name(struct device *dev,				\
+			struct device_attribute *attr, char *buf)	\
+{									\
+	struct devfreq *df = to_devfreq(dev);				\
+	struct cache_hwmon_node *hw = df->data;				\
+	return snprintf(buf, PAGE_SIZE, "%u\n", hw->name);		\
+}
+
+#define store_attr(name, _min, _max) \
+static ssize_t store_##name(struct device *dev,				\
+			struct device_attribute *attr, const char *buf,	\
+			size_t count)					\
+{									\
+	int ret;							\
+	unsigned int val;						\
+	struct devfreq *df = to_devfreq(dev);				\
+	struct cache_hwmon_node *hw = df->data;				\
+	ret = sscanf(buf, "%u", &val);					\
+	if (ret != 1)							\
+		return -EINVAL;						\
+	val = max(val, _min);						\
+	val = min(val, _max);						\
+	hw->name = val;							\
+	return count;							\
+}
+
+#define gov_attr(__attr, min, max)	\
+show_attr(__attr)			\
+store_attr(__attr, min, max)		\
+static DEVICE_ATTR(__attr, 0644, show_##__attr, store_##__attr)
+
+#define MIN_MS	10U
+#define MAX_MS	500U
+
+static struct cache_hwmon_node *find_hwmon_node(struct devfreq *df)
+{
+	struct cache_hwmon_node *node, *found = NULL;
+
+	mutex_lock(&list_lock);
+	list_for_each_entry(node, &cache_hwmon_list, list)
+		if (node->hw->dev == df->dev.parent ||
+		    node->hw->of_node == df->dev.parent->of_node) {
+			found = node;
+			break;
+		}
+	mutex_unlock(&list_lock);
+
+	return found;
+}
+
+static unsigned long measure_mrps_and_set_irq(struct cache_hwmon_node *node,
+			struct mrps_stats *stat)
+{
+	ktime_t ts;
+	unsigned int us;
+	struct cache_hwmon *hw = node->hw;
+
+	/*
+	 * Since we are stopping the counters, we don't want this short work
+	 * to be interrupted by other tasks and cause the measurements to be
+	 * wrong. Not blocking interrupts to avoid affecting interrupt
+	 * latency and since they should be short anyway because they run in
+	 * atomic context.
+	 */
+	preempt_disable();
+
+	ts = ktime_get();
+	us = ktime_to_us(ktime_sub(ts, node->prev_ts));
+	if (!us)
+		us = 1;
+
+	hw->meas_mrps_and_set_irq(hw, node->tolerance_mrps, us, stat);
+	node->prev_ts = ts;
+
+	preempt_enable();
+
+	dev_dbg(hw->df->dev.parent,
+		"stat H=%3lu, M=%3lu, L=%3lu, T=%3lu, b=%3u, f=%4lu, us=%d\n",
+		 stat->mrps[HIGH], stat->mrps[MED], stat->mrps[LOW],
+		 stat->mrps[HIGH] + stat->mrps[MED] + stat->mrps[LOW],
+		 stat->busy_percent, hw->df->previous_freq / 1000, us);
+
+	return 0;
+}
+
+static void compute_cache_freq(struct cache_hwmon_node *node,
+		struct mrps_stats *mrps, unsigned long *freq)
+{
+	unsigned long new_mhz;
+	unsigned int busy;
+
+	new_mhz = mrps->mrps[HIGH] * node->cycles_per_high_req
+		+ mrps->mrps[MED] * node->cycles_per_med_req
+		+ mrps->mrps[LOW] * node->cycles_per_low_req;
+
+	busy = max(node->min_busy, mrps->busy_percent);
+	busy = min(node->max_busy, busy);
+
+	new_mhz *= 100;
+	new_mhz /= busy;
+
+	if (new_mhz < node->prev_mhz) {
+		new_mhz = new_mhz * node->decay_rate + node->prev_mhz
+				* (100 - node->decay_rate);
+		new_mhz /= 100;
+	}
+	node->prev_mhz = new_mhz;
+
+	new_mhz += node->guard_band_mhz;
+	*freq = new_mhz * 1000;
+}
+
+#define TOO_SOON_US	(1 * USEC_PER_MSEC)
+int update_cache_hwmon(struct cache_hwmon *hwmon)
+{
+	struct cache_hwmon_node *node;
+	struct devfreq *df;
+	ktime_t ts;
+	unsigned int us;
+	int ret;
+
+	if (!hwmon)
+		return -EINVAL;
+	df = hwmon->df;
+	if (!df)
+		return -ENODEV;
+	node = df->data;
+	if (!node)
+		return -ENODEV;
+	if (!node->mon_started)
+		return -EBUSY;
+
+	dev_dbg(df->dev.parent, "Got update request\n");
+	devfreq_monitor_stop(df);
+
+	/*
+	 * Don't recalc cache freq if the interrupt comes right after a
+	 * previous cache freq calculation.  This is done for two reasons:
+	 *
+	 * 1. Sampling the cache request during a very short duration can
+	 *    result in a very inaccurate measurement due to very short
+	 *    bursts.
+	 * 2. This can only happen if the limit was hit very close to the end
+	 *    of the previous sample period. Which means the current cache
+	 *    request estimate is not very off and doesn't need to be
+	 *    readjusted.
+	 */
+	ts = ktime_get();
+	us = ktime_to_us(ktime_sub(ts, node->prev_ts));
+	if (us > TOO_SOON_US) {
+		mutex_lock(&df->lock);
+		ret = update_devfreq(df);
+		if (ret)
+			dev_err(df->dev.parent,
+				"Unable to update freq on request!\n");
+		mutex_unlock(&df->lock);
+	}
+
+	devfreq_monitor_start(df);
+
+	return 0;
+}
+
+static int devfreq_cache_hwmon_get_freq(struct devfreq *df,
+					unsigned long *freq,
+					u32 *flag)
+{
+	struct mrps_stats stat;
+	struct cache_hwmon_node *node = df->data;
+
+	memset(&stat, 0, sizeof(stat));
+	measure_mrps_and_set_irq(node, &stat);
+	compute_cache_freq(node, &stat, freq);
+
+	return 0;
+}
+
+gov_attr(cycles_per_low_req, 1U, 100U);
+gov_attr(cycles_per_med_req, 1U, 100U);
+gov_attr(cycles_per_high_req, 1U, 100U);
+gov_attr(min_busy, 1U, 100U);
+gov_attr(max_busy, 1U, 100U);
+gov_attr(tolerance_mrps, 0U, 100U);
+gov_attr(guard_band_mhz, 0U, 500U);
+gov_attr(decay_rate, 0U, 100U);
+
+static struct attribute *dev_attr[] = {
+	&dev_attr_cycles_per_low_req.attr,
+	&dev_attr_cycles_per_med_req.attr,
+	&dev_attr_cycles_per_high_req.attr,
+	&dev_attr_min_busy.attr,
+	&dev_attr_max_busy.attr,
+	&dev_attr_tolerance_mrps.attr,
+	&dev_attr_guard_band_mhz.attr,
+	&dev_attr_decay_rate.attr,
+	NULL,
+};
+
+static struct attribute_group dev_attr_group = {
+	.name = "cache_hwmon",
+	.attrs = dev_attr,
+};
+
+static int start_monitoring(struct devfreq *df)
+{
+	int ret;
+	struct mrps_stats mrps;
+	struct device *dev = df->dev.parent;
+	struct cache_hwmon_node *node;
+	struct cache_hwmon *hw;
+
+	node = find_hwmon_node(df);
+	if (!node) {
+		dev_err(dev, "Unable to find HW monitor!\n");
+		return -ENODEV;
+	}
+	hw = node->hw;
+	hw->df = df;
+	node->orig_data = df->data;
+	df->data = node;
+
+	node->prev_ts = ktime_get();
+	node->prev_mhz = 0;
+	mrps.mrps[HIGH] = (df->previous_freq / 1000) - node->guard_band_mhz;
+	mrps.mrps[HIGH] /= node->cycles_per_high_req;
+	mrps.mrps[MED] = mrps.mrps[LOW] = 0;
+
+	ret = hw->start_hwmon(hw, &mrps);
+	if (ret) {
+		dev_err(dev, "Unable to start HW monitor!\n");
+		goto err_start;
+	}
+
+	devfreq_monitor_start(df);
+	node->mon_started = true;
+
+	ret = sysfs_create_group(&df->dev.kobj, &dev_attr_group);
+	if (ret) {
+		dev_err(dev, "Error creating sys entries!\n");
+		goto sysfs_fail;
+	}
+
+	return 0;
+
+sysfs_fail:
+	node->mon_started = false;
+	devfreq_monitor_stop(df);
+	hw->stop_hwmon(hw);
+err_start:
+	df->data = node->orig_data;
+	node->orig_data = NULL;
+	hw->df = NULL;
+	return ret;
+}
+
+static void stop_monitoring(struct devfreq *df)
+{
+	struct cache_hwmon_node *node = df->data;
+	struct cache_hwmon *hw = node->hw;
+
+	sysfs_remove_group(&df->dev.kobj, &dev_attr_group);
+	node->mon_started = false;
+	devfreq_monitor_stop(df);
+	hw->stop_hwmon(hw);
+	df->data = node->orig_data;
+	node->orig_data = NULL;
+	hw->df = NULL;
+}
+
+static int devfreq_cache_hwmon_ev_handler(struct devfreq *df,
+					unsigned int event, void *data)
+{
+	int ret;
+	unsigned int sample_ms;
+
+	switch (event) {
+	case DEVFREQ_GOV_START:
+		sample_ms = df->profile->polling_ms;
+		sample_ms = max(MIN_MS, sample_ms);
+		sample_ms = min(MAX_MS, sample_ms);
+		df->profile->polling_ms = sample_ms;
+
+		ret = start_monitoring(df);
+		if (ret)
+			return ret;
+
+		dev_dbg(df->dev.parent, "Enabled Cache HW monitor governor\n");
+		break;
+
+	case DEVFREQ_GOV_STOP:
+		stop_monitoring(df);
+		dev_dbg(df->dev.parent, "Disabled Cache HW monitor governor\n");
+		break;
+
+	case DEVFREQ_GOV_INTERVAL:
+		sample_ms = *(unsigned int *)data;
+		sample_ms = max(MIN_MS, sample_ms);
+		sample_ms = min(MAX_MS, sample_ms);
+		devfreq_interval_update(df, &sample_ms);
+		break;
+	}
+
+	return 0;
+}
+
+static struct devfreq_governor devfreq_cache_hwmon = {
+	.name = "cache_hwmon",
+	.get_target_freq = devfreq_cache_hwmon_get_freq,
+	.event_handler = devfreq_cache_hwmon_ev_handler,
+};
+
+int register_cache_hwmon(struct device *dev, struct cache_hwmon *hwmon)
+{
+	int ret = 0;
+	struct cache_hwmon_node *node;
+
+	if (!hwmon->dev && !hwmon->of_node)
+		return -EINVAL;
+
+	node = devm_kzalloc(dev, sizeof(*node), GFP_KERNEL);
+	if (!node) {
+		dev_err(dev, "Unable to register gov. Out of memory!\n");
+		return -ENOMEM;
+	}
+
+	node->cycles_per_med_req = 20;
+	node->cycles_per_high_req = 35;
+	node->min_busy = 100;
+	node->max_busy = 100;
+	node->tolerance_mrps = 5;
+	node->guard_band_mhz = 100;
+	node->decay_rate = 90;
+	node->hw = hwmon;
+	node->attr_grp = &dev_attr_group;
+
+	mutex_lock(&state_lock);
+	if (!use_cnt) {
+		ret = devfreq_add_governor(&devfreq_cache_hwmon);
+		if (!ret)
+			use_cnt++;
+	}
+	mutex_unlock(&state_lock);
+
+	if (!ret) {
+		dev_info(dev, "Cache HWmon governor registered.\n");
+	} else {
+		dev_err(dev, "Failed to add Cache HWmon governor\n");
+		return ret;
+	}
+
+	mutex_lock(&list_lock);
+	list_add_tail(&node->list, &cache_hwmon_list);
+	mutex_unlock(&list_lock);
+
+	return ret;
+}
+
+MODULE_DESCRIPTION("HW monitor based cache freq driver");
+MODULE_LICENSE("GPL v2");
diff --git drivers/devfreq/governor_cache_hwmon.h drivers/devfreq/governor_cache_hwmon.h
new file mode 100644
index 0000000..b3748ac
--- /dev/null
+++ drivers/devfreq/governor_cache_hwmon.h
@@ -0,0 +1,71 @@
+/*
+ * Copyright (c) 2014, The Linux Foundation. All rights reserved.
+ *
+ * This program is free software; you can redistribute it and/or modify
+ * it under the terms of the GNU General Public License version 2 and
+ * only version 2 as published by the Free Software Foundation.
+ *
+ * This program is distributed in the hope that it will be useful,
+ * but WITHOUT ANY WARRANTY; without even the implied warranty of
+ * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
+ * GNU General Public License for more details.
+ */
+
+#ifndef _GOVERNOR_CACHE_HWMON_H
+#define _GOVERNOR_CACHE_HWMON_H
+
+#include <linux/kernel.h>
+#include <linux/devfreq.h>
+
+enum request_group {
+	HIGH,
+	MED,
+	LOW,
+	MAX_NUM_GROUPS,
+};
+
+struct mrps_stats {
+	unsigned long mrps[MAX_NUM_GROUPS];
+	unsigned int busy_percent;
+};
+
+/**
+ * struct cache_hwmon - devfreq Cache HW monitor info
+ * @start_hwmon:	Start the HW monitoring
+ * @stop_hwmon:		Stop the HW monitoring
+ * @meas_mrps_and_set_irq:	Return the measured count and set up the
+ *				IRQ to fire if usage exceeds current
+ *				measurement by @tol percent.
+ * @dev:		device that this HW monitor can monitor.
+ * @of_node:		OF node of device that this HW monitor can monitor.
+ * @df:			Devfreq node that this HW montior is being used
+ *			for. NULL when not actively in use, and non-NULL
+ *			when in use.
+ */
+struct cache_hwmon {
+	int (*start_hwmon)(struct cache_hwmon *hw, struct mrps_stats *mrps);
+	void (*stop_hwmon)(struct cache_hwmon *hw);
+	unsigned long (*meas_mrps_and_set_irq)(struct cache_hwmon *hw,
+					unsigned int tol, unsigned int us,
+					struct mrps_stats *mrps);
+	struct device *dev;
+	struct device_node *of_node;
+	struct devfreq *df;
+};
+
+#ifdef CONFIG_DEVFREQ_GOV_MSM_CACHE_HWMON
+int register_cache_hwmon(struct device *dev, struct cache_hwmon *hwmon);
+int update_cache_hwmon(struct cache_hwmon *hwmon);
+#else
+static inline int register_cache_hwmon(struct device *dev,
+				       struct cache_hwmon *hwmon)
+{
+	return 0;
+}
+int update_cache_hwmon(struct cache_hwmon *hwmon)
+{
+	return 0;
+}
+#endif
+
+#endif /* _GOVERNOR_CACHE_HWMON_H */
diff --git drivers/devfreq/governor_cpubw_hwmon.c drivers/devfreq/governor_cpubw_hwmon.c
deleted file mode 100644
index 23448ae..0000000
--- drivers/devfreq/governor_cpubw_hwmon.c
+++ /dev/null
@@ -1,470 +0,0 @@
-/*
- * Copyright (c) 2013-2014, The Linux Foundation. All rights reserved.
- *
- * This program is free software; you can redistribute it and/or modify
- * it under the terms of the GNU General Public License version 2 and
- * only version 2 as published by the Free Software Foundation.
- *
- * This program is distributed in the hope that it will be useful,
- * but WITHOUT ANY WARRANTY; without even the implied warranty of
- * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
- * GNU General Public License for more details.
- */
-
-#define pr_fmt(fmt) "cpubw-hwmon: " fmt
-
-#include <linux/kernel.h>
-#include <asm/sizes.h>
-#include <linux/module.h>
-#include <linux/init.h>
-#include <linux/io.h>
-#include <linux/delay.h>
-#include <linux/ktime.h>
-#include <linux/time.h>
-#include <linux/err.h>
-#include <linux/errno.h>
-#include <linux/mutex.h>
-#include <linux/interrupt.h>
-#include <linux/platform_device.h>
-#include <linux/of.h>
-#include <linux/devfreq.h>
-#include "governor.h"
-
-#include <mach/msm-krait-l2-accessors.h>
-
-#define L2PMRESR2		0x412
-#define L2PMCR			0x400
-#define L2PMCNTENCLR		0x402
-#define L2PMCNTENSET		0x403
-#define L2PMINTENCLR		0x404
-#define L2PMINTENSET		0x405
-#define L2PMOVSR		0x406
-#define L2PMOVSSET		0x407
-#define L2PMnEVCNTCR(n)		(0x420 + n * 0x10)
-#define L2PMnEVCNTR(n)		(0x421 + n * 0x10)
-#define L2PMnEVCNTSR(n)		(0x422 + n * 0x10)
-#define L2PMnEVFILTER(n)	(0x423 + n * 0x10)
-#define L2PMnEVTYPER(n)		(0x424 + n * 0x10)
-
-#define show_attr(name) \
-static ssize_t show_##name(struct device *dev,				\
-			struct device_attribute *attr, char *buf)	\
-{									\
-	return sprintf(buf, "%u\n", name);				\
-}
-
-#define store_attr(name, _min, _max) \
-static ssize_t store_##name(struct device *dev,				\
-			struct device_attribute *attr, const char *buf,	\
-			size_t count)					\
-{									\
-	int ret;							\
-	unsigned int val;						\
-	ret = sscanf(buf, "%u", &val);					\
-	if (ret != 1)							\
-		return -EINVAL;						\
-	val = max(val, _min);				\
-	val = min(val, _max);				\
-	name = val;							\
-	return count;							\
-}
-
-#define gov_attr(__attr, min, max)	\
-show_attr(__attr)			\
-store_attr(__attr, min, max)		\
-static DEVICE_ATTR(__attr, 0644, show_##__attr, store_##__attr)
-
-
-static int l2pm_irq;
-static unsigned int bytes_per_beat;
-static unsigned int tolerance_percent = 10;
-static unsigned int guard_band_mbps = 100;
-static unsigned int decay_rate = 90;
-static unsigned int io_percent = 16;
-static unsigned int bw_step = 190;
-
-#define MIN_MS	1U
-#define MAX_MS	500U
-static unsigned int sample_ms = 50;
-static u32 prev_r_start_val;
-static u32 prev_w_start_val;
-static unsigned long prev_ab;
-static ktime_t prev_ts;
-
-#define RD_MON	0
-#define WR_MON	1
-static void mon_init(void)
-{
-	/* Set up counters 0/1 to count write/read beats */
-	set_l2_indirect_reg(L2PMRESR2, 0x8B0B0000);
-	set_l2_indirect_reg(L2PMnEVCNTCR(RD_MON), 0x0);
-	set_l2_indirect_reg(L2PMnEVCNTCR(WR_MON), 0x0);
-	set_l2_indirect_reg(L2PMnEVCNTR(RD_MON), 0xFFFFFFFF);
-	set_l2_indirect_reg(L2PMnEVCNTR(WR_MON), 0xFFFFFFFF);
-	set_l2_indirect_reg(L2PMnEVFILTER(RD_MON), 0xF003F);
-	set_l2_indirect_reg(L2PMnEVFILTER(WR_MON), 0xF003F);
-	set_l2_indirect_reg(L2PMnEVTYPER(RD_MON), 0xA);
-	set_l2_indirect_reg(L2PMnEVTYPER(WR_MON), 0xB);
-}
-
-static void global_mon_enable(bool en)
-{
-	u32 regval;
-
-	/* Global counter enable */
-	regval = get_l2_indirect_reg(L2PMCR);
-	if (en)
-		regval |= BIT(0);
-	else
-		regval &= ~BIT(0);
-	set_l2_indirect_reg(L2PMCR, regval);
-}
-
-static void mon_enable(int n)
-{
-	/* Clear previous overflow state for event counter n */
-	set_l2_indirect_reg(L2PMOVSR, BIT(n));
-
-	/* Enable event counter n */
-	set_l2_indirect_reg(L2PMCNTENSET, BIT(n));
-}
-
-static void mon_disable(int n)
-{
-	/* Disable event counter n */
-	set_l2_indirect_reg(L2PMCNTENCLR, BIT(n));
-}
-
-static void mon_irq_enable(int n, bool en)
-{
-	if (en)
-		set_l2_indirect_reg(L2PMINTENSET, BIT(n));
-	else
-		set_l2_indirect_reg(L2PMINTENCLR, BIT(n));
-}
-
-/* Returns start counter value to be used with mon_get_mbps() */
-static u32 mon_set_limit_mbyte(int n, unsigned int mbytes)
-{
-	u32 regval, beats;
-
-	beats = mult_frac(mbytes, SZ_1M, bytes_per_beat);
-	regval = 0xFFFFFFFF - beats;
-	set_l2_indirect_reg(L2PMnEVCNTR(n), regval);
-	pr_debug("EV%d MB: %d, start val: %x\n", n, mbytes, regval);
-
-	return regval;
-}
-
-long mon_get_count(int n, u32 start_val)
-{
-	u32 overflow, count;
-
-	count = get_l2_indirect_reg(L2PMnEVCNTR(n));
-	overflow = get_l2_indirect_reg(L2PMOVSR);
-
-	pr_debug("EV%d ov: %x, cnt: %x\n", n, overflow, count);
-
-	if (overflow & BIT(n))
-		return 0xFFFFFFFF - start_val + count;
-	else
-		return count - start_val;
-}
-
-/* Returns MBps of read/writes for the sampling window. */
-unsigned int beats_to_mbps(long long beats, unsigned int us)
-{
-	beats *= USEC_PER_SEC;
-	beats *= bytes_per_beat;
-	do_div(beats, us);
-	beats = DIV_ROUND_UP_ULL(beats, SZ_1M);
-
-	return beats;
-}
-
-static int to_limit(int mbps)
-{
-	mbps *= (100 + tolerance_percent) * sample_ms;
-	mbps /= 100;
-	mbps = DIV_ROUND_UP(mbps, MSEC_PER_SEC);
-	return mbps;
-}
-
-unsigned long measure_bw_and_set_irq(void)
-{
-	long r_mbps, w_mbps, mbps;
-	ktime_t ts;
-	unsigned int us;
-
-	/*
-	 * Since we are stopping the counters, we don't want this short work
-	 * to be interrupted by other tasks and cause the measurements to be
-	 * wrong. Not blocking interrupts to avoid affecting interrupt
-	 * latency and since they should be short anyway because they run in
-	 * atomic context.
-	 */
-	preempt_disable();
-
-	ts = ktime_get();
-	us = ktime_to_us(ktime_sub(ts, prev_ts));
-	if (!us)
-		us = 1;
-
-	mon_disable(RD_MON);
-	mon_disable(WR_MON);
-
-	r_mbps = mon_get_count(RD_MON, prev_r_start_val);
-	r_mbps = beats_to_mbps(r_mbps, us);
-	w_mbps = mon_get_count(WR_MON, prev_w_start_val);
-	w_mbps = beats_to_mbps(w_mbps, us);
-
-	prev_r_start_val = mon_set_limit_mbyte(RD_MON, to_limit(r_mbps));
-	prev_w_start_val = mon_set_limit_mbyte(WR_MON, to_limit(w_mbps));
-	prev_ts = ts;
-
-	mon_enable(RD_MON);
-	mon_enable(WR_MON);
-
-	preempt_enable();
-
-	mbps = r_mbps + w_mbps;
-	pr_debug("R/W/BW/us = %ld/%ld/%ld/%d\n", r_mbps, w_mbps, mbps, us);
-
-	return mbps;
-}
-
-static void compute_bw(int mbps, unsigned long *freq, unsigned long *ab)
-{
-	int new_bw;
-
-	mbps += guard_band_mbps;
-
-	if (mbps > prev_ab) {
-		new_bw = mbps;
-	} else {
-		new_bw = mbps * decay_rate + prev_ab * (100 - decay_rate);
-		new_bw /= 100;
-	}
-
-	prev_ab = new_bw;
-	*ab = roundup(new_bw, bw_step);
-	*freq = (new_bw * 100) / io_percent;
-}
-
-#define TOO_SOON_US	(1 * USEC_PER_MSEC)
-static irqreturn_t mon_intr_handler(int irq, void *dev)
-{
-	struct devfreq *df = dev;
-	ktime_t ts;
-	unsigned int us;
-	u32 regval;
-	int ret;
-
-	regval = get_l2_indirect_reg(L2PMOVSR);
-	pr_debug("Got interrupt: %x\n", regval);
-
-	devfreq_monitor_stop(df);
-
-	/*
-	 * Don't recalc bandwidth if the interrupt comes right after a
-	 * previous bandwidth calculation.  This is done for two reasons:
-	 *
-	 * 1. Sampling the BW during a very short duration can result in a
-	 *    very inaccurate measurement due to very short bursts.
-	 * 2. This can only happen if the limit was hit very close to the end
-	 *    of the previous sample period. Which means the current BW
-	 *    estimate is not very off and doesn't need to be readjusted.
-	 */
-	ts = ktime_get();
-	us = ktime_to_us(ktime_sub(ts, prev_ts));
-	if (us > TOO_SOON_US) {
-		mutex_lock(&df->lock);
-		ret = update_devfreq(df);
-		if (ret)
-			pr_err("Unable to update freq on IRQ!\n");
-		mutex_unlock(&df->lock);
-	}
-
-	devfreq_monitor_start(df);
-
-	return IRQ_HANDLED;
-}
-
-static int start_monitoring(struct devfreq *df)
-{
-	int ret, mbyte;
-
-	ret = request_threaded_irq(l2pm_irq, NULL, mon_intr_handler,
-			  IRQF_ONESHOT | IRQF_SHARED,
-			  "cpubw_hwmon", df);
-	if (ret) {
-		pr_err("Unable to register interrupt handler\n");
-		return ret;
-	}
-
-	mon_init();
-	mon_disable(RD_MON);
-	mon_disable(WR_MON);
-
-	mbyte = (df->previous_freq * io_percent) / (2 * 100);
-	prev_r_start_val = mon_set_limit_mbyte(RD_MON, mbyte);
-	prev_w_start_val = mon_set_limit_mbyte(WR_MON, mbyte);
-	prev_ts = ktime_get();
-	prev_ab = 0;
-
-	mon_irq_enable(RD_MON, true);
-	mon_irq_enable(WR_MON, true);
-	mon_enable(RD_MON);
-	mon_enable(WR_MON);
-	global_mon_enable(true);
-
-	return 0;
-}
-
-static void stop_monitoring(struct devfreq *df)
-{
-	global_mon_enable(false);
-	mon_disable(RD_MON);
-	mon_disable(WR_MON);
-	mon_irq_enable(RD_MON, false);
-	mon_irq_enable(WR_MON, false);
-
-	disable_irq(l2pm_irq);
-	free_irq(l2pm_irq, df);
-}
-
-static int devfreq_cpubw_hwmon_get_freq(struct devfreq *df,
-					unsigned long *freq,
-					u32 *flag)
-{
-	unsigned long mbps;
-
-	mbps = measure_bw_and_set_irq();
-	compute_bw(mbps, freq, df->data);
-
-	return 0;
-}
-
-gov_attr(tolerance_percent, 0U, 30U);
-gov_attr(guard_band_mbps, 0U, 2000U);
-gov_attr(decay_rate, 0U, 100U);
-gov_attr(io_percent, 1U, 100U);
-gov_attr(bw_step, 50U, 1000U);
-
-static struct attribute *dev_attr[] = {
-	&dev_attr_tolerance_percent.attr,
-	&dev_attr_guard_band_mbps.attr,
-	&dev_attr_decay_rate.attr,
-	&dev_attr_io_percent.attr,
-	&dev_attr_bw_step.attr,
-	NULL,
-};
-
-static struct attribute_group dev_attr_group = {
-	.name = "cpubw_hwmon",
-	.attrs = dev_attr,
-};
-
-static int devfreq_cpubw_hwmon_ev_handler(struct devfreq *df,
-					unsigned int event, void *data)
-{
-	int ret;
-
-	switch (event) {
-	case DEVFREQ_GOV_START:
-		ret = start_monitoring(df);
-		if (ret)
-			return ret;
-		ret = sysfs_create_group(&df->dev.kobj, &dev_attr_group);
-		if (ret)
-			return ret;
-
-		sample_ms = df->profile->polling_ms;
-		sample_ms = max(MIN_MS, sample_ms);
-		sample_ms = min(MAX_MS, sample_ms);
-		df->profile->polling_ms = sample_ms;
-		devfreq_monitor_start(df);
-
-		pr_debug("Enabled CPU BW HW monitor governor\n");
-		break;
-
-	case DEVFREQ_GOV_STOP:
-		sysfs_remove_group(&df->dev.kobj, &dev_attr_group);
-		devfreq_monitor_stop(df);
-		*(unsigned long *)df->data = 0;
-		stop_monitoring(df);
-		pr_debug("Disabled CPU BW HW monitor governor\n");
-		break;
-
-	case DEVFREQ_GOV_INTERVAL:
-		sample_ms = *(unsigned int *)data;
-		sample_ms = max(MIN_MS, sample_ms);
-		sample_ms = min(MAX_MS, sample_ms);
-		devfreq_interval_update(df, &sample_ms);
-		break;
-	}
-
-	return 0;
-}
-
-static struct devfreq_governor devfreq_cpubw_hwmon = {
-	.name = "cpubw_hwmon",
-	.get_target_freq = devfreq_cpubw_hwmon_get_freq,
-	.event_handler = devfreq_cpubw_hwmon_ev_handler,
-};
-
-static int cpubw_hwmon_driver_probe(struct platform_device *pdev)
-{
-	struct device *dev = &pdev->dev;
-	int ret;
-
-	l2pm_irq = platform_get_irq(pdev, 0);
-	if (l2pm_irq < 0) {
-		pr_err("Unable to get IRQ number\n");
-		return l2pm_irq;
-	}
-
-	ret = of_property_read_u32(dev->of_node, "qcom,bytes-per-beat",
-			     &bytes_per_beat);
-	if (ret) {
-		pr_err("Unable to read bytes per beat\n");
-		return ret;
-	}
-
-	ret = devfreq_add_governor(&devfreq_cpubw_hwmon);
-	if (ret) {
-		pr_err("devfreq governor registration failed\n");
-		return ret;
-	}
-
-	return 0;
-}
-
-static struct of_device_id match_table[] = {
-	{ .compatible = "qcom,kraitbw-l2pm" },
-	{}
-};
-
-static struct platform_driver cpubw_hwmon_driver = {
-	.probe = cpubw_hwmon_driver_probe,
-	.driver = {
-		.name = "kraitbw-l2pm",
-		.of_match_table = match_table,
-		.owner = THIS_MODULE,
-	},
-};
-
-static int __init cpubw_hwmon_init(void)
-{
-	return platform_driver_register(&cpubw_hwmon_driver);
-}
-module_init(cpubw_hwmon_init);
-
-static void __exit cpubw_hwmon_exit(void)
-{
-	platform_driver_unregister(&cpubw_hwmon_driver);
-}
-module_exit(cpubw_hwmon_exit);
-
-MODULE_DESCRIPTION("HW monitor based CPU DDR bandwidth voting driver");
-MODULE_LICENSE("GPL v2");
diff --git drivers/devfreq/governor_cpufreq.c drivers/devfreq/governor_cpufreq.c
new file mode 100644
index 0000000..da989fe
--- /dev/null
+++ drivers/devfreq/governor_cpufreq.c
@@ -0,0 +1,711 @@
+/*
+ * Copyright (c) 2014-2015, The Linux Foundation. All rights reserved.
+ *
+ * This program is free software; you can redistribute it and/or modify
+ * it under the terms of the GNU General Public License version 2 and
+ * only version 2 as published by the Free Software Foundation.
+ *
+ * This program is distributed in the hope that it will be useful,
+ * but WITHOUT ANY WARRANTY; without even the implied warranty of
+ * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
+ * GNU General Public License for more details.
+ */
+
+#define pr_fmt(fmt) "dev-cpufreq: " fmt
+
+#include <linux/devfreq.h>
+#include <linux/cpu.h>
+#include <linux/cpumask.h>
+#include <linux/slab.h>
+#include <linux/platform_device.h>
+#include <linux/of.h>
+#include <linux/module.h>
+#include "governor.h"
+
+struct cpu_state {
+	unsigned int freq;
+	unsigned int min_freq;
+	unsigned int max_freq;
+	bool on;
+	unsigned int first_cpu;
+};
+static struct cpu_state *state[NR_CPUS];
+static int cpufreq_cnt;
+
+struct freq_map {
+	unsigned int cpu_khz;
+	unsigned int target_freq;
+};
+
+struct devfreq_node {
+	struct devfreq *df;
+	void *orig_data;
+	struct device *dev;
+	struct device_node *of_node;
+	struct list_head list;
+	struct freq_map **map;
+	struct freq_map *common_map;
+	unsigned int timeout;
+	struct delayed_work dwork;
+	bool drop;
+	unsigned long prev_tgt;
+};
+static LIST_HEAD(devfreq_list);
+static DEFINE_MUTEX(state_lock);
+static DEFINE_MUTEX(cpufreq_reg_lock);
+
+#define show_attr(name) \
+static ssize_t show_##name(struct device *dev,				\
+			struct device_attribute *attr, char *buf)	\
+{									\
+	struct devfreq *df = to_devfreq(dev);				\
+	struct devfreq_node *n = df->data;				\
+	return snprintf(buf, PAGE_SIZE, "%u\n", n->name);		\
+}
+
+#define store_attr(name, _min, _max) \
+static ssize_t store_##name(struct device *dev,				\
+			struct device_attribute *attr, const char *buf,	\
+			size_t count)					\
+{									\
+	struct devfreq *df = to_devfreq(dev);				\
+	struct devfreq_node *n = df->data;				\
+	int ret;							\
+	unsigned int val;						\
+	ret = sscanf(buf, "%u", &val);					\
+	if (ret != 1)							\
+		return -EINVAL;						\
+	val = max(val, _min);						\
+	val = min(val, _max);						\
+	n->name = val;							\
+	return count;							\
+}
+
+#define gov_attr(__attr, min, max)	\
+show_attr(__attr)			\
+store_attr(__attr, min, max)		\
+static DEVICE_ATTR(__attr, 0644, show_##__attr, store_##__attr)
+
+static int update_node(struct devfreq_node *node)
+{
+	int ret;
+	struct devfreq *df = node->df;
+
+	if (!df)
+		return 0;
+
+	cancel_delayed_work_sync(&node->dwork);
+
+	mutex_lock(&df->lock);
+	node->drop = false;
+	ret = update_devfreq(df);
+	if (ret) {
+		dev_err(df->dev.parent, "Unable to update frequency\n");
+		goto out;
+	}
+
+	if (!node->timeout)
+		goto out;
+
+	if (df->previous_freq <= df->min_freq)
+		goto out;
+
+	schedule_delayed_work(&node->dwork,
+			      msecs_to_jiffies(node->timeout));
+out:
+	mutex_unlock(&df->lock);
+	return ret;
+}
+
+static void update_all_devfreqs(void)
+{
+	struct devfreq_node *node;
+
+	list_for_each_entry(node, &devfreq_list, list) {
+		update_node(node);
+	}
+}
+
+static void do_timeout(struct work_struct *work)
+{
+	struct devfreq_node *node = container_of(to_delayed_work(work),
+						struct devfreq_node, dwork);
+	struct devfreq *df = node->df;
+
+	mutex_lock(&df->lock);
+	node->drop = true;
+	update_devfreq(df);
+	mutex_unlock(&df->lock);
+}
+
+static struct devfreq_node *find_devfreq_node(struct device *dev)
+{
+	struct devfreq_node *node;
+
+	list_for_each_entry(node, &devfreq_list, list)
+		if (node->dev == dev || node->of_node == dev->of_node)
+			return node;
+
+	return NULL;
+}
+
+/* ==================== cpufreq part ==================== */
+static void add_policy(struct cpufreq_policy *policy)
+{
+	struct cpu_state *new_state;
+	unsigned int cpu, first_cpu;
+
+	if (state[policy->cpu]) {
+		state[policy->cpu]->freq = policy->cur;
+		state[policy->cpu]->on = true;
+	} else {
+		new_state = kzalloc(sizeof(struct cpu_state), GFP_KERNEL);
+		if (!new_state)
+			return;
+
+		first_cpu = cpumask_first(policy->related_cpus);
+		new_state->first_cpu = first_cpu;
+		new_state->freq = policy->cur;
+		new_state->min_freq = policy->cpuinfo.min_freq;
+		new_state->max_freq = policy->cpuinfo.max_freq;
+		new_state->on = true;
+
+		for_each_cpu(cpu, policy->related_cpus)
+			state[cpu] = new_state;
+	}
+}
+
+static int cpufreq_policy_notifier(struct notifier_block *nb,
+		unsigned long event, void *data)
+{
+	struct cpufreq_policy *policy = data;
+
+	switch (event) {
+	case CPUFREQ_CREATE_POLICY:
+		mutex_lock(&state_lock);
+		add_policy(policy);
+		update_all_devfreqs();
+		mutex_unlock(&state_lock);
+		break;
+
+	case CPUFREQ_REMOVE_POLICY:
+		mutex_lock(&state_lock);
+		if (state[policy->cpu]) {
+			state[policy->cpu]->on = false;
+			update_all_devfreqs();
+		}
+		mutex_unlock(&state_lock);
+		break;
+	}
+
+	return 0;
+}
+
+static struct notifier_block cpufreq_policy_nb = {
+	.notifier_call = cpufreq_policy_notifier
+};
+
+static int cpufreq_trans_notifier(struct notifier_block *nb,
+		unsigned long event, void *data)
+{
+	struct cpufreq_freqs *freq = data;
+	struct cpu_state *s;
+
+	if (event != CPUFREQ_POSTCHANGE)
+		return 0;
+
+	mutex_lock(&state_lock);
+
+	s = state[freq->cpu];
+	if (!s)
+		goto out;
+
+	if (s->freq != freq->new) {
+		s->freq = freq->new;
+		update_all_devfreqs();
+	}
+
+out:
+	mutex_unlock(&state_lock);
+	return 0;
+}
+
+static struct notifier_block cpufreq_trans_nb = {
+	.notifier_call = cpufreq_trans_notifier
+};
+
+static int register_cpufreq(void)
+{
+	int ret = 0;
+	unsigned int cpu;
+	struct cpufreq_policy *policy;
+
+	mutex_lock(&cpufreq_reg_lock);
+
+	if (cpufreq_cnt)
+		goto cnt_not_zero;
+
+	get_online_cpus();
+	ret = cpufreq_register_notifier(&cpufreq_policy_nb,
+				CPUFREQ_POLICY_NOTIFIER);
+	if (ret)
+		goto out;
+
+	ret = cpufreq_register_notifier(&cpufreq_trans_nb,
+				CPUFREQ_TRANSITION_NOTIFIER);
+	if (ret) {
+		cpufreq_unregister_notifier(&cpufreq_policy_nb,
+				CPUFREQ_POLICY_NOTIFIER);
+		goto out;
+	}
+
+	for_each_online_cpu(cpu) {
+		policy = cpufreq_cpu_get(cpu);
+		if (policy) {
+			add_policy(policy);
+			cpufreq_cpu_put(policy);
+		}
+	}
+out:
+	put_online_cpus();
+cnt_not_zero:
+	if (!ret)
+		cpufreq_cnt++;
+	mutex_unlock(&cpufreq_reg_lock);
+	return ret;
+}
+
+static int unregister_cpufreq(void)
+{
+	int ret = 0;
+	int cpu;
+
+	mutex_lock(&cpufreq_reg_lock);
+
+	if (cpufreq_cnt > 1)
+		goto out;
+
+	cpufreq_unregister_notifier(&cpufreq_policy_nb,
+				CPUFREQ_POLICY_NOTIFIER);
+	cpufreq_unregister_notifier(&cpufreq_trans_nb,
+				CPUFREQ_TRANSITION_NOTIFIER);
+
+	for (cpu = ARRAY_SIZE(state) - 1; cpu >= 0; cpu--) {
+		if (!state[cpu])
+			continue;
+		if (state[cpu]->first_cpu == cpu)
+			kfree(state[cpu]);
+		state[cpu] = NULL;
+	}
+
+out:
+	cpufreq_cnt--;
+	mutex_unlock(&cpufreq_reg_lock);
+	return ret;
+}
+
+/* ==================== devfreq part ==================== */
+
+static unsigned int interpolate_freq(struct devfreq *df, unsigned int cpu)
+{
+	unsigned int *freq_table = df->profile->freq_table;
+	unsigned int cpu_min = state[cpu]->min_freq;
+	unsigned int cpu_max = state[cpu]->max_freq;
+	unsigned int cpu_freq = state[cpu]->freq;
+	unsigned int dev_min, dev_max, cpu_percent;
+
+	if (freq_table) {
+		dev_min = freq_table[0];
+		dev_max = freq_table[df->profile->max_state - 1];
+	} else {
+		if (df->max_freq <= df->min_freq)
+			return 0;
+		dev_min = df->min_freq;
+		dev_max = df->max_freq;
+	}
+
+	cpu_percent = ((cpu_freq - cpu_min) * 100) / (cpu_max - cpu_min);
+	return dev_min + mult_frac(dev_max - dev_min, cpu_percent, 100);
+}
+
+static unsigned int cpu_to_dev_freq(struct devfreq *df, unsigned int cpu)
+{
+	struct freq_map *map = NULL;
+	unsigned int cpu_khz = 0, freq;
+	struct devfreq_node *n = df->data;
+
+	if (!state[cpu] || !state[cpu]->on || state[cpu]->first_cpu != cpu) {
+		freq = 0;
+		goto out;
+	}
+
+	if (n->common_map)
+		map = n->common_map;
+	else if (n->map)
+		map = n->map[cpu];
+
+	cpu_khz = state[cpu]->freq;
+
+	if (!map) {
+		freq = interpolate_freq(df, cpu);
+		goto out;
+	}
+
+	while (map->cpu_khz && map->cpu_khz < cpu_khz)
+		map++;
+	if (!map->cpu_khz)
+		map--;
+	freq = map->target_freq;
+
+out:
+	dev_dbg(df->dev.parent, "CPU%u: %d -> dev: %u\n", cpu, cpu_khz, freq);
+	return freq;
+}
+
+static int devfreq_cpufreq_get_freq(struct devfreq *df,
+					unsigned long *freq,
+					u32 *flag)
+{
+	unsigned int cpu, tgt_freq = 0;
+	struct devfreq_node *node;
+
+	node = df->data;
+	if (!node) {
+		pr_err("Unable to find devfreq node!\n");
+		return -ENODEV;
+	}
+
+	if (node->drop) {
+		*freq = 0;
+		return 0;
+	}
+
+	for_each_possible_cpu(cpu)
+		tgt_freq = max(tgt_freq, cpu_to_dev_freq(df, cpu));
+
+	if (node->timeout && tgt_freq < node->prev_tgt)
+		*freq = 0;
+	else
+		*freq = tgt_freq;
+
+	node->prev_tgt = tgt_freq;
+
+	return 0;
+}
+
+static unsigned int show_table(char *buf, unsigned int len,
+				struct freq_map *map)
+{
+	unsigned int cnt = 0;
+
+	cnt += snprintf(buf + cnt, len - cnt, "CPU freq\tDevice freq\n");
+
+	while (map->cpu_khz && cnt < len) {
+		cnt += snprintf(buf + cnt, len - cnt, "%8u\t%11u\n",
+				map->cpu_khz, map->target_freq);
+		map++;
+	}
+	if (cnt < len)
+		cnt += snprintf(buf + cnt, len - cnt, "\n");
+
+	return cnt;
+}
+
+static ssize_t show_map(struct device *dev, struct device_attribute *attr,
+			char *buf)
+{
+	struct devfreq *df = to_devfreq(dev);
+	struct devfreq_node *n = df->data;
+	struct freq_map *map;
+	unsigned int cnt = 0, cpu;
+
+	mutex_lock(&state_lock);
+	if (n->common_map) {
+		map = n->common_map;
+		cnt += snprintf(buf + cnt, PAGE_SIZE - cnt,
+				"Common table for all CPUs:\n");
+		cnt += show_table(buf + cnt, PAGE_SIZE - cnt, map);
+	} else if (n->map) {
+		for_each_possible_cpu(cpu) {
+			map = n->map[cpu];
+			if (!map)
+				continue;
+			cnt += snprintf(buf + cnt, PAGE_SIZE - cnt,
+					"CPU %u:\n", cpu);
+			if (cnt >= PAGE_SIZE)
+				break;
+			cnt += show_table(buf + cnt, PAGE_SIZE - cnt, map);
+			if (cnt >= PAGE_SIZE)
+				break;
+		}
+	} else {
+		cnt += snprintf(buf + cnt, PAGE_SIZE - cnt,
+				"Device freq interpolated based on CPU freq\n");
+	}
+	mutex_unlock(&state_lock);
+
+	return cnt;
+}
+
+static DEVICE_ATTR(freq_map, 0444, show_map, NULL);
+gov_attr(timeout, 0U, 100U);
+
+static struct attribute *dev_attr[] = {
+	&dev_attr_freq_map.attr,
+	&dev_attr_timeout.attr,
+	NULL,
+};
+
+static struct attribute_group dev_attr_group = {
+	.name = "cpufreq",
+	.attrs = dev_attr,
+};
+
+static int devfreq_cpufreq_gov_start(struct devfreq *devfreq)
+{
+	int ret = 0;
+	struct devfreq_node *node;
+	bool alloc = false;
+
+	ret = register_cpufreq();
+	if (ret)
+		return ret;
+
+	ret = sysfs_create_group(&devfreq->dev.kobj, &dev_attr_group);
+	if (ret) {
+		unregister_cpufreq();
+		return ret;
+	}
+
+	mutex_lock(&state_lock);
+
+	node = find_devfreq_node(devfreq->dev.parent);
+	if (node == NULL) {
+		node = kzalloc(sizeof(struct devfreq_node), GFP_KERNEL);
+		if (!node) {
+			pr_err("Out of memory!\n");
+			ret = -ENOMEM;
+			goto alloc_fail;
+		}
+		alloc = true;
+		node->dev = devfreq->dev.parent;
+		list_add_tail(&node->list, &devfreq_list);
+	}
+
+	INIT_DELAYED_WORK(&node->dwork, do_timeout);
+
+	node->df = devfreq;
+	node->orig_data = devfreq->data;
+	devfreq->data = node;
+
+	ret = update_node(node);
+	if (ret)
+		goto update_fail;
+
+	mutex_unlock(&state_lock);
+	return 0;
+
+update_fail:
+	devfreq->data = node->orig_data;
+	if (alloc) {
+		list_del(&node->list);
+		kfree(node);
+	}
+alloc_fail:
+	mutex_unlock(&state_lock);
+	sysfs_remove_group(&devfreq->dev.kobj, &dev_attr_group);
+	unregister_cpufreq();
+	return ret;
+}
+
+static void devfreq_cpufreq_gov_stop(struct devfreq *devfreq)
+{
+	struct devfreq_node *node = devfreq->data;
+
+	cancel_delayed_work_sync(&node->dwork);
+
+	mutex_lock(&state_lock);
+	devfreq->data = node->orig_data;
+	if (node->map || node->common_map) {
+		node->df = NULL;
+	} else {
+		list_del(&node->list);
+		kfree(node);
+	}
+	mutex_unlock(&state_lock);
+
+	sysfs_remove_group(&devfreq->dev.kobj, &dev_attr_group);
+	unregister_cpufreq();
+}
+
+static int devfreq_cpufreq_ev_handler(struct devfreq *devfreq,
+					unsigned int event, void *data)
+{
+	int ret;
+
+	switch (event) {
+	case DEVFREQ_GOV_START:
+
+		ret = devfreq_cpufreq_gov_start(devfreq);
+		if (ret) {
+			pr_err("Governor start failed!\n");
+			return ret;
+		}
+		pr_debug("Enabled dev CPUfreq governor\n");
+		break;
+
+	case DEVFREQ_GOV_STOP:
+
+		devfreq_cpufreq_gov_stop(devfreq);
+		pr_debug("Disabled dev CPUfreq governor\n");
+		break;
+	}
+
+	return 0;
+}
+
+static struct devfreq_governor devfreq_cpufreq = {
+	.name = "cpufreq",
+	.get_target_freq = devfreq_cpufreq_get_freq,
+	.event_handler = devfreq_cpufreq_ev_handler,
+};
+
+#define NUM_COLS	2
+static struct freq_map *read_tbl(struct device_node *of_node, char *prop_name)
+{
+	int len, nf, i, j;
+	u32 data;
+	struct freq_map *tbl;
+
+	if (!of_find_property(of_node, prop_name, &len))
+		return NULL;
+	len /= sizeof(data);
+
+	if (len % NUM_COLS || len == 0)
+		return NULL;
+	nf = len / NUM_COLS;
+
+	tbl = kzalloc((nf + 1) * sizeof(*tbl), GFP_KERNEL);
+	if (!tbl)
+		return NULL;
+
+	for (i = 0, j = 0; i < nf; i++, j += 2) {
+		of_property_read_u32_index(of_node, prop_name, j, &data);
+		tbl[i].cpu_khz = data;
+
+		of_property_read_u32_index(of_node, prop_name, j + 1, &data);
+		tbl[i].target_freq = data;
+	}
+	tbl[i].cpu_khz = 0;
+
+	return tbl;
+}
+
+#define PROP_TARGET "target-dev"
+#define PROP_TABLE "cpu-to-dev-map"
+static int add_table_from_of(struct device_node *of_node)
+{
+	struct device_node *target_of_node;
+	struct devfreq_node *node;
+	struct freq_map *common_tbl;
+	struct freq_map **tbl_list = NULL;
+	static char prop_name[] = PROP_TABLE "-999999";
+	int cpu, ret, cnt = 0, prop_sz = ARRAY_SIZE(prop_name);
+
+	target_of_node = of_parse_phandle(of_node, PROP_TARGET, 0);
+	if (!target_of_node)
+		return -EINVAL;
+
+	node = kzalloc(sizeof(struct devfreq_node), GFP_KERNEL);
+	if (!node)
+		return -ENOMEM;
+
+	common_tbl = read_tbl(of_node, PROP_TABLE);
+	if (!common_tbl) {
+		tbl_list = kzalloc(sizeof(*tbl_list) * NR_CPUS, GFP_KERNEL);
+		if (!tbl_list)
+			return -ENOMEM;
+
+		for_each_possible_cpu(cpu) {
+			ret = snprintf(prop_name, prop_sz, "%s-%d",
+					PROP_TABLE, cpu);
+			if (ret >= prop_sz) {
+				pr_warn("More CPUs than I can handle!\n");
+				pr_warn("Skipping rest of the tables!\n");
+				break;
+			}
+			tbl_list[cpu] = read_tbl(of_node, prop_name);
+			if (tbl_list[cpu])
+				cnt++;
+		}
+	}
+	if (!common_tbl && !cnt) {
+		kfree(tbl_list);
+		return -EINVAL;
+	}
+
+	mutex_lock(&state_lock);
+	node->of_node = target_of_node;
+	node->map = tbl_list;
+	node->common_map = common_tbl;
+	list_add_tail(&node->list, &devfreq_list);
+	mutex_unlock(&state_lock);
+
+	return 0;
+}
+
+static int __init devfreq_cpufreq_init(void)
+{
+	int ret;
+	struct device_node *of_par, *of_child;
+
+	of_par = of_find_node_by_name(NULL, "devfreq-cpufreq");
+	if (of_par) {
+		for_each_child_of_node(of_par, of_child) {
+			ret = add_table_from_of(of_child);
+			if (ret)
+				pr_err("Parsing %s failed!\n", of_child->name);
+			else
+				pr_debug("Parsed %s.\n", of_child->name);
+		}
+		of_node_put(of_par);
+	} else {
+		pr_info("No tables parsed from DT.\n");
+	}
+
+	ret = devfreq_add_governor(&devfreq_cpufreq);
+	if (ret) {
+		pr_err("Governor add failed!\n");
+		return ret;
+	}
+
+	return 0;
+}
+subsys_initcall(devfreq_cpufreq_init);
+
+static void __exit devfreq_cpufreq_exit(void)
+{
+	int ret, cpu;
+	struct devfreq_node *node, *tmp;
+
+	ret = devfreq_remove_governor(&devfreq_cpufreq);
+	if (ret)
+		pr_err("Governor remove failed!\n");
+
+	mutex_lock(&state_lock);
+	list_for_each_entry_safe(node, tmp, &devfreq_list, list) {
+		kfree(node->common_map);
+		for_each_possible_cpu(cpu)
+			kfree(node->map[cpu]);
+		kfree(node->map);
+		list_del(&node->list);
+		kfree(node);
+	}
+	mutex_unlock(&state_lock);
+
+	return;
+}
+module_exit(devfreq_cpufreq_exit);
+
+MODULE_DESCRIPTION("CPU freq based generic governor for devfreq devices");
+MODULE_LICENSE("GPL v2");
diff --git drivers/devfreq/governor_msm_adreno_tz.c drivers/devfreq/governor_msm_adreno_tz.c
index 359de4b..92c5eff 100644
--- drivers/devfreq/governor_msm_adreno_tz.c
+++ drivers/devfreq/governor_msm_adreno_tz.c
@@ -265,10 +265,18 @@ static int tz_start(struct devfreq *devfreq)
 	unsigned int t1, t2 = 2 * HIST;
 	int i, out, ret;
 
-	if (devfreq->data == NULL) {
-		pr_err(TAG "data is required for this governor\n");
-		return -EINVAL;
-	}
+	struct msm_adreno_extended_profile *ext_profile = container_of(
+					(devfreq->profile),
+					struct msm_adreno_extended_profile,
+					profile);
+
+	/*
+	 * Assuming that we have only one instance of the adreno device
+	 * connected to this governor,
+	 * can safely restore the pointer to the governor private data
+	 * from the container of the device profile
+	 */
+	devfreq->data = ext_profile->private_data;
 
 	priv = devfreq->data;
 	priv->nb.notifier_call = tz_notify;
diff --git drivers/devfreq/governor_msm_cpufreq.c drivers/devfreq/governor_msm_cpufreq.c
deleted file mode 100644
index 9b13e26..0000000
--- drivers/devfreq/governor_msm_cpufreq.c
+++ /dev/null
@@ -1,85 +0,0 @@
-/*
- * Copyright (c) 2013, The Linux Foundation. All rights reserved.
- *
- * This program is free software; you can redistribute it and/or modify
- * it under the terms of the GNU General Public License version 2 and
- * only version 2 as published by the Free Software Foundation.
- *
- * This program is distributed in the hope that it will be useful,
- * but WITHOUT ANY WARRANTY; without even the implied warranty of
- * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
- * GNU General Public License for more details.
- */
-
-#include <linux/devfreq.h>
-#include <mach/cpufreq.h>
-#include "governor.h"
-
-DEFINE_MUTEX(df_lock);
-static struct devfreq *df;
-
-static int devfreq_msm_cpufreq_get_freq(struct devfreq *df,
-					unsigned long *freq,
-					u32 *flag)
-{
-	*freq = msm_cpufreq_get_bw();
-	return 0;
-}
-
-int devfreq_msm_cpufreq_update_bw(void)
-{
-	int ret = 0;
-
-	mutex_lock(&df_lock);
-	if (df) {
-		mutex_lock(&df->lock);
-		ret = update_devfreq(df);
-		mutex_unlock(&df->lock);
-	}
-	mutex_unlock(&df_lock);
-	return ret;
-}
-
-static int devfreq_msm_cpufreq_ev_handler(struct devfreq *devfreq,
-					unsigned int event, void *data)
-{
-	int ret;
-
-	switch (event) {
-	case DEVFREQ_GOV_START:
-		mutex_lock(&df_lock);
-		df = devfreq;
-		mutex_unlock(&df_lock);
-
-		ret = devfreq_msm_cpufreq_update_bw();
-		if (ret) {
-			pr_err("Unable to update BW! Gov start failed!\n");
-			return ret;
-		}
-
-		devfreq_monitor_stop(df);
-		pr_debug("Enabled MSM CPUfreq governor\n");
-		break;
-
-	case DEVFREQ_GOV_STOP:
-		mutex_lock(&df_lock);
-		df = NULL;
-		mutex_unlock(&df_lock);
-
-		pr_debug("Disabled MSM CPUfreq governor\n");
-		break;
-	}
-
-	return 0;
-}
-
-static struct devfreq_governor devfreq_msm_cpufreq = {
-	.name = "msm_cpufreq",
-	.get_target_freq = devfreq_msm_cpufreq_get_freq,
-	.event_handler = devfreq_msm_cpufreq_ev_handler,
-};
-
-int register_devfreq_msm_cpufreq(void)
-{
-	return devfreq_add_governor(&devfreq_msm_cpufreq);
-}
diff --git drivers/devfreq/krait-l2pm.c drivers/devfreq/krait-l2pm.c
new file mode 100644
index 0000000..329d042
--- /dev/null
+++ drivers/devfreq/krait-l2pm.c
@@ -0,0 +1,466 @@
+/*
+ * Copyright (c) 2013-2014, The Linux Foundation. All rights reserved.
+ *
+ * This program is free software; you can redistribute it and/or modify
+ * it under the terms of the GNU General Public License version 2 and
+ * only version 2 as published by the Free Software Foundation.
+ *
+ * This program is distributed in the hope that it will be useful,
+ * but WITHOUT ANY WARRANTY; without even the implied warranty of
+ * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
+ * GNU General Public License for more details.
+ */
+
+#define pr_fmt(fmt) "krait-l2pm: " fmt
+
+#include <linux/kernel.h>
+#include <linux/module.h>
+#include <linux/init.h>
+#include <linux/io.h>
+#include <linux/delay.h>
+#include <linux/err.h>
+#include <linux/errno.h>
+#include <linux/interrupt.h>
+#include <linux/platform_device.h>
+#include <linux/of.h>
+#include <linux/spinlock.h>
+#include "governor_bw_hwmon.h"
+#include "governor_cache_hwmon.h"
+
+#include <mach/msm-krait-l2-accessors.h>
+
+#define L2PMRESR(n)		(0x410 + n)
+#define L2PMCR			0x400
+#define L2PMCNTENCLR		0x402
+#define L2PMCNTENSET		0x403
+#define L2PMINTENCLR		0x404
+#define L2PMINTENSET		0x405
+#define L2PMOVSR		0x406
+#define L2PMOVSSET		0x407
+#define L2PMCCNTR		0x409
+#define L2PMnEVCNTCR(n)		(0x420 + n * 0x10)
+#define L2PMnEVCNTR(n)		(0x421 + n * 0x10)
+#define L2PMnEVCNTSR(n)		(0x422 + n * 0x10)
+#define L2PMnEVFILTER(n)	(0x423 + n * 0x10)
+#define L2PMnEVTYPER(n)		(0x424 + n * 0x10)
+
+static DEFINE_SPINLOCK(mon_lock);
+
+static void global_mon_enable(bool en)
+{
+	static unsigned int cnt;
+	u32 regval;
+
+	spin_lock(&mon_lock);
+	if (en) {
+		cnt++;
+	} else {
+		if (cnt)
+			cnt--;
+	}
+
+	/* Global counter enable */
+	regval = get_l2_indirect_reg(L2PMCR);
+	if (cnt)
+		regval |= BIT(0);
+	else
+		regval &= ~BIT(0);
+	set_l2_indirect_reg(L2PMCR, regval);
+	spin_unlock(&mon_lock);
+}
+
+static void mon_enable(int n)
+{
+	/* Clear previous overflow state for event counter n */
+	set_l2_indirect_reg(L2PMOVSR, BIT(n));
+
+	/* Enable event counter n */
+	set_l2_indirect_reg(L2PMCNTENSET, BIT(n));
+}
+
+static void mon_disable(int n)
+{
+	/* Disable event counter n */
+	set_l2_indirect_reg(L2PMCNTENCLR, BIT(n));
+}
+
+static void mon_irq_enable(int n, bool en)
+{
+	if (en)
+		set_l2_indirect_reg(L2PMINTENSET, BIT(n));
+	else
+		set_l2_indirect_reg(L2PMINTENCLR, BIT(n));
+}
+
+static int mon_overflow(int n)
+{
+	return get_l2_indirect_reg(L2PMOVSR) & BIT(n);
+}
+
+/* Returns start counter value to be used with mon_get_count() */
+static u32 mon_set_limit(int n, u32 count)
+{
+	u32 regval;
+
+	regval = 0xFFFFFFFF - count;
+	set_l2_indirect_reg(n == 31 ? L2PMCCNTR : L2PMnEVCNTR(n), regval);
+	pr_debug("EV%d start val: %x\n", n, regval);
+
+	return regval;
+}
+
+static long mon_get_count(int n, u32 start_val)
+{
+	u32 overflow, count;
+
+	count = get_l2_indirect_reg(n == 31 ? L2PMCCNTR : L2PMnEVCNTR(n));
+	overflow = get_l2_indirect_reg(L2PMOVSR);
+
+	pr_debug("EV%d ov: %x, cnt: %x\n", n, overflow, count);
+
+	if (overflow & BIT(n))
+		return 0xFFFFFFFF - start_val + count;
+	else
+		return count - start_val;
+}
+
+#define RD_MON	0
+#define WR_MON	1
+#define L2_H_REQ_MON	2
+#define L2_M_REQ_MON	3
+#define L2_CYC_MON	31
+
+/* ********** CPUBW specific code  ********** */
+
+static u32 bytes_per_beat;
+static u32 prev_r_start_val;
+static u32 prev_w_start_val;
+static int bw_irq;
+
+static void mon_bw_init(void)
+{
+	/* Set up counters 0/1 to count write/read beats */
+	set_l2_indirect_reg(L2PMRESR(2), 0x8B0B0000);
+	set_l2_indirect_reg(L2PMnEVCNTCR(RD_MON), 0x0);
+	set_l2_indirect_reg(L2PMnEVCNTCR(WR_MON), 0x0);
+	set_l2_indirect_reg(L2PMnEVCNTR(RD_MON), 0xFFFFFFFF);
+	set_l2_indirect_reg(L2PMnEVCNTR(WR_MON), 0xFFFFFFFF);
+	set_l2_indirect_reg(L2PMnEVFILTER(RD_MON), 0xF003F);
+	set_l2_indirect_reg(L2PMnEVFILTER(WR_MON), 0xF003F);
+	set_l2_indirect_reg(L2PMnEVTYPER(RD_MON), 0xA);
+	set_l2_indirect_reg(L2PMnEVTYPER(WR_MON), 0xB);
+}
+
+/* Returns MBps of read/writes for the sampling window. */
+static unsigned int beats_to_mbps(long long beats, unsigned int us)
+{
+	beats *= USEC_PER_SEC;
+	beats *= bytes_per_beat;
+	do_div(beats, us);
+	beats = DIV_ROUND_UP_ULL(beats, SZ_1M);
+
+	return beats;
+}
+
+static unsigned int mbps_to_beats(unsigned long mbps, unsigned int ms,
+				  unsigned int tolerance_percent)
+{
+	mbps *= (100 + tolerance_percent) * ms;
+	mbps /= 100;
+	mbps = DIV_ROUND_UP(mbps, MSEC_PER_SEC);
+	mbps = mult_frac(mbps, SZ_1M, bytes_per_beat);
+	return mbps;
+}
+
+static unsigned long meas_bw_and_set_irq(struct bw_hwmon *hw,
+					 unsigned int tol, unsigned int us)
+{
+	unsigned long r_mbps, w_mbps;
+	u32 r_limit, w_limit;
+	unsigned int sample_ms = hw->df->profile->polling_ms;
+
+	mon_disable(RD_MON);
+	mon_disable(WR_MON);
+
+	r_mbps = mon_get_count(RD_MON, prev_r_start_val);
+	r_mbps = beats_to_mbps(r_mbps, us);
+	w_mbps = mon_get_count(WR_MON, prev_w_start_val);
+	w_mbps = beats_to_mbps(w_mbps, us);
+
+	r_limit = mbps_to_beats(r_mbps, sample_ms, tol);
+	w_limit = mbps_to_beats(w_mbps, sample_ms, tol);
+
+	prev_r_start_val = mon_set_limit(RD_MON, r_limit);
+	prev_w_start_val = mon_set_limit(WR_MON, w_limit);
+
+	mon_enable(RD_MON);
+	mon_enable(WR_MON);
+
+	pr_debug("R/W = %ld/%ld\n", r_mbps, w_mbps);
+
+	return r_mbps + w_mbps;
+}
+
+static irqreturn_t bwmon_intr_handler(int irq, void *dev)
+{
+	if (mon_overflow(RD_MON) || mon_overflow(WR_MON)) {
+		update_bw_hwmon(dev);
+		return IRQ_HANDLED;
+	}
+
+	return IRQ_NONE;
+}
+
+static int start_bw_hwmon(struct bw_hwmon *hw, unsigned long mbps)
+{
+	u32 limit;
+	int ret;
+
+	ret = request_threaded_irq(bw_irq, NULL, bwmon_intr_handler,
+				  IRQF_ONESHOT | IRQF_SHARED,
+				  "bw_hwmon", hw);
+	if (ret) {
+		pr_err("Unable to register interrupt handler!\n");
+		return ret;
+	}
+
+	mon_bw_init();
+	mon_disable(RD_MON);
+	mon_disable(WR_MON);
+
+	limit = mbps_to_beats(mbps, hw->df->profile->polling_ms, 0);
+	limit /= 2;
+	prev_r_start_val = mon_set_limit(RD_MON, limit);
+	prev_w_start_val = mon_set_limit(WR_MON, limit);
+
+	mon_irq_enable(RD_MON, true);
+	mon_irq_enable(WR_MON, true);
+	mon_enable(RD_MON);
+	mon_enable(WR_MON);
+	global_mon_enable(true);
+
+	return 0;
+}
+
+static void stop_bw_hwmon(struct bw_hwmon *hw)
+{
+	disable_irq(bw_irq);
+	free_irq(bw_irq, hw);
+	global_mon_enable(false);
+	mon_disable(RD_MON);
+	mon_disable(WR_MON);
+	mon_irq_enable(RD_MON, false);
+	mon_irq_enable(WR_MON, false);
+}
+
+static struct devfreq_governor devfreq_gov_cpubw_hwmon = {
+	.name = "cpubw_hwmon",
+};
+
+static struct bw_hwmon cpubw_hwmon = {
+	.start_hwmon = &start_bw_hwmon,
+	.stop_hwmon = &stop_bw_hwmon,
+	.meas_bw_and_set_irq = &meas_bw_and_set_irq,
+	.gov = &devfreq_gov_cpubw_hwmon,
+};
+
+/* ********** Cache reqs specific code  ********** */
+
+static u32 prev_req_start_val;
+static int cache_irq;
+
+static void mon_mrps_init(void)
+{
+	/* Cache bank requests */
+	set_l2_indirect_reg(L2PMRESR(0), 0x86000001);
+	set_l2_indirect_reg(L2PMnEVCNTCR(L2_H_REQ_MON), 0x0);
+	set_l2_indirect_reg(L2PMnEVCNTR(L2_H_REQ_MON), 0x0);
+	set_l2_indirect_reg(L2PMnEVFILTER(L2_H_REQ_MON), 0xF003F);
+	set_l2_indirect_reg(L2PMnEVTYPER(L2_H_REQ_MON), 0x0);
+	set_l2_indirect_reg(L2PMnEVCNTCR(L2_M_REQ_MON), 0x0);
+	set_l2_indirect_reg(L2PMnEVCNTR(L2_M_REQ_MON), 0x0);
+	set_l2_indirect_reg(L2PMnEVFILTER(L2_M_REQ_MON), 0xF003F);
+	set_l2_indirect_reg(L2PMnEVTYPER(L2_M_REQ_MON), 0x3);
+}
+
+/* Returns million requests/sec for the sampling window. */
+static int count_to_mrps(long long count, unsigned int us)
+{
+	do_div(count, us);
+	count++;
+	return count;
+}
+
+static unsigned int mrps_to_count(unsigned int mrps, unsigned int ms,
+				  unsigned int tolerance)
+{
+	mrps += tolerance;
+	mrps *= ms * USEC_PER_MSEC;
+	return mrps;
+}
+
+static unsigned long meas_mrps_and_set_irq(struct cache_hwmon *hw,
+					unsigned int tol, unsigned int us,
+					struct mrps_stats *mrps)
+{
+	u32 limit;
+	unsigned int sample_ms = hw->df->profile->polling_ms;
+	unsigned long f = hw->df->previous_freq;
+	unsigned long t_mrps, m_mrps, l2_cyc;
+
+	mon_disable(L2_H_REQ_MON);
+	mon_disable(L2_M_REQ_MON);
+	mon_disable(L2_CYC_MON);
+
+	t_mrps = mon_get_count(L2_H_REQ_MON, prev_req_start_val);
+	t_mrps = count_to_mrps(t_mrps, us);
+	m_mrps = mon_get_count(L2_M_REQ_MON, 0);
+	m_mrps = count_to_mrps(m_mrps, us);
+
+	l2_cyc = mon_get_count(L2_CYC_MON, 0);
+
+	limit = mrps_to_count(t_mrps, sample_ms, tol);
+	prev_req_start_val = mon_set_limit(L2_H_REQ_MON, limit);
+	mon_set_limit(L2_M_REQ_MON, 0xFFFFFFFF);
+	mon_set_limit(L2_CYC_MON, 0xFFFFFFFF);
+
+	mon_enable(L2_H_REQ_MON);
+	mon_enable(L2_M_REQ_MON);
+	mon_enable(L2_CYC_MON);
+
+	mrps->mrps[HIGH] = t_mrps - m_mrps;
+	mrps->mrps[MED] = m_mrps;
+	mrps->mrps[LOW] = 0;
+	mrps->busy_percent = mult_frac(l2_cyc, 1000, us) * 100 / f;
+
+	return 0;
+}
+
+static irqreturn_t mon_intr_handler(int irq, void *dev)
+{
+	if (mon_overflow(L2_H_REQ_MON) || mon_overflow(L2_M_REQ_MON)) {
+		update_cache_hwmon(dev);
+		return IRQ_HANDLED;
+	}
+	return IRQ_NONE;
+}
+
+static int start_mrps_hwmon(struct cache_hwmon *hw, struct mrps_stats *mrps)
+{
+	u32 limit;
+	int ret;
+
+	ret = request_threaded_irq(cache_irq, NULL, mon_intr_handler,
+			  IRQF_ONESHOT | IRQF_SHARED,
+			  "cache_hwmon", hw);
+	if (ret) {
+		pr_err("Unable to register interrupt handler!\n");
+		return ret;
+	}
+
+	mon_mrps_init();
+	mon_disable(L2_H_REQ_MON);
+	mon_disable(L2_M_REQ_MON);
+	mon_disable(L2_CYC_MON);
+
+	limit = mrps_to_count(mrps->mrps[HIGH], hw->df->profile->polling_ms, 0);
+	prev_req_start_val = mon_set_limit(L2_H_REQ_MON, limit);
+	mon_set_limit(L2_M_REQ_MON, 0xFFFFFFFF);
+	mon_set_limit(L2_CYC_MON, 0xFFFFFFFF);
+
+	mon_irq_enable(L2_H_REQ_MON, true);
+	mon_irq_enable(L2_M_REQ_MON, true);
+	mon_enable(L2_H_REQ_MON);
+	mon_enable(L2_M_REQ_MON);
+	mon_enable(L2_CYC_MON);
+	global_mon_enable(true);
+
+	return 0;
+}
+
+static void stop_mrps_hwmon(struct cache_hwmon *hw)
+{
+	disable_irq(cache_irq);
+	free_irq(cache_irq, hw);
+	global_mon_enable(false);
+	mon_disable(L2_H_REQ_MON);
+	mon_disable(L2_M_REQ_MON);
+	mon_disable(L2_CYC_MON);
+	mon_irq_enable(L2_H_REQ_MON, false);
+	mon_irq_enable(L2_M_REQ_MON, false);
+}
+
+static struct cache_hwmon mrps_hwmon = {
+	.start_hwmon = &start_mrps_hwmon,
+	.stop_hwmon = &stop_mrps_hwmon,
+	.meas_mrps_and_set_irq = &meas_mrps_and_set_irq,
+};
+
+/*************************************************************************/
+
+static int krait_l2pm_driver_probe(struct platform_device *pdev)
+{
+	struct device *dev = &pdev->dev;
+	int ret, ret2;
+
+	bw_irq = platform_get_irq(pdev, 0);
+	if (bw_irq < 0) {
+		pr_err("Unable to get IRQ number\n");
+		return bw_irq;
+	}
+
+	ret = of_property_read_u32(dev->of_node, "qcom,bytes-per-beat",
+					&bytes_per_beat);
+	if (ret) {
+		pr_err("Unable to read bytes per beat\n");
+		return ret;
+	}
+
+	ret = register_bw_hwmon(dev, &cpubw_hwmon);
+	if (ret)
+		pr_err("CPUBW hwmon registration failed\n");
+
+	cache_irq = bw_irq;
+	mrps_hwmon.of_node = of_parse_phandle(dev->of_node, "qcom,target-dev",
+					      0);
+	if (!mrps_hwmon.of_node)
+		return -EINVAL;
+
+	ret2 = register_cache_hwmon(dev, &mrps_hwmon);
+	if (ret2)
+		pr_err("Cache hwmon registration failed\n");
+
+	if (ret && ret2)
+		return ret2;
+
+	return 0;
+}
+
+static struct of_device_id match_table[] = {
+	{ .compatible = "qcom,kraitbw-l2pm" },
+	{}
+};
+
+static struct platform_driver krait_l2pm_driver = {
+	.probe = krait_l2pm_driver_probe,
+	.driver = {
+		.name = "kraitbw-l2pm",
+		.of_match_table = match_table,
+		.owner = THIS_MODULE,
+	},
+};
+
+static int __init krait_l2pm_init(void)
+{
+	return platform_driver_register(&krait_l2pm_driver);
+}
+module_init(krait_l2pm_init);
+
+static void __exit krait_l2pm_exit(void)
+{
+	platform_driver_unregister(&krait_l2pm_driver);
+}
+module_exit(krait_l2pm_exit);
+
+MODULE_DESCRIPTION("Krait L2 performance monitor driver");
+MODULE_LICENSE("GPL v2");
diff --git drivers/gpu/msm/adreno.c drivers/gpu/msm/adreno.c
index a7aaa8b..dd3fa80 100644
--- drivers/gpu/msm/adreno.c
+++ drivers/gpu/msm/adreno.c
@@ -80,16 +80,6 @@
 
 static void adreno_input_work(struct work_struct *work);
 
-/*
- * The default values for the simpleondemand governor are 90 and 5,
- * we use different values here.
- * They have to be tuned and compare with the tz governor anyway.
- */
-static struct devfreq_simple_ondemand_data adreno_ondemand_data = {
-	.upthreshold = 80,
-	.downdifferential = 20,
-};
-
 static struct devfreq_msm_adreno_tz_data adreno_tz_data = {
 	.bus = {
 		.max = 450,
@@ -97,18 +87,12 @@ static struct devfreq_msm_adreno_tz_data adreno_tz_data = {
 	.device_id = KGSL_DEVICE_3D0,
 };
 
-static const struct devfreq_governor_data adreno_governors[] = {
-	{ .name = "simple_ondemand", .data = &adreno_ondemand_data },
-	{ .name = "msm-adreno-tz", .data = &adreno_tz_data },
-};
-
 static const struct kgsl_functable adreno_functable;
 
 static struct adreno_device device_3d0 = {
 	.dev = {
 		KGSL_DEVICE_COMMON_INIT(device_3d0.dev),
-		.pwrscale = KGSL_PWRSCALE_INIT(adreno_governors,
-					ARRAY_SIZE(adreno_governors)),
+		.pwrscale = KGSL_PWRSCALE_INIT(&adreno_tz_data),
 		.name = DEVICE_3D0_NAME,
 		.id = KGSL_DEVICE_3D0,
 		.mh = {
diff --git drivers/gpu/msm/kgsl_pwrscale.c drivers/gpu/msm/kgsl_pwrscale.c
index b0b1474..dd7388a 100644
--- drivers/gpu/msm/kgsl_pwrscale.c
+++ drivers/gpu/msm/kgsl_pwrscale.c
@@ -144,8 +144,7 @@ EXPORT_SYMBOL(kgsl_pwrscale_update);
 void kgsl_pwrscale_disable(struct kgsl_device *device)
 {
 	BUG_ON(!mutex_is_locked(&device->mutex));
-
-	if (device->pwrscale.enabled) {
+	if (device->pwrscale.devfreqptr) {
 		queue_work(device->pwrscale.devfreq_wq,
 			&device->pwrscale.devfreq_suspend_ws);
 		device->pwrscale.enabled = false;
@@ -165,10 +164,10 @@ void kgsl_pwrscale_enable(struct kgsl_device *device)
 {
 	BUG_ON(!mutex_is_locked(&device->mutex));
 
-	if (!device->pwrscale.enabled) {
-		device->pwrscale.enabled = true;
+	if (device->pwrscale.devfreqptr) {
 		queue_work(device->pwrscale.devfreq_wq,
 			&device->pwrscale.devfreq_resume_ws);
+		device->pwrscale.enabled = true;
 	}
 }
 EXPORT_SYMBOL(kgsl_pwrscale_enable);
@@ -396,6 +395,7 @@ int kgsl_pwrscale_init(struct device *dev, const char *governor)
 	struct kgsl_pwrscale *pwrscale;
 	struct kgsl_pwrctrl *pwr;
 	struct devfreq *devfreq;
+	struct msm_adreno_extended_profile *ext_profile;
 	struct devfreq_dev_profile *profile;
 	struct devfreq_msm_adreno_tz_data *data;
 	int i, out = 0;
@@ -407,7 +407,8 @@ int kgsl_pwrscale_init(struct device *dev, const char *governor)
 
 	pwrscale = &device->pwrscale;
 	pwr = &device->pwrctrl;
-	profile = &pwrscale->profile;
+	ext_profile = &pwrscale->ext_profile;
+	profile = &pwrscale->ext_profile.profile;
 
 	srcu_init_notifier_head(&pwrscale->nh);
 
@@ -428,40 +429,33 @@ int kgsl_pwrscale_init(struct device *dev, const char *governor)
 	if (profile->max_state == 1)
 		governor = "performance";
 
-	/* initialize any governor specific data here */
-	for (i = 0; i < profile->num_governor_data; i++) {
-		if (strncmp("msm-adreno-tz",
-				profile->governor_data[i].name,
-				DEVFREQ_NAME_LEN) == 0) {
-			data = (struct devfreq_msm_adreno_tz_data *)
-				profile->governor_data[i].data;
-			/*
-			 * If there is a separate GX power rail, allow
-			 * independent modification to its voltage through
-			 * the bus bandwidth vote.
-			 */
-			if (pwr->bus_control) {
-				out = 0;
-				while (pwr->bus_ib[out]) {
-					pwr->bus_ib[out] =
-						pwr->bus_ib[out] >> 20;
-					out++;
-				}
-				data->bus.num = out;
-				data->bus.ib = &pwr->bus_ib[0];
-				data->bus.index = &pwr->bus_index[0];
-				printk("kgsl: num bus is %d\n", out);
-			} else {
-				data->bus.num = 0;
-			}
+	/* initialize msm-adreno-tz governor specific data here */
+	data = ext_profile->private_data;
+	/*
+	 * If there is a separate GX power rail, allow
+	 * independent modification to its voltage through
+	 * the bus bandwidth vote.
+	 */
+	if (pwr->bus_control) {
+		out = 0;
+		while (pwr->bus_ib[out]) {
+			pwr->bus_ib[out] =
+				pwr->bus_ib[out] >> 20;
+			out++;
 		}
-	}
-
-	devfreq = devfreq_add_device(dev, &pwrscale->profile, governor, NULL);
-	if (IS_ERR(devfreq))
+		data->bus.num = out;
+		data->bus.ib = &pwr->bus_ib[0];
+		data->bus.index = &pwr->bus_index[0];
+	} else
+		data->bus.num = 0;
+
+	devfreq = devfreq_add_device(dev, &pwrscale->ext_profile.profile,
+			governor, pwrscale->ext_profile.private_data);
+	if (IS_ERR(devfreq)) {
+		device->pwrscale.enabled = false;
 		return PTR_ERR(devfreq);
-
-	pwrscale->devfreq = devfreq;
+    }
+	pwrscale->devfreqptr = devfreq;
 
 	ret = sysfs_create_link(&device->dev->kobj,
 			&devfreq->dev.kobj, "devfreq");
@@ -490,10 +484,12 @@ void kgsl_pwrscale_close(struct kgsl_device *device)
 	BUG_ON(!mutex_is_locked(&device->mutex));
 
 	pwrscale = &device->pwrscale;
+	if (!pwrscale->devfreqptr)
+		return;
 	flush_workqueue(pwrscale->devfreq_wq);
 	destroy_workqueue(pwrscale->devfreq_wq);
-	devfreq_remove_device(device->pwrscale.devfreq);
-	device->pwrscale.devfreq = NULL;
+	devfreq_remove_device(device->pwrscale.devfreqptr);
+	device->pwrscale.devfreqptr = NULL;
 	srcu_cleanup_notifier_head(&device->pwrscale.nh);
 }
 EXPORT_SYMBOL(kgsl_pwrscale_close);
@@ -502,7 +498,7 @@ static void do_devfreq_suspend(struct work_struct *work)
 {
 	struct kgsl_pwrscale *pwrscale = container_of(work,
 			struct kgsl_pwrscale, devfreq_suspend_ws);
-	struct devfreq *devfreq = pwrscale->devfreq;
+	struct devfreq *devfreq = pwrscale->devfreqptr;
 
 	devfreq_suspend_device(devfreq);
 }
@@ -511,7 +507,7 @@ static void do_devfreq_resume(struct work_struct *work)
 {
 	struct kgsl_pwrscale *pwrscale = container_of(work,
 			struct kgsl_pwrscale, devfreq_resume_ws);
-	struct devfreq *devfreq = pwrscale->devfreq;
+	struct devfreq *devfreq = pwrscale->devfreqptr;
 
 	devfreq_resume_device(devfreq);
 }
@@ -520,7 +516,7 @@ static void do_devfreq_notify(struct work_struct *work)
 {
 	struct kgsl_pwrscale *pwrscale = container_of(work,
 			struct kgsl_pwrscale, devfreq_notify_ws);
-	struct devfreq *devfreq = pwrscale->devfreq;
+	struct devfreq *devfreq = pwrscale->devfreqptr;
 	srcu_notifier_call_chain(&pwrscale->nh,
 				 ADRENO_DEVFREQ_NOTIFY_RETIRE,
 				 devfreq);
diff --git drivers/gpu/msm/kgsl_pwrscale.h drivers/gpu/msm/kgsl_pwrscale.h
index 866964c..5ce660a 100644
--- drivers/gpu/msm/kgsl_pwrscale.h
+++ drivers/gpu/msm/kgsl_pwrscale.h
@@ -27,8 +27,8 @@ struct kgsl_power_stats {
 };
 
 struct kgsl_pwrscale {
-	struct devfreq *devfreq;
-	struct devfreq_dev_profile profile;
+	struct devfreq *devfreqptr;
+	struct msm_adreno_extended_profile ext_profile;
 	unsigned int freq_table[KGSL_MAX_PWRLEVELS];
 	char last_governor[DEVFREQ_NAME_LEN];
 	struct kgsl_power_stats accum_stats;
@@ -59,13 +59,14 @@ int kgsl_devfreq_target(struct device *dev, unsigned long *freq, u32 flags);
 int kgsl_devfreq_get_dev_status(struct device *, struct devfreq_dev_status *);
 int kgsl_devfreq_get_cur_freq(struct device *dev, unsigned long *freq);
 
-#define KGSL_PWRSCALE_INIT(_gov_list, _num_gov) { \
+#define KGSL_PWRSCALE_INIT(_priv_data) { \
 	.enabled = true, \
-	.profile = { \
-		.target = kgsl_devfreq_target, \
-		.get_dev_status = kgsl_devfreq_get_dev_status, \
-		.get_cur_freq = kgsl_devfreq_get_cur_freq, \
-		.governor_data = (_gov_list), \
-		.num_governor_data = (_num_gov), \
-	} }
+	.ext_profile = { \
+		.private_data = _priv_data, \
+		.profile = { \
+			.target = kgsl_devfreq_target, \
+			.get_dev_status = kgsl_devfreq_get_dev_status, \
+			.get_cur_freq = kgsl_devfreq_get_cur_freq, \
+	} } }
+
 #endif
diff --git drivers/of/base.c drivers/of/base.c
index d48317e..ff8c1dc 100644
--- drivers/of/base.c
+++ drivers/of/base.c
@@ -283,82 +283,82 @@ EXPORT_SYMBOL(of_device_is_available);
 #ifdef CONFIG_MACH_LGE
 int compare_revision(const char *revision)
 {
-	char range = 0;
-	char min_rev_str[16];
-	char max_rev_str[16];
-	char min_rev_no = 0;
-	char max_rev_no = 0;
-	int i = 0, j = 0;
-
-	memset(min_rev_str, 0x0, sizeof(min_rev_str));
-	memset(max_rev_str, 0x0, sizeof(min_rev_str));
-
-	if (revision[0] != '.') {
-		while (revision[i] != 0 && revision[i] != '.')
-			min_rev_str[j++] = revision[i++];
-
-		if (revision[i] == '.' && revision[i + 1] == '.' &&
-				revision[i + 2] == '.') {
-			range = 1;
-			i += 3;
-			j = 0;
-			while (revision[i] != 0)
-				max_rev_str[j++] = revision[i++];
-		}
-	} else {
-		if (revision[i] == '.' && revision[i + 1] == '.' &&
-				revision[i + 2] == '.') {
-			range = 1;
-			i += 3;
-			while (revision[i] != 0)
-				max_rev_str[j++] = revision[i++];
-		}
-	}
-
-	if (!min_rev_str[0]) {
-		min_rev_no = HW_REV_EVB1;
-	} else {
-		for (i = 0; i < HW_REV_MAX; ++i) {
-			if (!strcmp(rev_str[i], min_rev_str)) {
-				min_rev_no = i;
-				break;
-			}
-		}
-
-		if (i == HW_REV_MAX) {
-			pr_err("wrong min revision string = %s\n", min_rev_str);
-			return 0;
-		}
-	}
-
-	if (!max_rev_str[0]) {
-		max_rev_no = HW_REV_MAX - 1;
-	} else {
-		for (i = 0; i < HW_REV_MAX; ++i) {
-			if (!strcmp(rev_str[i], max_rev_str)) {
-				max_rev_no = i;
-				break;
-			}
-		}
-
-		if (i == HW_REV_MAX) {
-			pr_err("wrong max revision string = %s\n", max_rev_str);
-			return 0;
-		}
-	}
-
-	if (range) {
-		if (min_rev_no <= lge_get_board_revno() &&
-				lge_get_board_revno() <= max_rev_no)
-			return 1;
-		else
-			return 0;
-	} else {
-		if (min_rev_no == lge_get_board_revno())
-			return 1;
-		else
-			return 0;
-	}
+       char range = 0;
+       char min_rev_str[16];
+       char max_rev_str[16];
+       char min_rev_no = 0;
+       char max_rev_no = 0;
+       int i = 0, j = 0;
+
+       memset(min_rev_str, 0x0, sizeof(min_rev_str));
+       memset(max_rev_str, 0x0, sizeof(min_rev_str));
+
+       if (revision[0] != '.') {
+               while (revision[i] != 0 && revision[i] != '.')
+                       min_rev_str[j++] = revision[i++];
+
+               if (revision[i] == '.' && revision[i + 1] == '.' &&
+                               revision[i + 2] == '.') {
+                       range = 1;
+                       i += 3;
+                       j = 0;
+                       while (revision[i] != 0)
+                               max_rev_str[j++] = revision[i++];
+               }
+       } else {
+               if (revision[i] == '.' && revision[i + 1] == '.' &&
+                               revision[i + 2] == '.') {
+                       range = 1;
+                       i += 3;
+                       while (revision[i] != 0)
+                               max_rev_str[j++] = revision[i++];
+               }
+       }
+
+       if (!min_rev_str[0]) {
+               min_rev_no = HW_REV_EVB1;
+       } else {
+               for (i = 0; i < HW_REV_MAX; ++i) {
+                       if (!strcmp(rev_str[i], min_rev_str)) {
+                               min_rev_no = i;
+                               break;
+                       }
+               }
+
+               if (i == HW_REV_MAX) {
+                       pr_err("wrong min revision string = %s\n", min_rev_str);
+                       return 0;
+               }
+       }
+
+       if (!max_rev_str[0]) {
+               max_rev_no = HW_REV_MAX - 1;
+       } else {
+               for (i = 0; i < HW_REV_MAX; ++i) {
+                       if (!strcmp(rev_str[i], max_rev_str)) {
+                               max_rev_no = i;
+                               break;
+                       }
+               }
+
+               if (i == HW_REV_MAX) {
+                       pr_err("wrong max revision string = %s\n", max_rev_str);
+                       return 0;
+               }
+       }
+
+       if (range) {
+               if (min_rev_no <= lge_get_board_revno() &&
+                               lge_get_board_revno() <= max_rev_no)
+                       return 1;
+               else
+                       return 0;
+       } else {
+               if (min_rev_no == lge_get_board_revno())
+                       return 1;
+               else
+                       return 0;
+       }
 }
 
 /**
@@ -371,22 +371,22 @@ int compare_revision(const char *revision)
  */
 int of_device_is_available_revision(struct device_node *device)
 {
-	int count;
-	int i;
-	const char *revision = NULL;
+       int count;
+       int i;
+       const char *revision = NULL;
 
-	count = of_property_count_strings(device, "revision");
-	if (count < 0)
-		return 1;
+       count = of_property_count_strings(device, "revision");
+       if (count < 0)
+               return 1;
 
-	for (i = 0; i < count; i++) {
-		of_property_read_string_index(device, "revision", i, &revision);
+       for (i = 0; i < count; i++) {
+               of_property_read_string_index(device, "revision", i, &revision);
 
-		if (compare_revision(revision))
-			return 1;
-	}
+               if (compare_revision(revision))
+                       return 1;
+       }
 
-	return 0;
+       return 0;
 }
 EXPORT_SYMBOL(of_device_is_available_revision);
 #endif
@@ -746,12 +746,122 @@ struct device_node *of_find_node_by_phandle(phandle handle)
 EXPORT_SYMBOL(of_find_node_by_phandle);
 
 /**
+ * of_property_read_u32_index - Find and read a u32 from a multi-value property.
+ *
+ * @np:		device node from which the property value is to be read.
+ * @propname:	name of the property to be searched.
+ * @index:	index of the u32 in the list of values
+ * @out_value:	pointer to return value, modified only if no error.
+ *
+ * Search for a property in a device node and read nth 32-bit value from
+ * it. Returns 0 on success, -EINVAL if the property does not exist,
+ * -ENODATA if property does not have a value, and -EOVERFLOW if the
+ * property data isn't large enough.
+ *
+ * The out_value is modified only if a valid u32 value can be decoded.
+ */
+int of_property_read_u32_index(const struct device_node *np,
+				       const char *propname,
+				       u32 index, u32 *out_value)
+{
+	struct property *prop = of_find_property(np, propname, NULL);
+
+	if (!prop)
+		return -EINVAL;
+	if (!prop->value)
+		return -ENODATA;
+	if (((index + 1) * sizeof(*out_value)) > prop->length)
+		return -EOVERFLOW;
+
+	*out_value = be32_to_cpup(((__be32 *)prop->value) + index);
+	return 0;
+}
+EXPORT_SYMBOL_GPL(of_property_read_u32_index);
+
+/**
+ * of_property_read_u8_array - Find and read an array of u8 from a property.
+ *
+ * @np:		device node from which the property value is to be read.
+ * @propname:	name of the property to be searched.
+ * @out_value:	pointer to return value, modified only if return value is 0.
+ * @sz:		number of array elements to read
+ *
+ * Search for a property in a device node and read 8-bit value(s) from
+ * it. Returns 0 on success, -EINVAL if the property does not exist,
+ * -ENODATA if property does not have a value, and -EOVERFLOW if the
+ * property data isn't large enough.
+ *
+ * dts entry of array should be like:
+ *	property = /bits/ 8 <0x50 0x60 0x70>;
+ *
+ * The out_value is modified only if a valid u8 value can be decoded.
+ */
+int of_property_read_u8_array(const struct device_node *np,
+			const char *propname, u8 *out_values, size_t sz)
+{
+	struct property *prop = of_find_property(np, propname, NULL);
+	const u8 *val;
+
+	if (!prop)
+		return -EINVAL;
+	if (!prop->value)
+		return -ENODATA;
+	if ((sz * sizeof(*out_values)) > prop->length)
+		return -EOVERFLOW;
+
+	val = prop->value;
+	while (sz--)
+		*out_values++ = *val++;
+	return 0;
+}
+EXPORT_SYMBOL_GPL(of_property_read_u8_array);
+
+/**
+ * of_property_read_u16_array - Find and read an array of u16 from a property.
+ *
+ * @np:		device node from which the property value is to be read.
+ * @propname:	name of the property to be searched.
+ * @out_value:	pointer to return value, modified only if return value is 0.
+ * @sz:		number of array elements to read
+ *
+ * Search for a property in a device node and read 16-bit value(s) from
+ * it. Returns 0 on success, -EINVAL if the property does not exist,
+ * -ENODATA if property does not have a value, and -EOVERFLOW if the
+ * property data isn't large enough.
+ *
+ * dts entry of array should be like:
+ *	property = /bits/ 16 <0x5000 0x6000 0x7000>;
+ *
+ * The out_value is modified only if a valid u16 value can be decoded.
+ */
+int of_property_read_u16_array(const struct device_node *np,
+			const char *propname, u16 *out_values, size_t sz)
+{
+	struct property *prop = of_find_property(np, propname, NULL);
+	const __be16 *val;
+
+	if (!prop)
+		return -EINVAL;
+	if (!prop->value)
+		return -ENODATA;
+	if ((sz * sizeof(*out_values)) > prop->length)
+		return -EOVERFLOW;
+
+	val = prop->value;
+	while (sz--)
+		*out_values++ = be16_to_cpup(val++);
+	return 0;
+}
+EXPORT_SYMBOL_GPL(of_property_read_u16_array);
+
+/**
  * of_property_read_u32_array - Find and read an array of 32 bit integers
  * from a property.
  *
  * @np:		device node from which the property value is to be read.
  * @propname:	name of the property to be searched.
  * @out_value:	pointer to return value, modified only if return value is 0.
+ * @sz:		number of array elements to read
  *
  * Search for a property in a device node and read 32-bit value(s) from
  * it. Returns 0 on success, -EINVAL if the property does not exist,
@@ -841,52 +951,6 @@ int of_property_read_string(struct device_node *np, const char *propname,
 EXPORT_SYMBOL_GPL(of_property_read_string);
 
 /**
- * of_property_read_string_index - Find and read a string from a multiple
- * strings property.
- * @np:		device node from which the property value is to be read.
- * @propname:	name of the property to be searched.
- * @index:	index of the string in the list of strings
- * @out_string:	pointer to null terminated return string, modified only if
- *		return value is 0.
- *
- * Search for a property in a device tree node and retrieve a null
- * terminated string value (pointer to data, not a copy) in the list of strings
- * contained in that property.
- * Returns 0 on success, -EINVAL if the property does not exist, -ENODATA if
- * property does not have a value, and -EILSEQ if the string is not
- * null-terminated within the length of the property data.
- *
- * The out_string pointer is modified only if a valid string can be decoded.
- */
-int of_property_read_string_index(struct device_node *np, const char *propname,
-				  int index, const char **output)
-{
-	struct property *prop = of_find_property(np, propname, NULL);
-	int i = 0;
-	size_t l = 0, total = 0;
-	const char *p;
-
-	if (!prop)
-		return -EINVAL;
-	if (!prop->value)
-		return -ENODATA;
-	if (strnlen(prop->value, prop->length) >= prop->length)
-		return -EILSEQ;
-
-	p = prop->value;
-
-	for (i = 0; total < prop->length; total += l, p += l) {
-		l = strlen(p) + 1;
-		if (i++ == index) {
-			*output = p;
-			return 0;
-		}
-	}
-	return -ENODATA;
-}
-EXPORT_SYMBOL_GPL(of_property_read_string_index);
-
-/**
  * of_property_match_string() - Find string in a list and return index
  * @np: pointer to node containing string list property
  * @propname: string list property name
@@ -912,7 +976,7 @@ int of_property_match_string(struct device_node *np, const char *propname,
 	end = p + prop->length;
 
 	for (i = 0; p < end; i++, p += l) {
-		l = strlen(p) + 1;
+		l = strnlen(p, end - p) + 1;
 		if (p + l > end)
 			return -EILSEQ;
 		pr_debug("comparing %s with %s\n", string, p);
@@ -924,39 +988,41 @@ int of_property_match_string(struct device_node *np, const char *propname,
 EXPORT_SYMBOL_GPL(of_property_match_string);
 
 /**
- * of_property_count_strings - Find and return the number of strings from a
- * multiple strings property.
+ * of_property_read_string_util() - Utility helper for parsing string properties
  * @np:		device node from which the property value is to be read.
  * @propname:	name of the property to be searched.
+ * @out_strs:	output array of string pointers.
+ * @sz:		number of array elements to read.
+ * @skip:	Number of strings to skip over at beginning of list.
  *
- * Search for a property in a device tree node and retrieve the number of null
- * terminated string contain in it. Returns the number of strings on
- * success, -EINVAL if the property does not exist, -ENODATA if property
- * does not have a value, and -EILSEQ if the string is not null-terminated
- * within the length of the property data.
+ * Don't call this function directly. It is a utility helper for the
+ * of_property_read_string*() family of functions.
  */
-int of_property_count_strings(struct device_node *np, const char *propname)
+int of_property_read_string_helper(struct device_node *np, const char *propname,
+				   const char **out_strs, size_t sz, int skip)
 {
 	struct property *prop = of_find_property(np, propname, NULL);
-	int i = 0;
-	size_t l = 0, total = 0;
-	const char *p;
+	int l = 0, i = 0;
+	const char *p, *end;
 
 	if (!prop)
 		return -EINVAL;
 	if (!prop->value)
 		return -ENODATA;
-	if (strnlen(prop->value, prop->length) >= prop->length)
-		return -EILSEQ;
-
 	p = prop->value;
+	end = p + prop->length;
 
-	for (i = 0; total < prop->length; total += l, p += l, i++)
-		l = strlen(p) + 1;
-
-	return i;
+	for (i = 0; p < end && (!out_strs || i < skip + sz); i++, p += l) {
+		l = strnlen(p, end - p) + 1;
+		if (p + l > end)
+			return -EILSEQ;
+		if (out_strs && i >= skip)
+			*out_strs++ = p;
+	}
+	i -= skip;
+	return i <= 0 ? -ENODATA : i;
 }
-EXPORT_SYMBOL_GPL(of_property_count_strings);
+EXPORT_SYMBOL_GPL(of_property_read_string_helper);
 
 /**
  * of_parse_phandle - Resolve a phandle property to a device_node pointer
@@ -1352,6 +1418,7 @@ void of_alias_scan(void * (*dt_alloc)(u64 size, u64 align))
 		ap = dt_alloc(sizeof(*ap) + len + 1, 4);
 		if (!ap)
 			continue;
+		memset(ap, 0, sizeof(*ap) + len + 1);
 		ap->alias = start;
 		of_alias_add(ap, np, id, start, len);
 	}
diff --git drivers/thermal/msm_thermal.c drivers/thermal/msm_thermal.c
index 00801df..e77dded 100644
--- drivers/thermal/msm_thermal.c
+++ drivers/thermal/msm_thermal.c
@@ -1293,7 +1293,7 @@ exit:
 	return ret;
 }
 
-static void __ref do_freq_control(long temp)
+static void do_freq_control(long temp)
 {
 	uint32_t cpu = 0;
 	uint32_t max_freq = cpus[cpu].limited_max_freq;
@@ -1335,7 +1335,7 @@ static void __ref do_freq_control(long temp)
 	put_online_cpus();
 }
 
-static void __ref check_temp(struct work_struct *work)
+static void check_temp(struct work_struct *work)
 {
 	static int limit_init;
 	long temp = 0;
@@ -1350,6 +1350,10 @@ static void __ref check_temp(struct work_struct *work)
 		goto reschedule;
 	}
 
+	do_core_control(temp);
+	do_psm();
+	do_ocr();
+
 	if (!limit_init) {
 		ret = msm_thermal_get_freq_table();
 		if (ret)
@@ -1358,10 +1362,7 @@ static void __ref check_temp(struct work_struct *work)
 			limit_init = 1;
 	}
 
-	do_core_control(temp);
 	do_vdd_restriction();
-	do_psm();
-	do_ocr();
 	do_freq_control(temp);
 
 reschedule:
diff --git include/linux/cpufreq.h include/linux/cpufreq.h
index 58442f6..9508eef 100644
--- include/linux/cpufreq.h
+++ include/linux/cpufreq.h
@@ -119,6 +119,8 @@ struct cpufreq_policy {
 #define CPUFREQ_INCOMPATIBLE	(1)
 #define CPUFREQ_NOTIFY		(2)
 #define CPUFREQ_START		(3)
+#define CPUFREQ_CREATE_POLICY (5)
+#define CPUFREQ_REMOVE_POLICY (6)
 
 #define CPUFREQ_SHARED_TYPE_NONE (0) /* None */
 #define CPUFREQ_SHARED_TYPE_HW	 (1) /* HW does needed coordination */
@@ -260,10 +262,10 @@ struct cpufreq_driver {
 int cpufreq_register_driver(struct cpufreq_driver *driver_data);
 int cpufreq_unregister_driver(struct cpufreq_driver *driver_data);
 
-
-void cpufreq_notify_transition(struct cpufreq_freqs *freqs, unsigned int state);
 void cpufreq_notify_utilization(struct cpufreq_policy *policy,
 		unsigned int load);
+void cpufreq_notify_transition(struct cpufreq_policy *policy,
+		struct cpufreq_freqs *freqs, unsigned int state);
 
 static inline void cpufreq_verify_within_limits(struct cpufreq_policy *policy, unsigned int min, unsigned int max)
 {
diff --git include/linux/devfreq.h include/linux/devfreq.h
index 77de366..5d2ee27 100644
--- include/linux/devfreq.h
+++ include/linux/devfreq.h
@@ -57,20 +57,6 @@ struct devfreq_dev_status {
 #define DEVFREQ_FLAG_WAKEUP_MAXFREQ		0x8
 
 /**
- * struct devfreq_governor_data - mapping to per device governor data
- * @name:		The name of the governor.
- * @data:		Private data for the governor.
- *
- * Devices may pass in an array of this structure to allow governors
- * to get the correct data pointer when they are enabled after
- * the devfreq_add_device() call.
- */
-struct devfreq_governor_data {
-	const char *name;
-	void *data;
-};
-
-/**
  * struct devfreq_dev_profile - Devfreq's user device profile
  * @initial_freq:	The operating frequency when devfreq_add_device() is
  *			called.
@@ -93,11 +79,6 @@ struct devfreq_governor_data {
  *			this is the time to unregister it.
  * @freq_table:	Optional list of frequencies to support statistics.
  * @max_state:	The size of freq_table.
- * @governor_data:	Optional array of private data for governors.
- *			This is used to set devfreq->data correctly
- *			when a governor is enabled via sysfs or other
- *			mechanisms after the devfreq_add_device() call.
- * @num_governor_data:  Number of elements in governor_data.
  */
 struct devfreq_dev_profile {
 	unsigned long initial_freq;
@@ -111,8 +92,6 @@ struct devfreq_dev_profile {
 
 	unsigned int *freq_table;
 	unsigned int max_state;
-	const struct devfreq_governor_data *governor_data;
-	unsigned int num_governor_data;
 };
 
 /**
diff --git include/linux/msm_adreno_devfreq.h include/linux/msm_adreno_devfreq.h
index 53d7085..6590580 100644
--- include/linux/msm_adreno_devfreq.h
+++ include/linux/msm_adreno_devfreq.h
@@ -1,6 +1,7 @@
 #ifndef MSM_ADRENO_DEVFREQ_H
 #define MSM_ADRENO_DEVFREQ_H
 
+#include <linux/devfreq.h>
 #include <linux/notifier.h>
 
 #define ADRENO_DEVFREQ_NOTIFY_SUBMIT	1
@@ -44,4 +45,9 @@ struct devfreq_msm_adreno_tz_data {
 	unsigned int device_id;
 };
 
+struct msm_adreno_extended_profile {
+	struct devfreq_msm_adreno_tz_data *private_data;
+	struct devfreq_dev_profile profile;
+};
+
 #endif
diff --git include/linux/of.h include/linux/of.h
index 8449edf..1112912 100644
--- include/linux/of.h
+++ include/linux/of.h
@@ -209,6 +209,13 @@ extern struct device_node *of_find_node_with_property(
 extern struct property *of_find_property(const struct device_node *np,
 					 const char *name,
 					 int *lenp);
+extern int of_property_read_u32_index(const struct device_node *np,
+				       const char *propname,
+				       u32 index, u32 *out_value);
+extern int of_property_read_u8_array(const struct device_node *np,
+			const char *propname, u8 *out_values, size_t sz);
+extern int of_property_read_u16_array(const struct device_node *np,
+			const char *propname, u16 *out_values, size_t sz);
 extern int of_property_read_u32_array(const struct device_node *np,
 				      const char *propname,
 				      u32 *out_values,
@@ -219,14 +226,12 @@ extern int of_property_read_u64(const struct device_node *np,
 extern int of_property_read_string(struct device_node *np,
 				   const char *propname,
 				   const char **out_string);
-extern int of_property_read_string_index(struct device_node *np,
-					 const char *propname,
-					 int index, const char **output);
 extern int of_property_match_string(struct device_node *np,
 				    const char *propname,
 				    const char *string);
-extern int of_property_count_strings(struct device_node *np,
-				     const char *propname);
+extern int of_property_read_string_helper(struct device_node *np,
+					      const char *propname,
+					      const char **out_strs, size_t sz, int index);
 extern int of_device_is_compatible(const struct device_node *device,
 				   const char *);
 extern int of_device_is_available(const struct device_node *device);
@@ -300,6 +305,24 @@ static inline struct device_node *of_find_compatible_node(
 	return NULL;
 }
 
+static inline int of_property_read_u32_index(const struct device_node *np,
+			const char *propname, u32 index, u32 *out_value)
+{
+	return -ENOSYS;
+}
+
+static inline int of_property_read_u8_array(const struct device_node *np,
+			const char *propname, u8 *out_values, size_t sz)
+{
+	return -ENOSYS;
+}
+
+static inline int of_property_read_u16_array(const struct device_node *np,
+			const char *propname, u16 *out_values, size_t sz)
+{
+	return -ENOSYS;
+}
+
 static inline int of_property_read_u32_array(const struct device_node *np,
 					     const char *propname,
 					     u32 *out_values, size_t sz)
@@ -314,15 +337,9 @@ static inline int of_property_read_string(struct device_node *np,
 	return -ENOSYS;
 }
 
-static inline int of_property_read_string_index(struct device_node *np,
-						const char *propname, int index,
-						const char **out_string)
-{
-	return -ENOSYS;
-}
-
-static inline int of_property_count_strings(struct device_node *np,
-					    const char *propname)
+static inline int of_property_read_string_helper(struct device_node *np,
+						 const char *propname,
+						 const char **out_strs, size_t sz, int index)
 {
 	return -ENOSYS;
 }
@@ -362,6 +379,70 @@ static inline int of_machine_is_compatible(const char *compat)
 #endif /* CONFIG_OF */
 
 /**
+ * of_property_read_string_array() - Read an array of strings from a multiple
+ * strings property.
+ * @np:		device node from which the property value is to be read.
+ * @propname:	name of the property to be searched.
+ * @out_strs:	output array of string pointers.
+ * @sz:		number of array elements to read.
+ *
+ * Search for a property in a device tree node and retrieve a list of
+ * terminated string values (pointer to data, not a copy) in that property.
+ *
+ * If @out_strs is NULL, the number of strings in the property is returned.
+ */
+static inline int of_property_read_string_array(struct device_node *np,
+						const char *propname, const char **out_strs,
+						size_t sz)
+{
+	return of_property_read_string_helper(np, propname, out_strs, sz, 0);
+}
+
+/**
+ * of_property_count_strings() - Find and return the number of strings from a
+ * multiple strings property.
+ * @np:		device node from which the property value is to be read.
+ * @propname:	name of the property to be searched.
+ *
+ * Search for a property in a device tree node and retrieve the number of null
+ * terminated string contain in it. Returns the number of strings on
+ * success, -EINVAL if the property does not exist, -ENODATA if property
+ * does not have a value, and -EILSEQ if the string is not null-terminated
+ * within the length of the property data.
+ */
+static inline int of_property_count_strings(struct device_node *np,
+					    const char *propname)
+{
+	return of_property_read_string_helper(np, propname, NULL, 0, 0);
+}
+
+/**
+ * of_property_read_string_index() - Find and read a string from a multiple
+ * strings property.
+ * @np:		device node from which the property value is to be read.
+ * @propname:	name of the property to be searched.
+ * @index:	index of the string in the list of strings
+ * @out_string:	pointer to null terminated return string, modified only if
+ *		return value is 0.
+ *
+ * Search for a property in a device tree node and retrieve a null
+ * terminated string value (pointer to data, not a copy) in the list of strings
+ * contained in that property.
+ * Returns 0 on success, -EINVAL if the property does not exist, -ENODATA if
+ * property does not have a value, and -EILSEQ if the string is not
+ * null-terminated within the length of the property data.
+ *
+ * The out_string pointer is modified only if a valid string can be decoded.
+ */
+static inline int of_property_read_string_index(struct device_node *np,
+						const char *propname,
+						int index, const char **output)
+{
+	int rc = of_property_read_string_helper(np, propname, output, 1, index);
+	return rc < 0 ? rc : 0;
+}
+
+/**
  * of_property_read_bool - Findfrom a property
  * @np:		device node from which the property value is to be read.
  * @propname:	name of the property to be searched.
@@ -377,6 +458,20 @@ static inline bool of_property_read_bool(const struct device_node *np,
 	return prop ? true : false;
 }
 
+static inline int of_property_read_u8(const struct device_node *np,
+				       const char *propname,
+				       u8 *out_value)
+{
+	return of_property_read_u8_array(np, propname, out_value, 1);
+}
+
+static inline int of_property_read_u16(const struct device_node *np,
+				       const char *propname,
+				       u16 *out_value)
+{
+	return of_property_read_u16_array(np, propname, out_value, 1);
+}
+
 static inline int of_property_read_u32(const struct device_node *np,
 				       const char *propname,
 				       u32 *out_value)
diff --git include/soc/qcom/devfreq_devbw.h include/soc/qcom/devfreq_devbw.h
new file mode 100644
index 0000000..7edb2ab
--- /dev/null
+++ include/soc/qcom/devfreq_devbw.h
@@ -0,0 +1,43 @@
+/*
+ * Copyright (c) 2014, The Linux Foundation. All rights reserved.
+ *
+ * This program is free software; you can redistribute it and/or modify
+ * it under the terms of the GNU General Public License version 2 and
+ * only version 2 as published by the Free Software Foundation.
+ *
+ * This program is distributed in the hope that it will be useful,
+ * but WITHOUT ANY WARRANTY; without even the implied warranty of
+ * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
+ * GNU General Public License for more details.
+ */
+
+#ifndef _DEVFREQ_DEVBW_H
+#define _DEVFREQ_DEVBW_H
+
+#include <linux/devfreq.h>
+
+#ifdef CONFIG_MSM_DEVFREQ_DEVBW
+int devfreq_add_devbw(struct device *dev);
+int devfreq_remove_devbw(struct device *dev);
+int devfreq_suspend_devbw(struct device *dev);
+int devfreq_resume_devbw(struct device *dev);
+#else
+static inline int devfreq_add_devbw(struct device *dev)
+{
+	return 0;
+}
+static inline int devfreq_remove_devbw(struct device *dev)
+{
+	return 0;
+}
+static inline int devfreq_suspend_devbw(struct device *dev)
+{
+	return 0;
+}
+static inline int devfreq_resume_devbw(struct device *dev)
+{
+	return 0;
+}
+#endif
+
+#endif /* _DEVFREQ_DEVBW_H */
